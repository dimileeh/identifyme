{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, make_scorer\n",
    "from vowpalwabbit.sklearn_vw import VWClassifier, VW\n",
    "import itertools\n",
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparsematrix(X):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for r in range(X.shape[0]):\n",
    "        row_counter = Counter(X[r])\n",
    "        for site, num in row_counter.items():\n",
    "            row.append(r)\n",
    "            col.append(site)\n",
    "            data.append(num)\n",
    "    print \"Sparse Matrix - rows:\", X.shape[0], \"columns:\", len(set(col))\n",
    "    return csr_matrix((data, (row, col)), shape=(X.shape[0], len(set(col))))[:,1:]\n",
    "\n",
    "\n",
    "def sites_to_sparse_tfidf(train_data, test_data, target_col, session_length, label_encoder=False):\n",
    "    train_test_df = pd.concat([train_data, test_data])\n",
    "    train_index_full = list(train_data.index)\n",
    "    train_index_dup = list(train_data[train_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]+[\"target\"]].index)\n",
    "    test_index_full = list(test_data.index)\n",
    "    test_index_dup = list(test_data[test_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]].index)\n",
    "    train_duplicates_mask = np.transpose([np.in1d(train_index_full, train_index_dup).astype(int)])\n",
    "    test_duplicates_mask = np.transpose([np.in1d(test_index_full, test_index_dup).astype(int)])\n",
    "\n",
    "    y = train_data[target_col]\n",
    "\n",
    "    train_test_df_sites = train_test_df[['site' + str(c) for c in range(1,10+1)]].fillna(0).astype('int')\n",
    "    train_test_df_sites_array = [\" \".join([\"s_\"+str(s) for s in train_test_df_sites.as_matrix()[i] if int(s) != 0]) \\\n",
    "                                                                  for i in range(train_test_df_sites.shape[0])]\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_df=0.9).fit(train_test_df_sites_array) #TfidfVectorizer()\n",
    "    X_train_test_sparse = tfidf.transform(train_test_df_sites_array)\n",
    "\n",
    "    X_train_sparse = X_train_test_sparse[:len(train_data)]\n",
    "    X_test_sparse = X_train_test_sparse[len(train_data):]\n",
    "    \n",
    "    sites_columns_num = X_train_test_sparse.shape[1]\n",
    "    \n",
    "    y_for_vw = None\n",
    "    class_encoder = None\n",
    "    if label_encoder:\n",
    "        class_encoder = LabelEncoder().fit(y.astype('str'))\n",
    "        y_for_vw = class_encoder.transform(y.astype('str')) + 1\n",
    "    \n",
    "    return [X_train_sparse, X_test_sparse, y, y_for_vw, sites_columns_num, class_encoder, tfidf, \\\n",
    "             train_duplicates_mask, test_duplicates_mask]\n",
    "\n",
    "\n",
    "def features_to_sparse(train_data, test_data, feature_cols):\n",
    "    features_matrix = []\n",
    "    for df in [train_data, test_data]:\n",
    "        num_cols = 0\n",
    "        data = []\n",
    "        rows = []\n",
    "        cols = []\n",
    "        for label in feature_cols:\n",
    "            if label in [\"day_of_week\", \"daytime\"]:\n",
    "                coldata = list(df[[label]].values.T[0].astype('float') + 1)\n",
    "            else:\n",
    "                coldata = list(df[[label]].values.T[0].astype('float'))\n",
    "            if len(data):\n",
    "                data += coldata\n",
    "            else:\n",
    "                data = list(coldata)\n",
    "            if len(cols):\n",
    "                cols += [num_cols] * len(coldata)\n",
    "            else:\n",
    "                cols = [num_cols] * len(coldata)\n",
    "            num_cols += 1\n",
    "        rows = [r for r in range(df.shape[0])] * num_cols\n",
    "        features = csr_matrix((data, (rows, cols)), shape=(df.shape[0], num_cols), dtype=float)\n",
    "        features_matrix.append(features)\n",
    "    return features_matrix\n",
    "\n",
    "\n",
    "def calc_site_times_portions(train_data, test_data):\n",
    "    site_times = [{},{}]\n",
    "    count = 0\n",
    "    for data in [train_data, test_data]:\n",
    "        for r, row in data[:][range(0, 10)+range(20,30)].iterrows():\n",
    "            rowdic = {}\n",
    "            for c, s in [[c, 'site' + str(c)] for c in range(1,10)]:\n",
    "                if row[s] == 0:\n",
    "                    continue\n",
    "                if row[s] in rowdic:\n",
    "                    rowdic[int(row[s])] += row[\"time_diff\"+str(c)]\n",
    "                else:\n",
    "                    rowdic[int(row[s])] = row[\"time_diff\"+str(c)]\n",
    "            site_times[count][r] = {}\n",
    "            for site, time in rowdic.items():\n",
    "                if len(rowdic) == 1:\n",
    "                    site_times[count][r][int(site)] = 1.0\n",
    "                    continue\n",
    "                if time > 0:\n",
    "                    site_times[count][r][int(site)] = round(float(time)/row[\"session_timespan\"],3)\n",
    "        count+=1\n",
    "    return site_times\n",
    "\n",
    "def site_times_to_sparse(sitetimes):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    rowcount = 0\n",
    "    for sitetime in sitetimes:\n",
    "        for r, sites in sitetime.items():\n",
    "            for site, p in sites.items():\n",
    "                col.append(site)\n",
    "                row.append(rowcount)\n",
    "                data.append(p)\n",
    "            rowcount+=1\n",
    "    site_times_sparse = csr_matrix((data, (row, col)), shape=(len(sitetimes[0])+len(sitetimes[1]), max(col)+1), \\\n",
    "                                                                                              dtype=float)[:,1:]\n",
    "    return site_times_sparse\n",
    "\n",
    "\n",
    "\n",
    "def combine_sites_features_sparse(sites_train_sparse, features_train_sparse, \\\n",
    "                                  sites_test_sparse, features_test_sparse, \\\n",
    "                                  train_duplicates_mask, test_duplicates_mask, \\\n",
    "                                  train_site_times_sparse = None, test_site_times_sparse = None, \\\n",
    "                                train_sites_sequence=None, test_sites_sequence=None):\n",
    "    if train_site_times_sparse is not None and test_site_times_sparse is not None:\n",
    "        X_train_sparse = hstack([sites_train_sparse, features_train_sparse, \\\n",
    "                                 train_site_times_sparse, train_sites_sequence], dtype=float).tocsr()\n",
    "        X_test_sparse = hstack([sites_test_sparse, features_test_sparse, \\\n",
    "                                test_site_times_sparse, test_sites_sequence], dtype=float).tocsr()\n",
    "    else:\n",
    "        X_train_sparse = hstack([sites_train_sparse, features_train_sparse], dtype=float).tocsr()\n",
    "        X_test_sparse = hstack([sites_test_sparse, features_test_sparse], dtype=float).tocsr()\n",
    "        \n",
    "    X_train_sparse = hstack([X_train_sparse, train_duplicates_mask], dtype=float).tocsr()\n",
    "    X_test_sparse = hstack([X_test_sparse, test_duplicates_mask], dtype=float).tocsr() \n",
    "    return [X_train_sparse, X_test_sparse]\n",
    "\n",
    "\n",
    "def sparse_matrix_to_vw(X_sparse_full, sites_columns_num, vocabulary, y=None, weights=None, mark_duplicates=False):\n",
    "    sessions = {}\n",
    "    used = {}\n",
    "    prediction = {}\n",
    "    day_of_week = {}\n",
    "    start_hour = {}\n",
    "    daytime = {}\n",
    "    unique_sites = {}\n",
    "    top30_portion = {}\n",
    "    fb_portion = {}\n",
    "    youtube_portion = {}\n",
    "    bot30_portion = {}\n",
    "    site_longest_time = {}\n",
    "    session_timespan = {}\n",
    "    sitetimes = {}\n",
    "    sequence = {}\n",
    "    \n",
    "    X_sparse = X_sparse_full[:,:-1]\n",
    "    \n",
    "    add_features = True\n",
    "\n",
    "    for r, c in zip(X_sparse.nonzero()[0], X_sparse.nonzero()[1]):\n",
    "        if tuple([r,c]) not in used:\n",
    "            used[tuple([r, c])] = 1\n",
    "            if add_features:\n",
    "                if c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"prediction\") - 10:\n",
    "                    prediction[r] = \" |aprediction {}:{}\".format(int(X_sparse[r,c]), 100)\n",
    "                    #prediction[r] = \" |prediction:100 {}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"day_of_week\") - 10:\n",
    "                    day_of_week[r] = \" |bday_of_week {}\".format(int(X_sparse[r,c]))\n",
    "                    #day_of_week[r] = \" day_of_week:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"start_hour\") - 10:\n",
    "                    start_hour[r] = \" |chour_start {}\".format(int(X_sparse[r,c]))\n",
    "                    #start_hour[r] = \" start_hour:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"daytime\") - 10:\n",
    "                    daytime[r] = \" |dtime_of_day {}\".format(int(X_sparse[r,c]))\n",
    "                    #daytime[r] = \" daytime:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"session_timespan\") - 10:\n",
    "                    session_timespan[r] = \" |jsession_timespan time:{}\".format(int(X_sparse[r,c]))\n",
    "                    #session_timespan[r] = \" session_timespan:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"#unique_sites\") - 10:\n",
    "                    unique_sites[r] = \" unique_sites:{}\".format(int(X_sparse[r,c]))\n",
    "                    #unique_sites[r] = \" unique_sites:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"site_longest_time\") - 10:\n",
    "                    site_longest_time[r] = \" |hsite_longest_time {}:{}\".format(int(X_sparse[r,c]), 3)\n",
    "                    #site_longest_time[r] = \" site_longest_time:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"top30_portion\") - 10:\n",
    "                    top30_portion[r] = \" top30:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"bot30_portion\") - 10:\n",
    "                    bot30_portion[r] = \" bot30:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"fb_portion\") - 10:\n",
    "                    fb_portion[r] = \" facebook:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"youtube_portion\") - 10:\n",
    "                    youtube_portion[r] = \" youtube:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c >= X_sparse.shape[1] - 10:\n",
    "                    if r not in sequence:\n",
    "                        sequence[r] = \" |ksequence \" + \\\n",
    "                            ' '.join(filter(lambda a: a != \"0\", X_sparse[r,-10:].todense().astype(int).astype(str).tolist()[0]))\n",
    "                    continue\n",
    "                    \n",
    "            if c < sites_columns_num: #X_sparse.shape[1] - len(mycolumns): \n",
    "                if r in sessions:\n",
    "                    sessions[r] += \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "                else:\n",
    "                    if y is not None:\n",
    "                        if int(X_sparse_full[r, -1]) and mark_duplicates: # duplicate row indicator\n",
    "                            sessions[r] = str(y[r]) + ' 0.3' + ' |site' + \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "                        else:\n",
    "                            if weights is not None:\n",
    "                                sessions[r] = str(y[r]) + ' ' + str(weights[y[r]-1]) + ' |site' + \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "                            else:\n",
    "                                sessions[r] = str(y[r]) + ' |site' + \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "                    else:\n",
    "                        sessions[r] = ' |site' + \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "            elif c > X_sparse.shape[1] - sites_columns_num and c < X_sparse.shape[1] - 10:\n",
    "                if r in sitetimes:\n",
    "                    sitetimes[r] += \" {}:{}\".format(int(c - sites_columns_num - len(mycolumns)+1), float(X_sparse[r,c]))\n",
    "                else:\n",
    "                    sitetimes[r] = ' |isitetime' + \" {}:{}\".format(int(c - sites_columns_num - len(mycolumns)+1), float(X_sparse[r,c]))\n",
    "        \n",
    "    \n",
    "    return {\"sites\": sessions, \"prediction\": prediction, \"day_of_week\": day_of_week, \\\n",
    "                      \"start_hour\": start_hour, \"daytime\": daytime, \\\n",
    "                     \"unique_site\": unique_sites, \"top30_portion\": top30_portion, \\\n",
    "                    \"bot30_portion\": bot30_portion, \"fb_portion\": fb_portion, \\\n",
    "                    \"youtube_portion\": youtube_portion, \"site_longest_time\": site_longest_time, \\\n",
    "                    \"session_timespan\": session_timespan, \"sitetimes\": sitetimes, \"sequence\": sequence}\n",
    "\n",
    "\n",
    "\n",
    "def vw_to_file(sites, out_file, features={}, quiet=True):   \n",
    "    vw_writer = open(out_file, 'w')\n",
    "    final_vw = {}\n",
    "    gen_features = []\n",
    "    \n",
    "    if not quiet:\n",
    "        print \"Features:\", features.keys()\n",
    "        \n",
    "    for r in sorted(sites.keys()):\n",
    "        final_vw[r] = sites[r] #+ \" |features\"\n",
    "        for fname, feature in features.items():\n",
    "            if fname in [\"youtube_portion\", \"fb_portion\", \"top30_portion\", \"bot30_portion\", \\\n",
    "                                         \"unique_sites\"] and r in feature:\n",
    "                gen_features.append(feature[r])\n",
    "                continue\n",
    "            if r in feature:\n",
    "                final_vw[r] += feature[r]        \n",
    "            \n",
    "        if len(gen_features):\n",
    "            final_vw[r] += \" |features\"\n",
    "            for gf in gen_features:\n",
    "                final_vw[r] += gf\n",
    "        gen_features = []\n",
    "        \n",
    "        #if \"prediction\" in features and r in features[\"prediction\"]:\n",
    "            #final_vw[r] += features[\"prediction\"][r]\n",
    "        \n",
    "        vw_writer.write(final_vw[r] + \"\\n\")\n",
    "        \n",
    "    vw_writer.close()\n",
    "    \n",
    "    \n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_predictions(train_data, test_data):\n",
    "    test_row_users = {}\n",
    "    train_row_users = {}\n",
    "    \n",
    "    # Add predictions from the dataframe (based on uniquely visited site)\n",
    "    for r, v in test_data[[\"prediction\"]].iterrows():\n",
    "        if int(v) != 0:\n",
    "            test_row_users[r] = [int(v)]\n",
    "    \n",
    "    \n",
    "    #Identify sessions with identical sites sequence\n",
    "    train_index_full = list(train_data.index)\n",
    "    train_index_dup = list(train_data[train_data.duplicated(subset=['site' + str(c) for c in range(1,10+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]+[\"target\"]].index)\n",
    "\n",
    "    test_index_full = list(test_data.index)\n",
    "    test_index_dup = list(test_data[test_data.duplicated(subset=['site' + str(c) for c in range(1,10+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]].index)\n",
    "    \n",
    "    train_user_dup_rows_dict = {}\n",
    "    train_dup_row_users_dict = {}\n",
    "\n",
    "    test_dup_rows_dict = {}\n",
    "    \n",
    "\n",
    "    sites_cols = ['site' + str(c) for c in range(1,10+1)]\n",
    "    \n",
    "    for r, row in train_data.iloc[train_index_dup][sites_cols+[\"target\"]].iterrows():\n",
    "        if row[\"target\"] in train_user_dup_rows_dict:\n",
    "            if tuple(row[sites_cols]) in train_user_dup_rows_dict[row[\"target\"]]:\n",
    "                train_user_dup_rows_dict[row[\"target\"]][tuple(row[sites_cols])] += 1\n",
    "            else:\n",
    "                train_user_dup_rows_dict[row[\"target\"]][tuple(row[sites_cols])] = 1 \n",
    "        else:\n",
    "            train_user_dup_rows_dict[row[\"target\"]] = {tuple(row[sites_cols]): 1}\n",
    "\n",
    "        if tuple(row[sites_cols]) in train_dup_row_users_dict:\n",
    "            train_dup_row_users_dict[tuple(row[sites_cols])].add(row[\"target\"])\n",
    "        else:\n",
    "            train_dup_row_users_dict[tuple(row[sites_cols])] = set([row[\"target\"]])\n",
    "\n",
    "    for r, row in test_data.iloc[test_index_dup][sites_cols].iterrows():  \n",
    "        if tuple(row[sites_cols]) in test_dup_rows_dict:\n",
    "            test_dup_rows_dict[tuple(row[sites_cols])] += 1\n",
    "        else:\n",
    "            test_dup_rows_dict[tuple(row[sites_cols])] = 1\n",
    "\n",
    "        if tuple(row[sites_cols]) in train_dup_row_users_dict:\n",
    "            if r in test_row_users:\n",
    "                pass #don't overwright predictions from the dataframe\n",
    "                #test_row_users[r] += train_dup_row_users_dict[tuple(row[sites_cols])]\n",
    "            else:\n",
    "                test_row_users[r] = train_dup_row_users_dict[tuple(row[sites_cols])]\n",
    "        \n",
    "    # Find users who visited 2 websites\n",
    "    site_pairs = {}\n",
    "    for r, row in train_data[sites_cols+[\"target\"]].iterrows():\n",
    "        unique_sites = Counter(row).keys()\n",
    "        if 0 in unique_sites:\n",
    "            del unique_sites[unique_sites.index(0)]\n",
    "        if len(unique_sites) > 1:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 2):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    site_pairs[tuple(subset)].add(row[\"target\"])\n",
    "                else:\n",
    "                    site_pairs[tuple(subset)] = set([row[\"target\"]])\n",
    "        if len(unique_sites) > 2:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 3):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    site_pairs[tuple(subset)].add(row[\"target\"])\n",
    "                else:\n",
    "                    site_pairs[tuple(subset)] = set([row[\"target\"]])\n",
    "        if len(unique_sites) > 3:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 4):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    site_pairs[tuple(subset)].add(row[\"target\"])\n",
    "                else:\n",
    "                    site_pairs[tuple(subset)] = set([row[\"target\"]])\n",
    "    \n",
    "    \n",
    "    # Add predictions to test data based on 2 visited websites\n",
    "    for r, row in test_data[sites_cols].iterrows():\n",
    "        unique_sites = Counter(row).keys()\n",
    "        if len(unique_sites) > 1:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 2):\n",
    "                if subset in site_pairs:\n",
    "                    if r in test_row_users:\n",
    "                        pass\n",
    "                    else:\n",
    "                        test_row_users[r] = list(site_pairs[subset])\n",
    "        if len(unique_sites) > 2:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 3):\n",
    "                if subset in site_pairs:\n",
    "                    if r in test_row_users:\n",
    "                        pass\n",
    "                    else:\n",
    "                        test_row_users[r] = list(site_pairs[subset])\n",
    "        if len(unique_sites) > 3:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 4):\n",
    "                if subset in site_pairs:\n",
    "                    if r in test_row_users:\n",
    "                        pass\n",
    "                    else:\n",
    "                        test_row_users[r] = list(site_pairs[subset])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return test_row_users, site_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150485x24052 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 546037 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_data = pd.read_csv('full_train_w8.csv')\n",
    "test_data = pd.read_csv('full_test.csv')\n",
    "\n",
    "train_site_sequence = csr_matrix(train_data[['site' + str(c) for c in range(1,10+1)]].as_matrix(), dtype=int)\n",
    "test_site_sequence = csr_matrix(test_data[['site' + str(c) for c in range(1,10+1)]].as_matrix(), dtype=int)\n",
    "\n",
    "#test_predictions = calc_predictions(train_data, test_data)\n",
    "\n",
    "# Additionally, let's calculate the percentage of session time spent by every site in session\n",
    "site_times = calc_site_times_portions(train_data, test_data)\n",
    "\n",
    "# Convert site times to sparse format\n",
    "site_times_sparse = site_times_to_sparse(site_times)\n",
    "train_site_times_sparse = site_times_sparse[:len(train_data)]\n",
    "test_site_times_sparse = site_times_sparse[len(train_data):]\n",
    "site_times_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_test_df = pd.concat([train_data, test_data])\n",
    "train_index_full = list(train_data.index)\n",
    "session_length = 10\n",
    "train_index_dup = list(train_data[train_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                       [['site' + str(c) for c in range(1,10+1)]+[\"target\"]].index)\n",
    "test_index_full = list(test_data.index)\n",
    "test_index_dup = list(test_data[test_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                       [['site' + str(c) for c in range(1,10+1)]].index)\n",
    "train_duplicates_mask = np.transpose([np.in1d(train_index_full, train_index_dup).astype(int)])\n",
    "test_duplicates_mask = np.transpose([np.in1d(test_index_full, test_index_dup).astype(int)])\n",
    "\n",
    "y = train_data[\"target\"]\n",
    "\n",
    "train_test_df_sites = train_test_df[['site' + str(c) for c in range(1,10+1)]].fillna(0).astype('int')\n",
    "train_test_df_sites_array = [\" \".join([\"s_\"+str(s) for s in train_test_df_sites.as_matrix()[i] if int(s) != 0]) \\\n",
    "                                                              for i in range(train_test_df_sites.shape[0])]\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer=str.split, max_df=0.95, ngram_range=(1,3)).fit(train_test_df_sites_array) #TfidfVectorizer()\n",
    "X_train_test_sparse = tfidf.transform(train_test_df_sites_array)\n",
    "#X_train_test_sparse = TruncatedSVD(n_components=10000).fit_transform(X_train_test_sparse)\n",
    "\n",
    "X_train_sparse = X_train_test_sparse[:len(train_data)]\n",
    "X_test_sparse = X_train_test_sparse[len(train_data):]\n",
    "\n",
    "class_encoder = LabelEncoder().fit(y.astype('str'))\n",
    "y_for_vw = class_encoder.transform(y.astype('str')) + 1\n",
    "\n",
    "sites_columns_num = X_train_test_sparse.shape[1]\n",
    "inv_vocabulary = {v: int(re.search(\"s_(\\d+)$\", k).group(1)) for k, v in tfidf.vocabulary_.iteritems()}\n",
    "\n",
    "y_weights = [(np.sum(Counter(y_for_vw).values()) - v + min((Counter(y_for_vw).values())))/ \\\n",
    "            float(np.sum(Counter(y_for_vw).values())) for k, v in sorted(Counter(y_for_vw).items())]\n",
    "\n",
    "#y_weights = [round(np.max(Counter(y_for_vw).values())/float(v), 3) for k, v in sorted(Counter(y_for_vw).items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 548 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X_train_sparse, X_test_sparse, y, y_for_vw, sites_columns_num, class_encoder, tfidf, train_duplicates_mask, test_duplicates_mask = \\\n",
    "    #sites_to_sparse_tfidf(train_data, test_data, \"target\", 10, label_encoder=LabelEncoder())\n",
    "\n",
    "mycolumns = [label for label in test_data[range(20, test_data.shape[1])]]\n",
    "\n",
    "train_features, test_features = features_to_sparse(train_data, test_data, mycolumns)\n",
    "\n",
    "X_train_sparse, X_test_sparse = combine_sites_features_sparse(X_train_sparse, train_features, \\\n",
    "                                                             X_test_sparse, test_features, \\\n",
    "                                                              train_duplicates_mask, test_duplicates_mask,\n",
    "                                                              train_site_times_sparse, test_site_times_sparse, \\\n",
    "                                                             train_site_sequence, test_site_sequence)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_sparse, y_for_vw, test_size=0.3, stratify=y_for_vw)\n",
    "\n",
    "y_train_weights = [(np.sum(Counter(y_train).values()) - v + min((Counter(y_train).values()))) / \\\n",
    "                   float(np.sum(Counter(y_train).values())) for k, v in sorted(Counter(y_train).items())]\n",
    "\n",
    "#y_train_weights = [round(np.max(Counter(y_train).values())/float(v), 3) for k, v in sorted(Counter(y_train).items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 50s, sys: 1.32 s, total: 11min 52s\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_part_vw = sparse_matrix_to_vw(X_train, sites_columns_num, inv_vocabulary, y_train, weights=y_train_weights)\n",
    "valid_vw = sparse_matrix_to_vw(X_valid, sites_columns_num, inv_vocabulary, y_valid)\n",
    "train_vw = sparse_matrix_to_vw(X_train_sparse, sites_columns_num, inv_vocabulary, y_for_vw, weights=y_weights)\n",
    "test_vw = sparse_matrix_to_vw(X_test_sparse, sites_columns_num, inv_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler and Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a: prediction\n",
    "- b: day_of_week \n",
    "- c: hour_start\n",
    "- d: time_of_day\n",
    "- e:\n",
    "- f: features\n",
    "- g: \n",
    "- h: site_longest_time\n",
    "- i: sitetimes\n",
    "- j: session_timespan\n",
    "- k: sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['youtube_portion', 'sequence', 'sitetimes', 'fb_portion', 'start_hour', 'prediction', 'daytime', 'day_of_week']\n",
      "Features: ['youtube_portion', 'sequence', 'sitetimes', 'fb_portion', 'start_hour', 'prediction', 'daytime', 'day_of_week']\n",
      "Features: ['youtube_portion', 'sequence', 'sitetimes', 'fb_portion', 'start_hour', 'prediction', 'daytime', 'day_of_week']\n",
      "Features: ['youtube_portion', 'sequence', 'sitetimes', 'fb_portion', 'start_hour', 'prediction', 'daytime', 'day_of_week']\n"
     ]
    }
   ],
   "source": [
    "folder = 'vw/'\n",
    "handler = '_idf_w8'\n",
    "\n",
    "keys = ['day_of_week', 'daytime', 'prediction', 'start_hour', 'youtube_portion', 'fb_portion', 'sitetimes', 'sequence']\n",
    "\n",
    "vw_to_file(train_part_vw[\"sites\"], folder+'train_part'+handler+'.vw', features={x:train_part_vw[x] for x in keys}, quiet=False)\n",
    "vw_to_file(valid_vw[\"sites\"], folder+'valid'+handler+'.vw', features={x:valid_vw[x] for x in keys}, quiet=False)\n",
    "vw_to_file(train_vw[\"sites\"], folder+'train'+handler+'.vw', features={x:train_vw[x] for x in keys}, quiet=False)\n",
    "vw_to_file(test_vw[\"sites\"], folder+'test'+handler+'.vw', features={x:test_vw[x] for x in keys}, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(folder+'train_part'+handler+'.vw')\n",
    "train_part_file = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(folder+'train'+handler+'.vw')\n",
    "train_file = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(folder+'valid'+handler+'.vw')\n",
    "valid_file = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(folder+'test'+handler+'.vw')\n",
    "test_file = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: sd sb \n",
      "creating cubic features for triples: sbc \n",
      "using namespaces beginning with: s b c d a \n",
      "using l1 regularization = 1e-11\n",
      "using l2 regularization = 1e-11\n",
      "final_regressor = vw/initial_model_idf_w8.model\n",
      "Num weight bits = 29\n",
      "learning rate = 0.541695\n",
      "initial_t = 0.00233705\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 0.9\n",
      "creating cache_file = vw/train_part_idf_w8.vw.cache\n",
      "Reading datafile = vw/train_part_idf_w8.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      330        1       32\n",
      "1.000000 1.000000            2            2.0      108      330       28\n",
      "1.000000 1.000000            4            4.0      214      330       28\n",
      "1.000000 1.000000            8            8.0      386      138       20\n",
      "1.000000 1.000000           16           16.0      237      386       17\n",
      "0.937500 0.875000           32           32.0      386      386       25\n",
      "0.937500 0.937500           64           64.0       64      386       20\n",
      "0.914062 0.890625          128          128.0      156       64       12\n",
      "0.925781 0.937500          256          256.0      328      469       24\n",
      "0.896484 0.867188          512          512.0      138      386       28\n",
      "0.882812 0.869141         1024         1024.0      550      386        8\n",
      "0.857910 0.833008         2048         2048.0      354       12       12\n",
      "0.821533 0.785156         4096         4096.0      444      438       36\n",
      "0.776367 0.731201         8192         8192.0      257      223       33\n",
      "0.720032 0.663696        16384        16384.0      529       18       20\n",
      "0.656616 0.593201        32768        32768.0       12       12       16\n",
      "0.585693 0.514771        65536        65536.0      469      469       40\n",
      "0.525889 0.525889       131072       131072.0      386      426       24 h\n",
      "0.480584 0.435281       262144       262144.0      530      530       13 h\n",
      "0.450300 0.420017       524288       524288.0      256      256       36 h\n",
      "0.433056 0.415811      1048576      1048576.0      420      420       24 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 68864\n",
      "passes used = 19\n",
      "weighted example sum = 1308416.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.414717 h\n",
      "total feature number = 36245635\n",
      "CPU times: user 2min 50s, sys: 19.4 s, total: 3min 9s\n",
      "Wall time: 1h 44min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa=550 -d {folder}train_part{handler}.vw \\\n",
    "-f {folder}initial_model{handler}.model -b 29 -c -k \\\n",
    "--passes=30 --decay_learning_rate 0.9 --initial_t 0.002337045080352835 \\\n",
    "-l 0.5416950450219994 \\\n",
    "--power_t 0.5 --loss_function='logistic' --l1 1e-11 --l2 1e-11 \\\n",
    "-q \"sd\" -q \"sb\" --cubic=\"sbc\"  \\\n",
    "--keep \"s\" --keep \"b\" --keep \"c\" --keep \"d\" --keep \"a\" \\\n",
    "--stage_poly --batch_sz {len(train_part_file)/6} --batch_sz_no_doubling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights experiment: before: average loss = 0.415629 h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average loss = 0.406958 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 324 ms, total: 2.1 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i {folder}initial_model{handler}.model  -t -d {folder}valid{handler}.vw \\\n",
    "-p {folder}vw_valid_pred{handler}.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56722471259110174"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_valid_pred = pd.read_csv(folder+'vw_valid_pred'+handler+'.csv', header=None)\n",
    "accuracy_score(y_valid, vw_valid_pred.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weiths1: 0.58872320312261761\n",
    "\n",
    "valid: 0.56661482633488858 -q \"sd\" -q \"sb\" --cubic=\"sbc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_weights = [1.0] * len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_train_weights = [1.0] * len(y_train)\n",
    "M = confusion_matrix(y_valid, vw_valid_pred.values)\n",
    "M_normalized = M.astype('float') / M.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "for (t,f), value in np.ndenumerate(M_normalized):\n",
    "    if t != f and value > 0:\n",
    "        #y_train_weights[t] += value\n",
    "        y_train_weights[f] -= value\n",
    "        if y_train_weights[f] < 0:\n",
    "            y_train_weights[f] = 0.001\n",
    "        y_train_weights[t] = round(y_train_weights[t], 3)\n",
    "        y_train_weights[f] = round(y_train_weights[f], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.928,\n",
       " 0.462,\n",
       " 0.842,\n",
       " 0.281,\n",
       " 0.074,\n",
       " 0.583,\n",
       " 0.952,\n",
       " 0.419,\n",
       " 0.635,\n",
       " 0.372,\n",
       " 0.609,\n",
       " 0.079,\n",
       " 0.665,\n",
       " 0.118,\n",
       " 0.592,\n",
       " 0.645,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 0.559,\n",
       " 0.001,\n",
       " 0.7,\n",
       " 0.396,\n",
       " 0.415,\n",
       " 0.414,\n",
       " 0.876,\n",
       " 0.889,\n",
       " 0.215,\n",
       " 0.797,\n",
       " 0.762,\n",
       " 0.86,\n",
       " 0.001,\n",
       " 0.633,\n",
       " 0.396,\n",
       " 0.398,\n",
       " 0.001,\n",
       " 0.487,\n",
       " 0.717,\n",
       " 0.001,\n",
       " 0.599,\n",
       " 0.515,\n",
       " 0.308,\n",
       " 0.934,\n",
       " 0.788,\n",
       " 0.899,\n",
       " 0.765,\n",
       " 0.854,\n",
       " 0.836,\n",
       " 0.556,\n",
       " 0.919,\n",
       " 0.001,\n",
       " 0.845,\n",
       " 0.801,\n",
       " 0.001,\n",
       " 0.669,\n",
       " 0.263,\n",
       " 0.021,\n",
       " 0.009,\n",
       " 0.815,\n",
       " 0.211,\n",
       " 0.674,\n",
       " 0.133,\n",
       " 0.597,\n",
       " 0.914,\n",
       " 0.43,\n",
       " 0.669,\n",
       " 0.49,\n",
       " 0.264,\n",
       " 0.353,\n",
       " 1.0,\n",
       " 0.684,\n",
       " 0.822,\n",
       " 0.222,\n",
       " 0.188,\n",
       " 0.618,\n",
       " 0.9,\n",
       " 0.907,\n",
       " 0.985,\n",
       " 0.958,\n",
       " 0.966,\n",
       " 0.686,\n",
       " 0.475,\n",
       " 0.057,\n",
       " 0.383,\n",
       " 0.619,\n",
       " 0.872,\n",
       " 0.582,\n",
       " 0.196,\n",
       " 0.124,\n",
       " 0.593,\n",
       " 0.064,\n",
       " 0.983,\n",
       " 0.414,\n",
       " 0.679,\n",
       " 0.796,\n",
       " 0.552,\n",
       " 0.782,\n",
       " 0.232,\n",
       " 0.001,\n",
       " 1.0,\n",
       " 0.508,\n",
       " 0.078,\n",
       " 0.231,\n",
       " 0.467,\n",
       " 0.842,\n",
       " 0.727,\n",
       " 0.674,\n",
       " 0.44,\n",
       " 0.263,\n",
       " 0.54,\n",
       " 0.186,\n",
       " 0.335,\n",
       " 0.439,\n",
       " 0.108,\n",
       " 0.596,\n",
       " 0.926,\n",
       " 0.926,\n",
       " 0.4,\n",
       " 0.07,\n",
       " 0.868,\n",
       " 0.658,\n",
       " 0.719,\n",
       " 0.732,\n",
       " 0.516,\n",
       " 0.33,\n",
       " 0.365,\n",
       " 0.166,\n",
       " 0.46,\n",
       " 0.634,\n",
       " 0.926,\n",
       " 0.129,\n",
       " 0.72,\n",
       " 0.553,\n",
       " 0.434,\n",
       " 0.22,\n",
       " 0.217,\n",
       " 0.537,\n",
       " 0.986,\n",
       " 0.001,\n",
       " 0.088,\n",
       " 0.704,\n",
       " 0.486,\n",
       " 0.812,\n",
       " 0.755,\n",
       " 0.973,\n",
       " 0.001,\n",
       " 0.654,\n",
       " 0.001,\n",
       " 0.001,\n",
       " 0.61,\n",
       " 0.001,\n",
       " 0.769,\n",
       " 0.954,\n",
       " 0.558,\n",
       " 0.122,\n",
       " 0.125,\n",
       " 0.371,\n",
       " 0.405,\n",
       " 0.849,\n",
       " 0.664,\n",
       " 0.086,\n",
       " 0.501,\n",
       " 0.778,\n",
       " 0.917,\n",
       " 0.001,\n",
       " 0.603,\n",
       " 0.981,\n",
       " 0.001,\n",
       " 0.071,\n",
       " 0.25,\n",
       " 0.333,\n",
       " 0.001,\n",
       " 1.0,\n",
       " 0.001,\n",
       " 0.823,\n",
       " 0.631,\n",
       " 0.465,\n",
       " 0.698,\n",
       " 0.516,\n",
       " 0.001,\n",
       " 0.565,\n",
       " 0.243,\n",
       " 0.448,\n",
       " 0.828,\n",
       " 0.894,\n",
       " 0.635,\n",
       " 0.387,\n",
       " 0.401,\n",
       " 0.173,\n",
       " 0.231,\n",
       " 0.438,\n",
       " 0.645,\n",
       " 0.256,\n",
       " 0.806,\n",
       " 0.839,\n",
       " 0.995,\n",
       " 0.128,\n",
       " 0.465,\n",
       " 0.895,\n",
       " 0.426,\n",
       " 0.417,\n",
       " 0.898,\n",
       " 0.841,\n",
       " 0.919,\n",
       " 0.636,\n",
       " 0.827,\n",
       " 0.888,\n",
       " 0.299,\n",
       " 0.618,\n",
       " 0.651,\n",
       " 0.846,\n",
       " 0.558,\n",
       " 0.754,\n",
       " 0.921,\n",
       " 0.001,\n",
       " 0.231,\n",
       " 0.379,\n",
       " 0.886,\n",
       " 0.623,\n",
       " 0.74,\n",
       " 0.761,\n",
       " 0.739,\n",
       " 0.874,\n",
       " 0.001,\n",
       " 0.746,\n",
       " 0.792,\n",
       " 0.001,\n",
       " 0.001,\n",
       " 0.793,\n",
       " 0.358,\n",
       " 0.869,\n",
       " 0.001,\n",
       " 0.928,\n",
       " 0.773,\n",
       " 0.001,\n",
       " 1.0,\n",
       " 0.179,\n",
       " 1.0,\n",
       " 0.875,\n",
       " 0.001,\n",
       " 0.807,\n",
       " 0.4,\n",
       " 0.001,\n",
       " 0.178,\n",
       " 0.865,\n",
       " 0.501,\n",
       " 0.166,\n",
       " 0.567,\n",
       " 0.889,\n",
       " 0.293,\n",
       " 0.594,\n",
       " 0.164,\n",
       " 0.001,\n",
       " 0.871,\n",
       " 0.975,\n",
       " 0.678,\n",
       " 0.762,\n",
       " 0.633,\n",
       " 0.745,\n",
       " 0.495,\n",
       " 0.766,\n",
       " 0.621,\n",
       " 0.609,\n",
       " 0.529,\n",
       " 0.784,\n",
       " 0.706,\n",
       " 0.794,\n",
       " 0.001,\n",
       " 0.836,\n",
       " 0.472,\n",
       " 0.409,\n",
       " 0.432,\n",
       " 0.917,\n",
       " 0.386,\n",
       " 0.165,\n",
       " 0.938,\n",
       " 0.669,\n",
       " 0.444,\n",
       " 0.665,\n",
       " 0.711,\n",
       " 0.601,\n",
       " 0.865,\n",
       " 0.001,\n",
       " 0.001,\n",
       " 0.903,\n",
       " 0.744,\n",
       " 0.17,\n",
       " 0.208,\n",
       " 0.92,\n",
       " 0.691,\n",
       " 0.323,\n",
       " 1.0,\n",
       " 0.464,\n",
       " 0.946,\n",
       " 0.283,\n",
       " 0.679,\n",
       " 0.343,\n",
       " 0.176,\n",
       " 0.542,\n",
       " 1.0,\n",
       " 0.364,\n",
       " 0.435,\n",
       " 0.894,\n",
       " 0.799,\n",
       " 0.585,\n",
       " 0.383,\n",
       " 0.95,\n",
       " 0.165,\n",
       " 1.0,\n",
       " 0.945,\n",
       " 0.944,\n",
       " 0.578,\n",
       " 0.45,\n",
       " 0.565,\n",
       " 0.785,\n",
       " 0.259,\n",
       " 0.893,\n",
       " 0.001,\n",
       " 0.761,\n",
       " 0.947,\n",
       " 0.623,\n",
       " 0.657,\n",
       " 0.543,\n",
       " 0.73,\n",
       " 0.572,\n",
       " 0.701,\n",
       " 0.52,\n",
       " 0.001,\n",
       " 0.036,\n",
       " 0.797,\n",
       " 0.074,\n",
       " 0.854,\n",
       " 0.257,\n",
       " 0.196,\n",
       " 0.57,\n",
       " 0.412,\n",
       " 0.001,\n",
       " 0.001,\n",
       " 0.598,\n",
       " 0.381,\n",
       " 0.223,\n",
       " 0.844,\n",
       " 0.934,\n",
       " 0.088,\n",
       " 0.865,\n",
       " 0.239,\n",
       " 0.666,\n",
       " 0.415,\n",
       " 0.749,\n",
       " 0.224,\n",
       " 0.764,\n",
       " 0.633,\n",
       " 0.109,\n",
       " 0.559,\n",
       " 1.0,\n",
       " 0.971,\n",
       " 0.424,\n",
       " 0.045,\n",
       " 0.433,\n",
       " 0.859,\n",
       " 0.538,\n",
       " 0.833,\n",
       " 0.862,\n",
       " 0.502,\n",
       " 0.001,\n",
       " 0.448,\n",
       " 0.819,\n",
       " 0.212,\n",
       " 0.509,\n",
       " 0.572,\n",
       " 0.617,\n",
       " 0.965,\n",
       " 0.001,\n",
       " 0.625,\n",
       " 0.454,\n",
       " 0.512,\n",
       " 0.857,\n",
       " 0.064,\n",
       " 0.741,\n",
       " 0.395,\n",
       " 1.0,\n",
       " 0.035,\n",
       " 0.11,\n",
       " 0.736,\n",
       " 0.535,\n",
       " 0.874,\n",
       " 0.294,\n",
       " 0.736,\n",
       " 0.873,\n",
       " 0.484,\n",
       " 0.621,\n",
       " 0.604,\n",
       " 0.723,\n",
       " 0.363,\n",
       " 0.606,\n",
       " 0.887,\n",
       " 0.197,\n",
       " 0.825,\n",
       " 0.951,\n",
       " 0.898,\n",
       " 0.288,\n",
       " 0.633,\n",
       " 0.389,\n",
       " 0.809,\n",
       " 1.0,\n",
       " 0.925,\n",
       " 0.166,\n",
       " 0.877,\n",
       " 0.571,\n",
       " 0.46,\n",
       " 0.938,\n",
       " 0.001,\n",
       " 0.517,\n",
       " 0.835,\n",
       " 0.944,\n",
       " 0.565,\n",
       " 0.919,\n",
       " 0.001,\n",
       " 0.775,\n",
       " 0.78,\n",
       " 0.001,\n",
       " 0.791,\n",
       " 0.573,\n",
       " 0.405,\n",
       " 0.593,\n",
       " 0.001,\n",
       " 0.001,\n",
       " 0.531,\n",
       " 0.397,\n",
       " 0.801,\n",
       " 0.216,\n",
       " 0.898,\n",
       " 0.822,\n",
       " 0.909,\n",
       " 0.617,\n",
       " 0.551,\n",
       " 0.875,\n",
       " 0.167,\n",
       " 0.001,\n",
       " 0.861,\n",
       " 0.584,\n",
       " 0.529,\n",
       " 0.05,\n",
       " 0.668,\n",
       " 0.418,\n",
       " 0.79,\n",
       " 0.056,\n",
       " 0.705,\n",
       " 0.681,\n",
       " 0.802,\n",
       " 0.224,\n",
       " 0.482,\n",
       " 0.065,\n",
       " 0.786,\n",
       " 0.989,\n",
       " 0.269,\n",
       " 0.892,\n",
       " 0.373,\n",
       " 1.0,\n",
       " 0.316,\n",
       " 0.561,\n",
       " 0.498,\n",
       " 0.181,\n",
       " 0.558,\n",
       " 0.67,\n",
       " 0.912,\n",
       " 0.572,\n",
       " 0.659,\n",
       " 0.993,\n",
       " 0.169,\n",
       " 0.798,\n",
       " 0.001,\n",
       " 0.469,\n",
       " 0.385,\n",
       " 0.723,\n",
       " 0.109,\n",
       " 0.364,\n",
       " 0.001,\n",
       " 0.562,\n",
       " 0.891,\n",
       " 0.573,\n",
       " 0.794,\n",
       " 0.874,\n",
       " 0.606,\n",
       " 0.991,\n",
       " 0.615,\n",
       " 0.646,\n",
       " 0.342,\n",
       " 0.708,\n",
       " 0.344,\n",
       " 0.612,\n",
       " 0.299,\n",
       " 0.833,\n",
       " 0.725,\n",
       " 0.165,\n",
       " 0.796,\n",
       " 0.65,\n",
       " 0.356,\n",
       " 0.461,\n",
       " 1.0,\n",
       " 0.32,\n",
       " 0.77,\n",
       " 0.775,\n",
       " 0.001,\n",
       " 0.001,\n",
       " 0.752,\n",
       " 0.879,\n",
       " 0.968,\n",
       " 0.567,\n",
       " 0.73,\n",
       " 0.954,\n",
       " 0.001,\n",
       " 0.888,\n",
       " 0.583,\n",
       " 0.281,\n",
       " 0.45,\n",
       " 0.656,\n",
       " 0.477,\n",
       " 0.656,\n",
       " 0.454,\n",
       " 0.717,\n",
       " 0.001,\n",
       " 0.991,\n",
       " 0.245,\n",
       " 0.676,\n",
       " 0.306,\n",
       " 0.736,\n",
       " 0.933,\n",
       " 0.221,\n",
       " 0.509,\n",
       " 0.132,\n",
       " 0.866,\n",
       " 0.534,\n",
       " 0.367,\n",
       " 0.019,\n",
       " 0.572,\n",
       " 0.795,\n",
       " 0.766,\n",
       " 0.377,\n",
       " 0.686,\n",
       " 0.001,\n",
       " 0.873,\n",
       " 0.437,\n",
       " 0.581,\n",
       " 0.494,\n",
       " 0.143,\n",
       " 0.133,\n",
       " 0.442,\n",
       " 0.457,\n",
       " 0.341,\n",
       " 0.582,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainvw = open(folder+'train'+handler+'.vw').readlines()\n",
    "np.random.shuffle(trainvw)\n",
    "with open(folder+'train'+handler+'.vw', \"wb\") as f:\n",
    "    for item in trainvw:\n",
    "        f.write(\"%s\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: sd sb \n",
      "creating cubic features for triples: sbc \n",
      "using namespaces beginning with: s b c d a \n",
      "using l1 regularization = 1e-11\n",
      "using l2 regularization = 1e-11\n",
      "final_regressor = vw/initial_model_idf_w8.model\n",
      "Num weight bits = 29\n",
      "learning rate = 0.541695\n",
      "initial_t = 0.00233705\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 0.9\n",
      "creating cache_file = vw/train_idf_w8.vw.cache\n",
      "Reading datafile = vw/train_idf_w8.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            2            2.0      271       67       28\n",
      "1.000000 1.000000            4            4.0      328       67       41\n",
      "1.000000 1.000000            8            8.0      249      271       20\n",
      "1.000000 1.000000           17           16.9      165      249       24\n",
      "1.000000 1.000000           35           34.8      274       63       16\n",
      "0.971588 0.943182           70           69.6       13      150       20\n",
      "0.971996 0.972398          141          140.3      420       32       44\n",
      "0.937175 0.902579          283          281.4      488      392       40\n",
      "0.900464 0.863878          567          563.8      110      243       20\n",
      "0.868102 0.835795         1135         1128.6      531      426       28\n",
      "0.844437 0.820783         2270         2257.8      336      386       32\n",
      "0.806789 0.769153         4541         4516.2      249      386       24\n",
      "0.766716 0.726646         9083         9032.9      227      318       24\n",
      "0.712302 0.657891        18166        18066.3      138      317       32\n",
      "0.647666 0.583032        36332        36133.0      533      418       24\n",
      "0.576739 0.505813        72669        72266.6       35      372       20\n",
      "0.511930 0.511930       145338       144534.0      452      452       16 h\n",
      "0.465440 0.418956       290681       289068.3      223      223       40 h\n",
      "0.433867 0.402292       581363       578137.0      271      271       40 h\n",
      "0.415550 0.397233      1162727      1156274.8       12       12       16 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 98378\n",
      "passes used = 19\n",
      "weighted example sum = 1858808.960410\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.394155 h\n",
      "total feature number = 51807661\n",
      "CPU times: user 3min 14s, sys: 21.4 s, total: 3min 35s\n",
      "Wall time: 2h 29min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa=550 -d {folder}train{handler}.vw \\\n",
    "-f {folder}initial_model{handler}.model -b 29 -c -k \\\n",
    "--passes=30 --decay_learning_rate 0.9 --initial_t 0.002337045080352835 \\\n",
    "-l 0.5416950450219994 \\\n",
    "--power_t 0.5 --loss_function='logistic' --l1 1e-11 --l2 1e-11 \\\n",
    "-q \"sd\" -q \"sb\" --cubic=\"sbc\"  \\\n",
    "--keep \"s\" --keep \"b\" --keep \"c\" --keep \"d\" --keep \"a\" \\\n",
    "--stage_poly --batch_sz {len(train_part_file)/6} --batch_sz_no_doubling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average loss = 0.396340 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 260 ms, total: 1.5 s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Prediction on VALID\n",
    "!vw -i {folder}initial_model{handler}.model  -t -d {folder}valid{handler}.vw \\\n",
    "-p {folder}vw_valid_pred{handler}.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81660720275668586"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_valid_pred = pd.read_csv(folder+'vw_valid_pred'+handler+'.csv', header=None)\n",
    "accuracy_score(y_valid, vw_valid_pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: sd sb \n",
      "creating cubic features for triples: sbc \n",
      "only testing\n",
      "predictions = vw/vw_test_pred_idf_w8.csv\n",
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = vw/test_idf_w8.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0  unknown      469       10\n",
      "1.000000 1.000000            2            2.0  unknown      517       44\n",
      "1.000000 1.000000            4            4.0  unknown      168       12\n",
      "1.000000 1.000000            8            8.0  unknown       24       52\n",
      "1.000000 1.000000           16           16.0  unknown      328       28\n",
      "1.000000 1.000000           32           32.0  unknown      460       48\n",
      "1.000000 1.000000           64           64.0  unknown      514       49\n",
      "1.000000 1.000000          128          128.0  unknown      426       59\n",
      "1.000000 1.000000          256          256.0  unknown      388       11\n",
      "1.000000 1.000000          512          512.0  unknown       97       52\n",
      "1.000000 1.000000         1024         1024.0  unknown      545       45\n",
      "1.000000 1.000000         2048         2048.0  unknown      317       44\n",
      "1.000000 1.000000         4096         4096.0  unknown       10       57\n",
      "1.000000 1.000000         8192         8192.0  unknown      306       49\n",
      "1.000000 1.000000        16384        16384.0  unknown       73       24\n",
      "1.000000 1.000000        32768        32768.0  unknown      313       55\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 41177\n",
      "passes used = 1\n",
      "weighted example sum = 41177.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 1.000000\n",
      "total feature number = 1605732\n",
      "CPU times: user 1.57 s, sys: 208 ms, total: 1.78 s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prediction on TEST!\n",
    "!vw -i {folder}initial_model{handler}.model -t -d {folder}test{handler}.vw \\\n",
    "-p {folder}vw_test_pred{handler}.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw_pred = pd.read_csv(folder+'vw_test_pred'+handler+'.csv', header=None)\n",
    "vw_subm = class_encoder.inverse_transform(vw_pred-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(vw_subm,\n",
    "                         folder+'27vw_submission'+handler+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score: 0.57276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://vw/27vw_submission_idf_w8.csv [Content-Type=text/csv]...\n",
      "/ [1 files][419.8 KiB/419.8 KiB]                                                \n",
      "Operation completed over 1 objects/419.8 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {folder}27vw_submission{handler}.csv gs://smartandnimble/identifyme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.867574166625138, 'initial_t': 0.2776239270739265, 'l': 0.0434341264970275, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 5.248698547405331e-09, 'loss_function': 'squared', 'l1': 1.541908660931064e-08, 'type': 'ect'}\n",
      "Accuracy: 0.412161131949 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.4380919176573933, 'initial_t': 0.08681977356754463, 'l': 0.2790283913381128, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 1.4656938601889154e-08, 'loss_function': 'hinge', 'l1': 2.5435275529929987e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.528496935322 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.10244638809961329, 'initial_t': 1.0419999810170089, 'l': 0.07462834369874273, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 1.1388346589835574e-06, 'loss_function': 'squared', 'l1': 5.803833976036988e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.289513005824 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.16808058541633378, 'initial_t': 0.005555321314757138, 'l': 0.04444752645218835, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 1.1965405145568205e-05, 'loss_function': 'squared', 'l1': 1.4518447803551378e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.495807031989 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.4709268106303166, 'initial_t': 0.00018232830908504607, 'l': 1.7237113551377938, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 1.1179779226251723e-07, 'loss_function': 'logistic', 'l1': 9.004914465343011e-09, 'type': 'ect'}\n",
      "Accuracy: 0.447930960876 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.667221282158522, 'initial_t': 0.0006975129144123112, 'l': 0.32060741849890867, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 2.5570817227072065e-08, 'loss_function': 'hinge', 'l1': 2.1057562361303843e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.513646204983 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.7858665585312469, 'initial_t': 0.00042344201060401116, 'l': 1.4730057038030036, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 5.836736355475676e-05, 'loss_function': 'logistic', 'l1': 2.1203383742965224e-05, 'type': 'ect'}\n",
      "Accuracy: 0.168481078279 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.028318987790783814, 'initial_t': 0.030032169493808977, 'l': 0.5339022525190165, 'q': 'sb', 'power_t': 0.5, 'noconstant': True, 'l2': 1.2323338977249126e-08, 'loss_function': 'logistic', 'l1': 1.3026316879961454e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.476626109231 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.803828413283501, 'initial_t': 7.251986425318597e-05, 'l': 0.010738114909829934, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 8.293060327461105e-05, 'loss_function': 'hinge', 'l1': 1.017453078652902e-05, 'type': 'ect'}\n",
      "Accuracy: 0.136340072576 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8350969530752927, 'initial_t': 6.148033377066741e-05, 'l': 0.28727062121464286, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.6196189470466576e-07, 'loss_function': 'squared', 'l1': 1.076166841799221e-05, 'type': 'ect'}\n",
      "Accuracy: 0.410057024365 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.38071123698050885, 'initial_t': 1.029655337972089, 'l': 0.238946431436958, 'q': 'sb', 'power_t': 1, 'noconstant': False, 'l2': 3.4810379092435342e-06, 'loss_function': 'logistic', 'l1': 2.9740305019497227e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.347665660354 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.3569775300809522, 'initial_t': 0.03620474030483321, 'l': 0.006914254438518453, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 8.17563084648187e-05, 'loss_function': 'squared', 'l1': 1.0152289980224266e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.176988991553 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9425358835992573, 'initial_t': 0.00010266179700461874, 'l': 0.9040110078154401, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 2.2022658199277962e-07, 'loss_function': 'hinge', 'l1': 1.012003849706742e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.542981733907 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.963750119439077, 'initial_t': 0.00021341866476415038, 'l': 0.4057361275172061, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 7.871280140366821e-07, 'loss_function': 'logistic', 'l1': 2.9095665502016997e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.345653035709 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.9950491847551776, 'initial_t': 0.0016859038817446455, 'l': 0.8611465899365406, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 5.660212285444413e-08, 'loss_function': 'logistic', 'l1': 1.31935022648046e-08, 'type': 'ect'}\n",
      "Accuracy: 0.301985179764 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.8244305209892622, 'initial_t': 0.6044731177268563, 'l': 0.05898405895120441, 'q': 'sc', 'power_t': 0.5, 'noconstant': False, 'l2': 2.230259958554409e-07, 'loss_function': 'logistic', 'l1': 8.465536600126847e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.201902845119 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.9836243046489217, 'initial_t': 0.49960742438834327, 'l': 13.947026272264141, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 3.329590227960979e-07, 'loss_function': 'squared', 'l1': 1.383889873145811e-07, 'type': 'ect'}\n",
      "Accuracy: 0.410422956119 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.2069750855559933, 'initial_t': 2.044801037183741, 'l': 0.1486979684439112, 'q': 'sc', 'power_t': 1, 'noconstant': False, 'l2': 6.737026930977787e-09, 'loss_function': 'squared', 'l1': 7.852046429182051e-08, 'type': 'ect'}\n",
      "Accuracy: 0.46458085567 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9647307710877955, 'initial_t': 0.013825871179414648, 'l': 6.214989541783011, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 4.5987144503865284e-08, 'loss_function': 'hinge', 'l1': 5.0681556248419835e-08, 'type': 'ect'}\n",
      "Accuracy: 0.362333424816 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.7596547947685287, 'initial_t': 0.00010624603226661501, 'l': 2.228098807107105, 'q': 'sb', 'power_t': 1, 'noconstant': False, 'l2': 3.829575753815416e-06, 'loss_function': 'logistic', 'l1': 9.562560941127986e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.347818131918 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6114642593697446, 'initial_t': 0.17494198716491285, 'l': 4.087508444334099, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 2.891510296207632e-09, 'loss_function': 'hinge', 'l1': 3.3717311644920374e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.518616777971 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5608206423819566, 'initial_t': 0.09582253572080197, 'l': 0.01625028536502988, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 2.1009703268757885e-09, 'loss_function': 'hinge', 'l1': 1.2331193199982042e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.528283475132 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.32583392552738244, 'initial_t': 0.0037633987719442523, 'l': 0.1253821724283344, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 1.8624144463140984e-08, 'loss_function': 'hinge', 'l1': 4.3209428693750286e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.527978532004 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.4725251087411133, 'initial_t': 0.07118893566426134, 'l': 0.7609741146179296, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 1.833406701345565e-06, 'loss_function': 'hinge', 'l1': 2.429787231673145e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.519104686976 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6903038146057064, 'initial_t': 0.012978095051215995, 'l': 3.3719472932911034, 'q': 'sd', 'power_t': 0.5, 'noconstant': True, 'l2': 4.789461559086119e-08, 'loss_function': 'hinge', 'l1': 1.0734782836610043e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.519684078919 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.31260845757366884, 'initial_t': 0.0019265616640974361, 'l': 13.289300736478957, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 4.694875570658157e-07, 'loss_function': 'hinge', 'l1': 2.8657950844506984e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.528100509255 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5504255982235231, 'initial_t': 0.026177117831937383, 'l': 0.9644049119424981, 'q': 'si', 'power_t': 0.5, 'noconstant': True, 'l2': 9.958615331544467e-08, 'loss_function': 'hinge', 'l1': 6.730661620715218e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.519196169914 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.42463535883088643, 'initial_t': 0.11831785697971116, 'l': 0.16884333680606062, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 9.010238562889848e-06, 'loss_function': 'hinge', 'l1': 3.889856481623916e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.518616777971 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.2511874906956846, 'initial_t': 0.28037167624937537, 'l': 0.0193456758102741, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 4.256803659543965e-09, 'loss_function': 'hinge', 'l1': 2.966577697601274e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.528161497881 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8966456642972636, 'initial_t': 2.591190562005083, 'l': 0.030355876387419708, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 9.432291954140874e-09, 'loss_function': 'hinge', 'l1': 3.022708505737078e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.544597932486 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9038745943123347, 'initial_t': 0.0006506852216306373, 'l': 0.025297537178081007, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 5.691905490085639e-09, 'loss_function': 'hinge', 'l1': 3.613280742959939e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.54377458604 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8924143429991436, 'initial_t': 0.0009176749968896749, 'l': 0.02719148259572378, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 8.611626562241357e-09, 'loss_function': 'hinge', 'l1': 2.2923878354039406e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.54475040405 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.7411724684515997, 'initial_t': 0.0032760466146900644, 'l': 0.007682965176907049, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0187459370369072e-08, 'loss_function': 'hinge', 'l1': 2.41554814655738e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.509559967066 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6806678479212226, 'initial_t': 0.0008895493280219338, 'l': 0.02966976825054761, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 3.3315429739876752e-09, 'loss_function': 'hinge', 'l1': 2.3548352859844302e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.544414966609 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.8606191701687609, 'initial_t': 0.007479088544991431, 'l': 0.08523867443268686, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.9452785137192623e-08, 'loss_function': 'hinge', 'l1': 7.0536033141966626e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.509834415881 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9016364068908295, 'initial_t': 2.656762843770968, 'l': 0.03819034685580118, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0330447278285289e-08, 'loss_function': 'squared', 'l1': 2.2033581258741658e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.530844997408 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.6297951276295942, 'initial_t': 0.00029110952581480517, 'l': 0.012175374196556475, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.0921511462750696e-09, 'loss_function': 'hinge', 'l1': 2.2081921620480158e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.509163541 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.7360955082403693, 'initial_t': 0.0011360578115734766, 'l': 0.08174689700362535, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 2.56009126176999e-08, 'loss_function': 'hinge', 'l1': 7.104847515271128e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.541975421584 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.02414675781724518, 'initial_t': 0.00039770713562303333, 'l': 0.05631507266574943, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.9261369235907193e-05, 'loss_function': 'squared', 'l1': 4.780803019180059e-09, 'type': 'ect'}\n",
      "Accuracy: 0.18845485317 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9043901943230026, 'initial_t': 0.0030179846419993994, 'l': 0.010014644666380024, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 6.101052355586952e-08, 'loss_function': 'hinge', 'l1': 1.647028902873203e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.543713597414 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.7782475448882687, 'initial_t': 0.007480946302319199, 'l': 0.03891371083842383, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0291450756094518e-07, 'loss_function': 'hinge', 'l1': 1.277504362794637e-07, 'type': 'ect'}\n",
      "Accuracy: 0.372488030982 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5404385074112038, 'initial_t': 0.041030236990719504, 'l': 0.016980053014815123, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0138500988137962e-06, 'loss_function': 'squared', 'l1': 8.121596545017285e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.543073216845 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.09102838187044016, 'initial_t': 1.3781158778266847, 'l': 0.11216051684063558, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.6542756526855426e-08, 'loss_function': 'logistic', 'l1': 4.52668948600449e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.323697130485 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.6339908970006558, 'initial_t': 0.00015269816906855234, 'l': 0.24081193168742832, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 6.2860519956614055e-09, 'loss_function': 'hinge', 'l1': 5.886873861693009e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.463544049035 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8498198522212665, 'initial_t': 0.017724570965637624, 'l': 0.47891316300051534, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 9.802344452997663e-09, 'loss_function': 'hinge', 'l1': 1.089918421658346e-08, 'type': 'ect'}\n",
      "Accuracy: 0.353032659409 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.9985245270661639, 'initial_t': 5.6376305095619074e-05, 'l': 0.0265659462238616, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 2.141392626992311e-09, 'loss_function': 'logistic', 'l1': 4.9851144080070744e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.000304943128107 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.7141337060555072, 'initial_t': 0.0014012333606823588, 'l': 0.007234363561354108, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.891377083199654e-07, 'loss_function': 'squared', 'l1': 1.6351475567091892e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.53075351447 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9216755533035966, 'initial_t': 0.0004678639323557776, 'l': 0.19920698610238285, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.0658897519635912e-06, 'loss_function': 'hinge', 'l1': 3.2941696238959135e-09, 'type': 'ect'}\n",
      "Accuracy: 0.336809684994 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.8003661292648909, 'initial_t': 0.061366782666453935, 'l': 0.04706359934348978, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 5.229073935104497e-07, 'loss_function': 'logistic', 'l1': 9.185081042507018e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.118378922331 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.511829427912783, 'initial_t': 0.002180606672363022, 'l': 0.012771199211871103, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 3.923826960065199e-08, 'loss_function': 'hinge', 'l1': 4.138316786854354e-08, 'type': 'ect'}\n",
      "Accuracy: 0.338120940445 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.4139319015786712, 'initial_t': 0.4703685746945758, 'l': 0.061115965647616954, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 3.1810949490067295e-05, 'loss_function': 'squared', 'l1': 2.3733807062425772e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.530844997408 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.5989129637151813, 'initial_t': 0.00596811114052136, 'l': 0.33771828284683847, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 7.715387602266084e-08, 'loss_function': 'hinge', 'l1': 1.523643081868199e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.511999512091 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.868742381038061, 'initial_t': 0.00022524088644335286, 'l': 0.10130010225767733, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 2.0065362204351222e-08, 'loss_function': 'logistic', 'l1': 5.925442072941253e-09, 'type': 'ect'}\n",
      "Accuracy: 0.374012746623 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9431747752219428, 'initial_t': 4.703256587334727e-05, 'l': 0.6169710590248493, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 6.93947925168237e-06, 'loss_function': 'hinge', 'l1': 1.9338132560453233e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.54356112585 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.8210881657187984, 'initial_t': 0.00012135491850180972, 'l': 1.4055895316204468, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 3.436166850552988e-09, 'loss_function': 'hinge', 'l1': 4.55084179024482e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.513676699296 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.994301899421435, 'initial_t': 0.8733990383178091, 'l': 0.008974327412449122, 'q': 'sc', 'power_t': 0.5, 'noconstant': False, 'l2': 1.4340308395150135e-07, 'loss_function': 'squared', 'l1': 1.1046261054580319e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.0835544171012 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.147515241193658, 'initial_t': 0.3070425282762998, 'l': 9.219277866573012, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 4.07834749978152e-07, 'loss_function': 'logistic', 'l1': 1.9318631557197636e-08, 'type': 'ect'}\n",
      "Accuracy: 0.361632055622 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5886509467982302, 'initial_t': 0.14249250639344718, 'l': 0.021072771541441267, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 3.47093028545959e-08, 'loss_function': 'hinge', 'l1': 3.122930522066985e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.545360290306 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.2803270699530178, 'initial_t': 0.13165421842819006, 'l': 0.021450353546160983, 'q': 'sb', 'power_t': 0.5, 'noconstant': True, 'l2': 8.372662927056156e-08, 'loss_function': 'hinge', 'l1': 1.6865581063499615e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.525020583661 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.4557892299481036, 'initial_t': 0.2024706762556334, 'l': 0.015548992248513544, 'q': 'sb', 'power_t': 1, 'noconstant': False, 'l2': 2.4873846210259985e-07, 'loss_function': 'hinge', 'l1': 7.028324607359167e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.000304943128107 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.35824236145095445, 'initial_t': 0.01885870669637885, 'l': 0.07005245622187406, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 3.842472246496982e-08, 'loss_function': 'logistic', 'l1': 5.958407209441769e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.347787637606 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6528557133125664, 'initial_t': 0.040628719432438135, 'l': 0.1510350985381956, 'q': 'sb', 'power_t': 1, 'noconstant': True, 'l2': 1.3036145202013727e-07, 'loss_function': 'squared', 'l1': 3.222755093814935e-09, 'type': 'ect'}\n",
      "Accuracy: 0.438508218217 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5054904256118788, 'initial_t': 8.474172793882138e-05, 'l': 0.04910364485272336, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 4.829478246653022e-09, 'loss_function': 'hinge', 'l1': 9.646286240319292e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.546305614003 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5779945710270283, 'initial_t': 0.055681674604569326, 'l': 0.04766346626707306, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 1.4421125487342108e-08, 'loss_function': 'hinge', 'l1': 1.1133601373615166e-08, 'type': 'oaa'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-1de8059121aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'def hyperopt_train_test(params):\\n    with open(folder+\\'train_part\\'+handler+\\'.vw\\') as f:\\n        train_part_file = f.readlines()\\n    \\n    with open(folder+\\'valid\\'+handler+\\'.vw\\') as f:\\n        valid_file = f.readlines()\\n    \\n    clas_type = params[\"type\"]\\n    del params[\"type\"]\\n    \\n    if clas_type == \"ect\":\\n        model = VW(ect=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\\n    else:\\n        model = VW(oaa=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\\n    \\n    #skf = StratifiedKFold(n_splits=3, shuffle=True)\\n    model.fit(train_part_file)\\n    accuracy = accuracy_score(y_valid, model.predict(valid_file))\\n    return accuracy\\n    #return cross_val_score(model, X=train_part_file, y=y_train, cv=skf, scoring=make_scorer(accuracy_score), n_jobs=3).mean()\\n\\nspace4knn = {\\n    \\'type\\': hp.choice(\\'type\\', [\\'oaa\\', \\'ect\\']),\\n    \\'l\\': hp.loguniform(\\'l\\', -5, 3),\\n    \\'initial_t\\': hp.loguniform(\\'initial_t\\', -10, 1),\\n    \\'power_t\\': hp.choice(\\'power_t\\', [0.5, 1]),\\n    \\'decay_learning_rate\\': hp.uniform(\\'decay_learning_rate\\', 0.001, 1),\\n    \\'l2\\': hp.loguniform(\\'l2\\', -20, -9),\\n    \\'l1\\': hp.loguniform(\\'l1\\', -20, -9),\\n    \\'loss_function\\': hp.choice(\\'loss_function\\', [\"logistic\", \"hinge\", \"squared\"]),\\n    \\'ftrl\\': hp.choice(\\'ftrl\\', [True, False]),\\n    \\'noconstant\\': hp.choice(\\'noconstant\\', [True, False]),\\n    \\'cubic\\': hp.choice(\\'cubic\\', [\\'sbc\\', \\'ibc\\']),\\n    \\'q\\': hp.choice(\\'q\\', [\"sb\", \"sc\", \"sd\", \"si\"])\\n}\\n\\ndef f(params):\\n    print \"Testing with params:\"\\n    print params\\n    acc = hyperopt_train_test(params)\\n    print \"Accuracy:\", acc, \"\\\\n\"\\n    return {\\'loss\\': -acc, \\'status\\': STATUS_OK}\\n\\ntrials_wide_range = Trials()\\n#trials_wide_range = MongoTrials(\\'mongo://localhost:1234/mydb/jobs\\', exp_key=\\'exp1\\')\\nbest = fmin(f, space4knn, algo=tpe.suggest, max_evals=100, trials=trials_wide_range)\\nprint \\'best:\\'\\nprint best'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mf\u001b[1;34m(params)\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mhyperopt_train_test\u001b[1;34m(params)\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/vowpalwabbit/sklearn_vw.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/vowpalwabbit/pyvw.pyc\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, ec)\u001b[0m\n\u001b[0;32m     82\u001b[0m         learned on).\"\"\"\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'setup_done'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def hyperopt_train_test(params):\n",
    "    with open(folder+'train_part'+handler+'.vw') as f:\n",
    "        train_part_file = f.readlines()\n",
    "    \n",
    "    with open(folder+'valid'+handler+'.vw') as f:\n",
    "        valid_file = f.readlines()\n",
    "    \n",
    "    clas_type = params[\"type\"]\n",
    "    del params[\"type\"]\n",
    "    \n",
    "    if clas_type == \"ect\":\n",
    "        model = VW(ect=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\n",
    "    else:\n",
    "        model = VW(oaa=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\n",
    "    \n",
    "    #skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    model.fit(train_part_file)\n",
    "    accuracy = accuracy_score(y_valid, model.predict(valid_file))\n",
    "    return accuracy\n",
    "    #return cross_val_score(model, X=train_part_file, y=y_train, cv=skf, scoring=make_scorer(accuracy_score), n_jobs=3).mean()\n",
    "\n",
    "space4knn = {\n",
    "    'type': hp.choice('type', ['oaa', 'ect']),\n",
    "    'l': hp.loguniform('l', -5, 3),\n",
    "    'initial_t': hp.loguniform('initial_t', -10, 1),\n",
    "    'power_t': hp.choice('power_t', [0.5, 1]),\n",
    "    'decay_learning_rate': hp.uniform('decay_learning_rate', 0.001, 1),\n",
    "    'l2': hp.loguniform('l2', -20, -9),\n",
    "    'l1': hp.loguniform('l1', -20, -9),\n",
    "    'loss_function': hp.choice('loss_function', [\"logistic\", \"hinge\", \"squared\"]),\n",
    "    'ftrl': hp.choice('ftrl', [True, False]),\n",
    "    'noconstant': hp.choice('noconstant', [True, False]),\n",
    "    'cubic': hp.choice('cubic', ['sbc', 'ibc']),\n",
    "    'q': hp.choice('q', [\"sb\", \"sc\", \"sd\", \"si\"])\n",
    "}\n",
    "\n",
    "def f(params):\n",
    "    print \"Testing with params:\"\n",
    "    print params\n",
    "    acc = hyperopt_train_test(params)\n",
    "    print \"Accuracy:\", acc, \"\\n\"\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials_wide_range = Trials()\n",
    "#trials_wide_range = MongoTrials('mongo://localhost:1234/mydb/jobs', exp_key='exp1')\n",
    "best = fmin(f, space4knn, algo=tpe.suggest, max_evals=100, trials=trials_wide_range)\n",
    "print 'best:'\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
