{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://smartandnimble/identifyme/xgb/toy/test.buffer...\n",
      "/ [1 files][  4.3 MiB/  4.3 MiB]                                                Copying gs://smartandnimble/identifyme/xgb/toy/train.buffer...\n",
      "Copying gs://smartandnimble/identifyme/xgb/toy/trainfull.buffer...              / [2 files][  6.6 MiB/  6.6 MiB]                                                \n",
      "Copying gs://smartandnimble/identifyme/xgb/toy/valid.buffer...                  / [3 files][ 11.2 MiB/ 11.2 MiB]                                                \n",
      "/ [3 files][ 11.2 MiB/ 12.2 MiB]                                                / [4 files][ 12.2 MiB/ 12.2 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m -o ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://smartandnimble/identifyme/xgb/toy/y_valid_w5_old.csv...\n",
      "- [5 files][ 12.2 MiB/ 12.2 MiB]                                                -\n",
      "Operation completed over 5 objects/12.2 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://smartandnimble/identifyme/xgb/toy \"data/identifyme/xgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 475, 'subsample': 0.7000000000000001, 'eta': 0.375, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 2, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.5519879208\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 85, 'subsample': 0.75, 'eta': 0.25, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.21179822865\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 315, 'subsample': 0.65, 'eta': 0.35000000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.25577964871\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 154, 'subsample': 0.9500000000000001, 'eta': 0.2, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.42029625998\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 567, 'subsample': 0.9500000000000001, 'eta': 0.375, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 7, 'gamma': 0.8}\n",
      "\tScore 1.36709947362\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 633, 'subsample': 0.55, 'eta': 0.1, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.65}\n",
      "\tScore 1.32578832496\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 150, 'subsample': 0.65, 'eta': 0.07500000000000001, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.9}\n",
      "\tScore 1.53680620027\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 117, 'subsample': 0.7000000000000001, 'eta': 0.125, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.38551037486\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 675, 'subsample': 0.9, 'eta': 0.15000000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 11, 'gamma': 0.65}\n",
      "\tScore 1.4036898782\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 761, 'subsample': 0.65, 'eta': 0.4, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 5, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.33331261765\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 33, 'subsample': 0.5, 'eta': 0.275, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 11, 'gamma': 1.0}\n",
      "\tScore 1.53152106563\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 678, 'subsample': 1.0, 'eta': 0.30000000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 5, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.28788003398\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 968, 'subsample': 0.9, 'eta': 0.35000000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 12, 'gamma': 0.6000000000000001}\n",
      "\tScore 1.26396601907\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 212, 'subsample': 0.8500000000000001, 'eta': 0.35000000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 7, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.20345350759\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 124, 'subsample': 0.75, 'eta': 0.375, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.65}\n",
      "\tScore 1.31126550764\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 220, 'subsample': 0.9, 'eta': 0.05, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.65}\n",
      "\tScore 1.36500701088\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 37, 'subsample': 0.9500000000000001, 'eta': 0.05, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 3, 'gamma': 0.9500000000000001}\n",
      "\tScore 2.69067419943\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 940, 'subsample': 0.7000000000000001, 'eta': 0.07500000000000001, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 11, 'gamma': 0.8}\n",
      "\tScore 1.34606775606\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 93, 'subsample': 0.8, 'eta': 0.42500000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 1, 'gamma': 0.9}\n",
      "\tScore 2.12542629457\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 979, 'subsample': 0.6000000000000001, 'eta': 0.375, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 11, 'gamma': 0.55}\n",
      "\tScore 1.29578282673\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 535, 'subsample': 0.8, 'eta': 0.5, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.8}\n",
      "\tScore 1.16187959296\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 137, 'subsample': 0.8, 'eta': 0.5, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.8}\n",
      "\tScore 1.20155969032\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 526, 'subsample': 0.8, 'eta': 0.47500000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.8}\n",
      "\tScore 1.1584993586\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 592, 'subsample': 0.8, 'eta': 0.5, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.15919008106\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 26, 'subsample': 0.8500000000000001, 'eta': 0.45, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.49463709931\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 291, 'subsample': 0.8500000000000001, 'eta': 0.47500000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.75}\n",
      "\tScore 1.16115543404\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 188, 'subsample': 0.8, 'eta': 0.45, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 4, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.39531041094\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 1.0, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 427, 'subsample': 0.75, 'eta': 0.47500000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.75}\n",
      "\tScore 1.16959206157\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 838, 'subsample': 0.7000000000000001, 'eta': 0.30000000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 2, 'gamma': 0.9}\n",
      "\tScore 1.51320466437\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 1.0, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 438, 'subsample': 0.8500000000000001, 'eta': 0.42500000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.14343572838\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 1.0, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 526, 'subsample': 1.0, 'eta': 0.225, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 1.0}\n",
      "\tScore 1.22606237487\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 1.0, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 248, 'subsample': 0.8500000000000001, 'eta': 0.42500000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 0.9}\n",
      "\tScore 1.14937757163\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 1.0, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 27, 'subsample': 0.8500000000000001, 'eta': 0.42500000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 0.9}\n",
      "\tScore 1.48094045854\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 1.0, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 549, 'subsample': 0.9500000000000001, 'eta': 0.325, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.37488572885\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 895, 'subsample': 0.9, 'eta': 0.225, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 1.0}\n",
      "\tScore 1.13674545436\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 895, 'subsample': 0.9, 'eta': 0.17500000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 1.0}\n",
      "\tScore 1.15243455764\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 257, 'subsample': 1.0, 'eta': 0.225, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 8, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.43426013281\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 690, 'subsample': 0.9500000000000001, 'eta': 0.25, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 12, 'gamma': 1.0}\n",
      "\tScore 1.35654848123\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 361, 'subsample': 0.9, 'eta': 0.2, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 1, 'gamma': 0.75}\n",
      "\tScore 1.69338632968\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 641, 'subsample': 0.75, 'eta': 0.125, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 2, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.53767454587\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 56, 'subsample': 1.0, 'eta': 0.275, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 3, 'gamma': 0.5}\n",
      "\tScore 1.80991757562\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 790, 'subsample': 0.9500000000000001, 'eta': 0.17500000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.09112261279\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 695, 'subsample': 0.9500000000000001, 'eta': 0.15000000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.6000000000000001}\n",
      "\tScore 1.34320110752\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 735, 'subsample': 0.5, 'eta': 0.17500000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 1.0}\n",
      "\tScore 1.14669457854\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 936, 'subsample': 0.9500000000000001, 'eta': 0.1, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.9}\n",
      "\tScore 1.16665906754\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 237, 'subsample': 1.0, 'eta': 0.225, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 7, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.43312398378\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 718, 'subsample': 0.6000000000000001, 'eta': 0.25, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.14710638292\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 101, 'subsample': 0.9, 'eta': 0.17500000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 5, 'gamma': 0.6000000000000001}\n",
      "\tScore 1.48319465003\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 88, 'subsample': 0.9, 'eta': 0.125, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.75}\n",
      "\tScore 1.26855681614\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 748, 'subsample': 0.9500000000000001, 'eta': 0.025, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.37343935072\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 281, 'subsample': 1.0, 'eta': 0.30000000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 12, 'gamma': 0.5}\n",
      "\tScore 1.16467126438\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 132, 'subsample': 0.6000000000000001, 'eta': 0.2, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.51679412482\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 643, 'subsample': 0.7000000000000001, 'eta': 0.07500000000000001, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.8}\n",
      "\tScore 1.12151343803\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 573, 'subsample': 0.55, 'eta': 0.025, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.8}\n",
      "\tScore 1.66761907712\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 752, 'subsample': 0.65, 'eta': 0.05, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.65}\n",
      "\tScore 1.29644530574\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 109, 'subsample': 0.65, 'eta': 0.1, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.8}\n",
      "\tScore 1.38683774092\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 506, 'subsample': 0.7000000000000001, 'eta': 0.07500000000000001, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 3, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.30341120197\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 594, 'subsample': 0.65, 'eta': 0.15000000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 7, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.37824547848\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 790, 'subsample': 0.55, 'eta': 0.05, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 1, 'gamma': 0.75}\n",
      "\tScore 1.91479818497\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 9, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 11, 'subsample': 0.7000000000000001, 'eta': 0.1, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 5, 'gamma': 0.7000000000000001}\n",
      "\tScore 2.90562217567\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 834, 'subsample': 0.75, 'eta': 0.125, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.8}\n",
      "\tScore 1.10827253381\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 345, 'subsample': 0.75, 'eta': 0.15000000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.65}\n",
      "\tScore 1.19393414745\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 139, 'subsample': 0.55, 'eta': 0.125, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.24339271154\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 349, 'subsample': 0.8, 'eta': 0.2, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.9}\n",
      "\tScore 1.42682461208\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 943, 'subsample': 0.6000000000000001, 'eta': 0.275, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 11, 'gamma': 0.55}\n",
      "\tScore 1.51713060055\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 600, 'subsample': 0.7000000000000001, 'eta': 0.07500000000000001, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 10, 'gamma': 0.8}\n",
      "\tScore 1.11947549216\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 287, 'subsample': 0.75, 'eta': 0.05, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.8}\n",
      "\tScore 1.24516869312\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.75, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 97, 'subsample': 0.65, 'eta': 0.1, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 2, 'gamma': 0.75}\n",
      "\tScore 2.20504535683\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 480, 'subsample': 0.7000000000000001, 'eta': 0.07500000000000001, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.1221809795\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.7000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 964, 'subsample': 0.75, 'eta': 0.17500000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.8}\n",
      "\tScore 1.11787705607\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 834, 'subsample': 0.75, 'eta': 0.17500000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.9}\n",
      "\tScore 1.12795551785\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 518, 'subsample': 0.8, 'eta': 0.2, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.75}\n",
      "\tScore 1.12115262711\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 771, 'subsample': 0.8500000000000001, 'eta': 0.15000000000000002, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.13296600576\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 485, 'subsample': 0.8500000000000001, 'eta': 0.125, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 6, 'gamma': 0.7000000000000001}\n",
      "\tScore 1.34280571578\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 561, 'subsample': 0.75, 'eta': 0.275, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 12, 'gamma': 0.8}\n",
      "\tScore 1.11908258919\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 986, 'subsample': 0.8, 'eta': 0.325, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9}\n",
      "\tScore 1.10288385007\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 578, 'subsample': 0.8, 'eta': 0.325, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9}\n",
      "\tScore 1.25316040581\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 780, 'subsample': 0.8, 'eta': 0.35000000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9}\n",
      "\tScore 1.39516781694\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 521, 'subsample': 0.8500000000000001, 'eta': 0.4, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.11326783112\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 271, 'subsample': 0.8500000000000001, 'eta': 0.4, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.44118718167\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 500, 'subsample': 0.9500000000000001, 'eta': 0.25, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 3, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.31535388853\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 4, 'n_estimators': 276, 'subsample': 0.9, 'eta': 0.325, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 11, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.32841146488\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 704, 'subsample': 0.8, 'eta': 0.35000000000000003, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 1, 'gamma': 1.0}\n",
      "\tScore 1.50312513507\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 539, 'subsample': 0.75, 'eta': 0.225, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 0.9}\n",
      "\tScore 1.1125224753\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.6000000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 3, 'n_estimators': 523, 'subsample': 0.7000000000000001, 'eta': 0.30000000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 7, 'gamma': 0.8500000000000001}\n",
      "\tScore 1.30693647149\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.55, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 428, 'subsample': 0.9, 'eta': 0.375, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 2, 'gamma': 0.9}\n",
      "\tScore 1.31242745046\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.9, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 3, 'nthread': 5, 'min_child_weight': 5, 'n_estimators': 869, 'subsample': 0.65, 'eta': 0.325, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 5, 'gamma': 0.75}\n",
      "\tScore 1.46920862791\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.65, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 7, 'nthread': 5, 'min_child_weight': 6, 'n_estimators': 114, 'subsample': 0.9500000000000001, 'eta': 0.30000000000000004, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.9500000000000001}\n",
      "\tScore 1.42909331892\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.5, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 5, 'nthread': 5, 'min_child_weight': 2, 'n_estimators': 296, 'subsample': 0.8500000000000001, 'eta': 0.25, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 13, 'gamma': 0.8}\n",
      "\tScore 1.17679802572\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'colsample_bytree': 0.8500000000000001, 'silent': 1, 'eval_metric': 'mlogloss', 'max_delta_step': 1, 'nthread': 5, 'min_child_weight': 1, 'n_estimators': 720, 'subsample': 1.0, 'eta': 0.45, 'objective': 'multi:softprob', 'num_class': 150, 'max_depth': 9, 'gamma': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-500159db8f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'def write_submission(preds, output):\\n    sample = pd.read_csv(\\'../data/sampleSubmission.csv\\')\\n    preds = pd.DataFrame(\\n        preds, index=sample.id.values, columns=sample.columns[1:])\\n    preds.to_csv(output, index_label=\\'id\\')\\n\\n\\ndef score(params):\\n    print \"Training with params : \"\\n    print params\\n    num_round = int(params[\\'n_estimators\\'])\\n    del params[\\'n_estimators\\']\\n    \\n    dtrain = xgb.DMatrix(folder+\"train.buffer\")\\n    dvalid = xgb.DMatrix(folder+\"valid.buffer\")\\n    \\n    y_valid=pd.read_csv(folder+\"y_valid_w5_old.csv\", header=None, squeeze=True)\\n\\n    #evallist = [(dvalid, \\'eval\\'), (dtrain, \\'train\\')]\\n    model = xgb.train(params, dtrain, num_round)#, evallist, early_stopping_rounds=3)\\n    predictions = model.predict(dvalid).reshape((int(dvalid.num_row()), 150))\\n    score = log_loss(y_valid, predictions)\\n    print \"\\\\tScore {0}\\\\n\\\\n\".format(score)\\n    return {\\'loss\\': score, \\'status\\': STATUS_OK}\\n\\n\\ndef optimize(trials):\\n    space = {\\n             \\'n_estimators\\' : hp.choice(\\'n_estimators\\', np.arange(1, 1001, dtype=int)),\\n             \\'eta\\' : hp.quniform(\\'eta\\', 0.025, 0.5, 0.025),\\n             \\'max_depth\\' : hp.choice(\\'max_depth\\', np.arange(1, 14, dtype=int)),\\n             \\'min_child_weight\\' : hp.choice(\\'min_child_weight\\', np.arange(1, 7, dtype=int)),\\n             \\'subsample\\' : hp.quniform(\\'subsample\\', 0.5, 1, 0.05),\\n             \\'gamma\\' : hp.quniform(\\'gamma\\', 0.5, 1, 0.05),\\n             \\'colsample_bytree\\' : hp.quniform(\\'colsample_bytree\\', 0.5, 1, 0.05),\\n             \\'max_delta_step\\': hp.choice(\\'max_delta_step\\', np.arange(1, 11, 2, dtype=int)),\\n             \\'num_class\\' : 150,\\n             \\'eval_metric\\': \\'mlogloss\\',#\\'merror\\',\\n             \\'objective\\': \\'multi:softprob\\',\\n             \\'nthread\\' : 5,\\n             \\'silent\\' : 1\\n             }\\n\\n    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\\n\\n    print best\\n\\n\\nfolder = \"data/identifyme/xgb/toy/\"\\n\\n#Trials object where the history of search will be stored\\ntrials = Trials()\\n\\noptimize(trials)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials)\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/miniconda/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(params)\u001b[0m\n",
      "\u001b[0;32m/home/dmitri_likhachev/xgboost/python-package/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmitri_likhachev/xgboost/python-package/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmitri_likhachev/xgboost/python-package/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def write_submission(preds, output):\n",
    "    sample = pd.read_csv('../data/sampleSubmission.csv')\n",
    "    preds = pd.DataFrame(\n",
    "        preds, index=sample.id.values, columns=sample.columns[1:])\n",
    "    preds.to_csv(output, index_label='id')\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print \"Training with params : \"\n",
    "    print params\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    \n",
    "    dtrain = xgb.DMatrix(folder+\"train.buffer\")\n",
    "    dvalid = xgb.DMatrix(folder+\"valid.buffer\")\n",
    "    \n",
    "    y_valid=pd.read_csv(folder+\"y_valid_w5_old.csv\", header=None, squeeze=True)\n",
    "\n",
    "    #evallist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)#, evallist, early_stopping_rounds=3)\n",
    "    predictions = model.predict(dvalid).reshape((int(dvalid.num_row()), 150))\n",
    "    score = log_loss(y_valid, predictions)\n",
    "    print \"\\tScore {0}\\n\\n\".format(score)\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.choice('n_estimators', np.arange(1, 1001, dtype=int)),\n",
    "             'eta' : hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "             'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "             'min_child_weight' : hp.choice('min_child_weight', np.arange(1, 7, dtype=int)),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'max_delta_step': hp.choice('max_delta_step', np.arange(1, 11, 2, dtype=int)),\n",
    "             'num_class' : 150,\n",
    "             'eval_metric': 'mlogloss',#'merror',\n",
    "             'objective': 'multi:softprob',\n",
    "             'nthread' : 5,\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print best\n",
    "\n",
    "\n",
    "folder = \"data/identifyme/xgb/toy/\"\n",
    "\n",
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
