{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, make_scorer\n",
    "from vowpalwabbit.sklearn_vw import VWClassifier, VW\n",
    "import itertools\n",
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparsematrix(X):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for r in range(X.shape[0]):\n",
    "        row_counter = Counter(X[r])\n",
    "        for site, num in row_counter.items():\n",
    "            row.append(r)\n",
    "            col.append(site)\n",
    "            data.append(num)\n",
    "    print \"Sparse Matrix - rows:\", X.shape[0], \"columns:\", len(set(col))\n",
    "    return csr_matrix((data, (row, col)), shape=(X.shape[0], len(set(col))))[:,1:]\n",
    "\n",
    "\n",
    "def sites_to_sparse_tfidf(train_data, test_data, target_col, session_length, label_encoder=False):\n",
    "    train_test_df = pd.concat([train_data, test_data])\n",
    "    train_index_full = list(train_data.index)\n",
    "    train_index_dup = list(train_data[train_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]+[\"target\"]].index)\n",
    "    test_index_full = list(test_data.index)\n",
    "    test_index_dup = list(test_data[test_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]].index)\n",
    "    train_duplicates_mask = np.transpose([np.in1d(train_index_full, train_index_dup).astype(int)])\n",
    "    test_duplicates_mask = np.transpose([np.in1d(test_index_full, test_index_dup).astype(int)])\n",
    "\n",
    "    y = train_data[target_col]\n",
    "\n",
    "    train_test_df_sites = train_test_df[['site' + str(c) for c in range(1,10+1)]].fillna(0).astype('int')\n",
    "    train_test_df_sites_array = [\" \".join([\"s_\"+str(s) for s in train_test_df_sites.as_matrix()[i] if int(s) != 0]) \\\n",
    "                                                                  for i in range(train_test_df_sites.shape[0])]\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_df=0.9).fit(train_test_df_sites_array) #TfidfVectorizer()\n",
    "    X_train_test_sparse = tfidf.transform(train_test_df_sites_array)\n",
    "\n",
    "    X_train_sparse = X_train_test_sparse[:len(train_data)]\n",
    "    X_test_sparse = X_train_test_sparse[len(train_data):]\n",
    "    \n",
    "    sites_columns_num = X_train_test_sparse.shape[1]\n",
    "    \n",
    "    y_for_vw = None\n",
    "    class_encoder = None\n",
    "    if label_encoder:\n",
    "        class_encoder = LabelEncoder().fit(y.astype('str'))\n",
    "        y_for_vw = class_encoder.transform(y.astype('str')) + 1\n",
    "    \n",
    "    return [X_train_sparse, X_test_sparse, y, y_for_vw, sites_columns_num, class_encoder, tfidf, \\\n",
    "             train_duplicates_mask, test_duplicates_mask]\n",
    "\n",
    "\n",
    "def features_to_sparse(train_data, test_data, feature_cols):\n",
    "    features_matrix = []\n",
    "    for df in [train_data, test_data]:\n",
    "        num_cols = 0\n",
    "        data = []\n",
    "        rows = []\n",
    "        cols = []\n",
    "        for label in feature_cols:\n",
    "            if label in [\"day_of_week\", \"daytime\"]:\n",
    "                coldata = list(df[[label]].values.T[0].astype('float') + 1)\n",
    "            else:\n",
    "                coldata = list(df[[label]].values.T[0].astype('float'))\n",
    "            if len(data):\n",
    "                data += coldata\n",
    "            else:\n",
    "                data = list(coldata)\n",
    "            if len(cols):\n",
    "                cols += [num_cols] * len(coldata)\n",
    "            else:\n",
    "                cols = [num_cols] * len(coldata)\n",
    "            num_cols += 1\n",
    "        rows = [r for r in range(df.shape[0])] * num_cols\n",
    "        features = csr_matrix((data, (rows, cols)), shape=(df.shape[0], num_cols), dtype=float)\n",
    "        features_matrix.append(features)\n",
    "    return features_matrix\n",
    "\n",
    "\n",
    "def calc_site_times_portions(train_data, test_data):\n",
    "    site_times = [{},{}]\n",
    "    count = 0\n",
    "    for data in [train_data, test_data]:\n",
    "        for r, row in data[:][range(0, 10)+range(20,30)].iterrows():\n",
    "            rowdic = {}\n",
    "            for c, s in [[c, 'site' + str(c)] for c in range(1,10)]:\n",
    "                if row[s] == 0:\n",
    "                    continue\n",
    "                if row[s] in rowdic:\n",
    "                    rowdic[int(row[s])] += row[\"time_diff\"+str(c)]\n",
    "                else:\n",
    "                    rowdic[int(row[s])] = row[\"time_diff\"+str(c)]\n",
    "            site_times[count][r] = {}\n",
    "            for site, time in rowdic.items():\n",
    "                if len(rowdic) == 1:\n",
    "                    site_times[count][r][int(site)] = time #1.0\n",
    "                    continue\n",
    "                if time > 0:\n",
    "                    #site_times[count][r][int(site)] = round(float(time)/row[\"session_timespan\"],3)\n",
    "                    site_times[count][r][int(site)] = time\n",
    "        count+=1\n",
    "    return site_times\n",
    "\n",
    "def site_times_to_sparse(sitetimes):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    rowcount = 0\n",
    "    for sitetime in sitetimes:\n",
    "        for r, sites in sitetime.items():\n",
    "            for site, p in sites.items():\n",
    "                col.append(site)\n",
    "                row.append(rowcount)\n",
    "                data.append(p)\n",
    "            rowcount+=1\n",
    "    site_times_sparse = csr_matrix((data, (row, col)), shape=(len(sitetimes[0])+len(sitetimes[1]), max(col)+1), \\\n",
    "                                                                                              dtype=float)[:,1:]\n",
    "    return site_times_sparse\n",
    "\n",
    "\n",
    "def combine_sites_features_sparse(sites_train_sparse, features_train_sparse, train_preds_sparse,\\\n",
    "                                  sites_test_sparse, features_test_sparse, test_preds_sparse,\\\n",
    "                                  train_duplicates_mask = None, test_duplicates_mask = None, \\\n",
    "                                  train_site_times_sparse = None, test_site_times_sparse = None, \\\n",
    "                                train_sites_sequence=None, test_sites_sequence=None):\n",
    "    if train_site_times_sparse is not None and test_site_times_sparse is not None:\n",
    "        X_train_sparse = hstack([sites_train_sparse, features_train_sparse, train_preds_sparse,\\\n",
    "                                 train_site_times_sparse, train_sites_sequence], dtype=float).tocsr()\n",
    "        X_test_sparse = hstack([sites_test_sparse, features_test_sparse, test_preds_sparse,\\\n",
    "                                test_site_times_sparse, test_sites_sequence], dtype=float).tocsr()\n",
    "    else:\n",
    "        X_train_sparse = hstack([sites_train_sparse, features_train_sparse, train_preds_sparse], dtype=float).tocsr()\n",
    "        X_test_sparse = hstack([sites_test_sparse, features_test_sparse, test_preds_sparse], dtype=float).tocsr()\n",
    "        \n",
    "    X_train_sparse = hstack([X_train_sparse, train_duplicates_mask], dtype=float).tocsr()\n",
    "    X_test_sparse = hstack([X_test_sparse, test_duplicates_mask], dtype=float).tocsr() \n",
    "    return [X_train_sparse, X_test_sparse]\n",
    "\n",
    "\n",
    "def sparse_matrix_to_vw(X_sparse_full, sites_columns_num, vocabulary, y=None, weights=None, mark_duplicates=False):\n",
    "    sessions = {}\n",
    "    used = {}\n",
    "    prediction = {}\n",
    "    day_of_week = {}\n",
    "    start_hour = {}\n",
    "    daytime = {}\n",
    "    unique_sites = {}\n",
    "    top30_portion = {}\n",
    "    fb_portion = {}\n",
    "    youtube_portion = {}\n",
    "    bot30_portion = {}\n",
    "    site_longest_time = {}\n",
    "    session_timespan = {}\n",
    "    sitetimes = {}\n",
    "    sequence = {}\n",
    "    \n",
    "    lables = {}\n",
    "    lable_weights = {}\n",
    "    \n",
    "    X_sparse = X_sparse_full[:,:-1]\n",
    "    \n",
    "    add_features = True\n",
    "\n",
    "    for r, c in zip(X_sparse.nonzero()[0], X_sparse.nonzero()[1]):\n",
    "        if tuple([r,c]) not in used:\n",
    "            used[tuple([r, c])] = 1\n",
    "            if add_features:\n",
    "                if c >= X_sparse.shape[1] - sites_columns_num - 10 - 550 and \\\n",
    "                    c < X_sparse.shape[1] - sites_columns_num - 10:\n",
    "                    sites_length = X_sparse.shape[1] - sites_columns_num - len(mycolumns) - 550 - 10\n",
    "                    if r not in prediction:\n",
    "                        prediction[r] = \" |aprediction {}:{}\".format(int(c - sites_length - len(mycolumns) + 1), int(X_sparse[r,c]))\n",
    "                    else:\n",
    "                        prediction[r] += \" {}:{}\".format(int(c - sites_length - len(mycolumns) + 1), int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"day_of_week\") - 10 - 550:\n",
    "                    day_of_week[r] = \" |bday_of_week {}\".format(int(X_sparse[r,c]))\n",
    "                    #day_of_week[r] = \" day_of_week:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"start_hour\") - 10 - 550:\n",
    "                    start_hour[r] = \" |chour_start {}\".format(int(X_sparse[r,c]))\n",
    "                    #start_hour[r] = \" start_hour:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"daytime\") - 10 - 550:\n",
    "                    daytime[r] = \" |dtime_of_day {}\".format(int(X_sparse[r,c]))\n",
    "                    #daytime[r] = \" daytime:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"session_timespan\") - 10 - 550:\n",
    "                    session_timespan[r] = \" |jsession_timespan time:{}\".format(int(X_sparse[r,c]))\n",
    "                    #session_timespan[r] = \" session_timespan:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"#unique_sites\") - 10 - 550:\n",
    "                    unique_sites[r] = \" unique_sites:{}\".format(int(X_sparse[r,c]))\n",
    "                    #unique_sites[r] = \" unique_sites:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"site_longest_time\") - 10 - 550:\n",
    "                    site_longest_time[r] = \" |hsite_longest_time {}:{}\".format(int(X_sparse[r,c]), 3)\n",
    "                    #site_longest_time[r] = \" site_longest_time:{}\".format(int(X_sparse[r,c]))\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"top30_portion\") - 10 - 550:\n",
    "                    top30_portion[r] = \" top30:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"bot30_portion\") - 10 - 550:\n",
    "                    bot30_portion[r] = \" bot30:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"fb_portion\") - 10 - 550:\n",
    "                    fb_portion[r] = \" facebook:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c == X_sparse.shape[1] - len(mycolumns) - sites_columns_num + mycolumns.index(\"youtube_portion\") - 10 - 550:\n",
    "                    youtube_portion[r] = \" youtube:{}\".format(X_sparse[r,c])\n",
    "                    continue\n",
    "                elif c >= X_sparse.shape[1] - 10:\n",
    "                    if r not in sequence:\n",
    "                        sequence[r] = \" |ksequence \" + \\\n",
    "                            ' '.join(filter(lambda a: a != \"0\", X_sparse[r,-10:].todense().astype(int).astype(str).tolist()[0]))\n",
    "                    continue\n",
    "                    \n",
    "            if c < sites_columns_num: # X_sparse.shape[1] - len(mycolumns) - 550:\n",
    "                if r in sessions:\n",
    "                    sessions[r] += \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "                else:\n",
    "                    if y is not None:\n",
    "                        sessions[r] = ' |site' + \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "                        lables[r] = str(y[r])\n",
    "                        if weights is not None:\n",
    "                            lable_weights[r] = str(weights[y[r]-1])\n",
    "                    else:\n",
    "                        sessions[r] = ' |site' + \" {}:{}\".format(int(vocabulary[c]), X_sparse[r,c])\n",
    "            elif c >= X_sparse.shape[1] - sites_columns_num - 10 and c < X_sparse.shape[1] - 10:\n",
    "                if r in sitetimes:\n",
    "                    sitetimes[r] += \" {}:{}\".format(int(c - sites_columns_num - len(mycolumns)+1), float(X_sparse[r,c]))\n",
    "                else:\n",
    "                    sitetimes[r] = ' |isitetime' + \" {}:{}\".format(int(c - sites_columns_num - len(mycolumns)+1), float(X_sparse[r,c]))\n",
    "        \n",
    "    \n",
    "    return {\"sites\": sessions, \"lables\": lables, \"lable_weights\": lable_weights, \"prediction\": prediction, \"day_of_week\": day_of_week, \\\n",
    "                      \"start_hour\": start_hour, \"daytime\": daytime, \\\n",
    "                     \"unique_site\": unique_sites, \"top30_portion\": top30_portion, \\\n",
    "                    \"bot30_portion\": bot30_portion, \"fb_portion\": fb_portion, \\\n",
    "                    \"youtube_portion\": youtube_portion, \"site_longest_time\": site_longest_time, \\\n",
    "                    \"session_timespan\": session_timespan, \"sitetimes\": sitetimes, \"sequence\": sequence}\n",
    "\n",
    "\n",
    "\n",
    "def vw_to_file(sites, out_file, features={}, lables={}, lable_weights={},  quiet=True):   \n",
    "    vw_writer = open(out_file, 'w')\n",
    "    final_vw = {}\n",
    "    gen_features = []\n",
    "    \n",
    "    if not quiet:\n",
    "        print \"Features:\", features.keys()\n",
    "        \n",
    "    for r in sorted(sites.keys()):\n",
    "        if r in lables:\n",
    "            final_vw[r] = lables[r]\n",
    "        else:\n",
    "            final_vw[r] = \"\"\n",
    "        if r in lable_weights:\n",
    "            final_vw[r] += \" {}\".format(lable_weights[r])\n",
    "        final_vw[r] += sites[r] #+ \" |features\"\n",
    "        for fname, feature in features.items():\n",
    "            if fname in [\"youtube_portion\", \"fb_portion\", \"top30_portion\", \"bot30_portion\", \\\n",
    "                                         \"unique_sites\"] and r in feature:\n",
    "                gen_features.append(feature[r])\n",
    "                continue\n",
    "            if r in feature:\n",
    "                final_vw[r] += feature[r]        \n",
    "            \n",
    "        if len(gen_features):\n",
    "            final_vw[r] += \" |features\"\n",
    "            for gf in gen_features:\n",
    "                final_vw[r] += gf\n",
    "        gen_features = []\n",
    "        \n",
    "        #if \"prediction\" in features and r in features[\"prediction\"]:\n",
    "            #final_vw[r] += features[\"prediction\"][r]\n",
    "        \n",
    "        vw_writer.write(final_vw[r] + \"\\n\")\n",
    "        \n",
    "    vw_writer.close()\n",
    "    \n",
    "    \n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_predictions(train_data, test_data, site_dic, user_dic, min_users, max_users, permutations=False):\n",
    "    train_row_users = {}\n",
    "    test_row_users = {}\n",
    "    \n",
    "    sites_cols = ['site' + str(c) for c in range(1,10+1)]\n",
    "    \n",
    "    # Add predictions from the dataframe (based on uniquely visited site)\n",
    "    for r, v in train_data[[\"prediction\"]].iterrows():\n",
    "        if int(v) != 0:\n",
    "            train_row_users[r] = {int(v): 1}  \n",
    "    \n",
    "    for r, v in test_data[[\"prediction\"]].iterrows():\n",
    "        if int(v) != 0:\n",
    "            test_row_users[r] = {int(v): 1}\n",
    "    \n",
    "    # Add predictions if a website in session was visited by less than num_users_for_prediction\n",
    "    for r, row in train_data[sites_cols+[\"target\"]].iterrows():\n",
    "        if r in train_row_users:\n",
    "            continue\n",
    "        session_predictions = {}\n",
    "        for site in row:\n",
    "            predictions = set([])\n",
    "            if site in site_dic and site in user_dic[int(row[\"target\"])] \\\n",
    "                          and len(site_dic[site]) in range(min_users, max_users+1):\n",
    "                predictions = set(site_dic[site])\n",
    "            if len(predictions):\n",
    "                for puser in predictions:\n",
    "                    if puser in session_predictions:\n",
    "                        session_predictions[puser] +=1\n",
    "                    else:\n",
    "                        session_predictions[puser] = 1\n",
    "                #session_predictions |= predictions\n",
    "        if len(session_predictions):\n",
    "            train_row_users[r] = session_predictions\n",
    "    \n",
    "    \n",
    "    for r, row in test_data[sites_cols].iterrows():\n",
    "        if r in test_row_users:\n",
    "            continue\n",
    "        session_predictions = {}\n",
    "        for site in row:\n",
    "            predictions = set([])\n",
    "            if site in site_dic and len(site_dic[site]) in range(min_users, max_users):\n",
    "                predictions = set(site_dic[site])\n",
    "            if len(predictions):\n",
    "                for puser in predictions:\n",
    "                    if puser in session_predictions:\n",
    "                        session_predictions[puser] +=1\n",
    "                    else:\n",
    "                        session_predictions[puser] = 1\n",
    "                #session_predictions |= predictions\n",
    "        if len(session_predictions):\n",
    "            test_row_users[r] = session_predictions\n",
    "    \n",
    "    if not permutations:\n",
    "        return train_row_users, test_row_users\n",
    "    \n",
    "    #Identify sessions with identical sites sequence\n",
    "    train_index_full = list(train_data.index)\n",
    "    train_index_dup = list(train_data[train_data.duplicated(subset=['site' + str(c) for c in range(1,10+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]+[\"target\"]].index)\n",
    "\n",
    "    test_index_full = list(test_data.index)\n",
    "    test_index_dup = list(test_data[test_data.duplicated(subset=['site' + str(c) for c in range(1,10+1)], keep=False)]\\\n",
    "                           [['site' + str(c) for c in range(1,10+1)]].index)\n",
    "    \n",
    "    train_user_dup_rows_dict = {}\n",
    "    train_dup_row_users_dict = {}\n",
    "\n",
    "    #test_dup_rows_dict = {} \n",
    "\n",
    "    \n",
    "    \n",
    "    for r, row in train_data.ix[train_index_dup][sites_cols+[\"target\"]].iterrows():\n",
    "        if row[\"target\"] in train_user_dup_rows_dict:\n",
    "            if tuple(row[sites_cols]) in train_user_dup_rows_dict[row[\"target\"]]:\n",
    "                train_user_dup_rows_dict[row[\"target\"]][tuple(row[sites_cols])] += 1\n",
    "            else:\n",
    "                train_user_dup_rows_dict[row[\"target\"]][tuple(row[sites_cols])] = 1 \n",
    "        else:\n",
    "            train_user_dup_rows_dict[row[\"target\"]] = {tuple(row[sites_cols]): 1}\n",
    "\n",
    "        if tuple(row[sites_cols]) in train_dup_row_users_dict:\n",
    "            train_dup_row_users_dict[tuple(row[sites_cols])].add(row[\"target\"])\n",
    "        else:\n",
    "            train_dup_row_users_dict[tuple(row[sites_cols])] = set([row[\"target\"]])\n",
    "    \n",
    "    # Make predictions based on duplicate sessions\n",
    "    for r, row in train_data.ix[train_index_dup][sites_cols].iterrows():        \n",
    "        if tuple(row[sites_cols]) in train_dup_row_users_dict:\n",
    "            if r in train_row_users:\n",
    "                pass #don't overwright predictions from the dataframe\n",
    "                #train_row_users[r] += train_dup_row_users_dict[tuple(row[sites_cols])]\n",
    "            else:\n",
    "                train_row_users[r] = train_dup_row_users_dict[tuple(row[sites_cols])]\n",
    "    \n",
    "    for r, row in test_data.ix[test_index_dup][sites_cols].iterrows():  \n",
    "        #if tuple(row[sites_cols]) in test_dup_rows_dict:\n",
    "            #test_dup_rows_dict[tuple(row[sites_cols])] += 1\n",
    "        #else:\n",
    "            #test_dup_rows_dict[tuple(row[sites_cols])] = 1\n",
    "\n",
    "        if tuple(row[sites_cols]) in train_dup_row_users_dict:\n",
    "            if r in test_row_users:\n",
    "                pass #don't overwright predictions from the dataframe\n",
    "                #test_row_users[r] += train_dup_row_users_dict[tuple(row[sites_cols])]\n",
    "            else:\n",
    "                test_row_users[r] = train_dup_row_users_dict[tuple(row[sites_cols])]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Find users who visited 2, 3, 4 websites\n",
    "    site_pairs = {}\n",
    "    for r, row in train_data[sites_cols+[\"target\"]].iterrows():\n",
    "        unique_sites = Counter(row).keys()\n",
    "        if 0 in unique_sites:\n",
    "            del unique_sites[unique_sites.index(0)]\n",
    "        if len(unique_sites) > 1:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 2):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    site_pairs[tuple(subset)].add(row[\"target\"])\n",
    "                else:\n",
    "                    site_pairs[tuple(subset)] = set([row[\"target\"]])\n",
    "        if len(unique_sites) > 2:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 3):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    site_pairs[tuple(subset)].add(row[\"target\"])\n",
    "                else:\n",
    "                    site_pairs[tuple(subset)] = set([row[\"target\"]])\n",
    "        #if len(unique_sites) > 3:\n",
    "            #for subset in itertools.permutations(Counter(row).keys(), 4):\n",
    "                #if tuple(subset) in site_pairs:\n",
    "                    #site_pairs[tuple(subset)].add(row[\"target\"])\n",
    "                #else:\n",
    "                    #site_pairs[tuple(subset)] = set([row[\"target\"]])\n",
    "    \n",
    "    # Add predictions to train data based on 2 visited websites\n",
    "    for r, row in train_data[sites_cols+[\"target\"]].iterrows():\n",
    "        if r in train_row_users:\n",
    "            continue\n",
    "        unique_sites = Counter(row).keys()\n",
    "        if 0 in unique_sites:\n",
    "            del unique_sites[unique_sites.index(0)]\n",
    "        if len(unique_sites) > 1:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 2):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    if r in train_row_users:\n",
    "                        train_row_users[r] |= site_pairs[subset]\n",
    "                    else:\n",
    "                        train_row_users[r] = set(site_pairs[subset])\n",
    "        if len(unique_sites) > 2:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 3):\n",
    "                if tuple(subset) in site_pairs:\n",
    "                    if r in test_row_users:\n",
    "                        train_row_users[r] |= site_pairs[subset]\n",
    "                    else:\n",
    "                        train_row_users[r] = set(site_pairs[subset])\n",
    "        #if len(unique_sites) > 3:\n",
    "            #for subset in itertools.permutations(Counter(row).keys(), 4):\n",
    "                #if tuple(subset) in site_pairs:\n",
    "                    #if r in test_row_users:\n",
    "                        #train_row_users[r].add(site_pairs[subset])\n",
    "                    #else:\n",
    "                        #train_row_users[r] = set(site_pairs[subset])\n",
    "    \n",
    "    # Add predictions to test data based on 2 visited websites\n",
    "    for r, row in test_data[sites_cols].iterrows():\n",
    "        if r in test_row_users:\n",
    "            continue\n",
    "        unique_sites = Counter(row).keys()\n",
    "        if len(unique_sites) > 1:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 2):\n",
    "                if subset in site_pairs:\n",
    "                    if r in test_row_users:\n",
    "                        test_row_users[r] |= site_pairs[subset]\n",
    "                    else:\n",
    "                        test_row_users[r] = set(site_pairs[subset])\n",
    "        if len(unique_sites) > 2:\n",
    "            for subset in itertools.permutations(Counter(row).keys(), 3):\n",
    "                if subset in site_pairs:\n",
    "                    if r in test_row_users:\n",
    "                        test_row_users[r] |= site_pairs[subset]\n",
    "                    else:\n",
    "                        test_row_users[r] = set(site_pairs[subset])\n",
    "        #if len(unique_sites) > 3:\n",
    "            #for subset in itertools.permutations(Counter(row).keys(), 4):\n",
    "                #if subset in site_pairs:\n",
    "                    #if r in test_row_users:\n",
    "                        #test_row_users[r].add(site_pairs[subset])\n",
    "                    #else:\n",
    "                        #test_row_users[r] = set(site_pairs[subset])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return train_row_users, test_row_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions_to_vw(predictions):\n",
    "    new_pred = {}\n",
    "    \n",
    "    for row, pred in [[k, v.items()] for k, v in predictions.items() if len(v) ==2]:\n",
    "        if pred[0][1] != pred[1][1]:\n",
    "            print \"Predictions probabilities are not equal! Breaking!\", pred\n",
    "            break\n",
    "        new_pred[row] = \" |aprediction \" + str(pred[0][0]) + \":0.5\" + \" \" + str(pred[1][0]) + \":0.5\"\n",
    "    \n",
    "    ###################\n",
    "    for row, pred in [[k, v.items()] for k, v in predictions.items() if len(v) ==3]:\n",
    "        a = pred[0][1]\n",
    "        b = pred[1][1]\n",
    "        c = pred[2][1]\n",
    "\n",
    "        if a == b and b==c:\n",
    "            new_pred[row] = \" |aprediction \" + str(pred[0][0]) + \":0.33\" + \" \" + str(pred[1][0]) + \":0.33\" + \\\n",
    "                                                                            \" \" + str(pred[2][0]) + \":0.33\"\n",
    "        else:\n",
    "            sorted_preds = sorted(pred, key= lambda t: t[1], reverse=True)\n",
    "            a = sorted_preds[0][1]\n",
    "            b = sorted_preds[1][1]\n",
    "            if a == b:\n",
    "                new_pred[row] = \" |aprediction \" + str(sorted_preds[0][0]) + \":0.5\" + \" \" + \\\n",
    "                                                        str(sorted_preds[1][0]) + \":0.5\"\n",
    "            else:\n",
    "                new_pred[row] = \" |aprediction \" + str(sorted_preds[0][0]) + \":1\"      \n",
    "    \n",
    "    \n",
    "    #####################\n",
    "    for row, pred in [[k, v.items()] for k, v in predictions.items() if len(v) ==4]:\n",
    "        a = pred[0][1]\n",
    "        b = pred[1][1]\n",
    "        c = pred[2][1]\n",
    "        d = pred[3][1]\n",
    "\n",
    "        if a == b and b==c and c==d:\n",
    "            new_pred[row] = \" |aprediction \" + str(pred[0][0]) + \":0.25\" + \" \" + str(pred[1][0]) + \":0.25\" + \\\n",
    "                                       \" \" + str(pred[2][0]) + \":0.25\" + \" \" + str(pred[3][0]) + \":0.25\"\n",
    "        else:\n",
    "            sorted_preds = sorted(pred, key= lambda t: t[1], reverse=True)\n",
    "            a = sorted_preds[0][1]\n",
    "            b = sorted_preds[1][1]\n",
    "            c = sorted_preds[2][1]\n",
    "            if a == b and b==c:\n",
    "                new_pred[row] = \" |aprediction \" + str(sorted_preds[0][0]) + \":0.33\" + \" \" + \\\n",
    "                                           str(sorted_preds[1][0]) + \":0.33\" + \" \" + str(sorted_preds[2][0]) + \":0.33\"\n",
    "            else:\n",
    "                sorted_preds2 = sorted(sorted_preds, key= lambda t: t[1], reverse=True)\n",
    "                a = sorted_preds2[0][1]\n",
    "                b = sorted_preds2[1][1]\n",
    "                if a == b:\n",
    "                    new_pred[row] = \" |aprediction \" + str(sorted_preds2[0][0]) + \":0.5\" + \" \" + \\\n",
    "                                                        str(sorted_preds2[1][0]) + \":0.5\"\n",
    "                else:\n",
    "                    new_pred[row] = \" |aprediction \" + str(sorted_preds2[0][0]) + \":1\"\n",
    "    \n",
    "    return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_user_site_dic(train_data, site_freq_pkl):\n",
    "    user_dic = {}\n",
    "    site_dic = {}\n",
    "\n",
    "    pkl_file = open(site_freq_pkl, 'rb')\n",
    "    site_freq = pickle.load(pkl_file)\n",
    "    #top_sites = [v[1] for k, v in sorted(site_freq.items(), key=lambda t: t[1][1], reverse=True)[:0]]\n",
    "    \n",
    "    for i, v in train_data.iterrows():\n",
    "        if v.target not in user_dic:\n",
    "            user_dic[v.target] = {}\n",
    "        for site in ['site' + str(i) for i in range(1,11)]:\n",
    "            if int(v[site]) != 0: #and v[site] not in top_sites:\n",
    "                if v[site] in user_dic[v.target]:\n",
    "                    user_dic[v.target][v[site]] +=1\n",
    "                else:\n",
    "                    user_dic[v.target][v[site]] = 1\n",
    "\n",
    "                if v[site] in site_dic:\n",
    "                    site_dic[v[site]].add(v.target)\n",
    "                else:\n",
    "                    site_dic[v[site]] = set([v.target])\n",
    "    \n",
    "    return user_dic, site_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 s, sys: 212 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = pd.read_csv('full_train_w8.csv')\n",
    "test_data = pd.read_csv('full_test.csv')\n",
    "\n",
    "train_site_sequence = csr_matrix(train_data[['site' + str(c) for c in range(1,10+1)]].as_matrix(), dtype=int)\n",
    "test_site_sequence = csr_matrix(test_data[['site' + str(c) for c in range(1,10+1)]].as_matrix(), dtype=int)\n",
    "\n",
    "#test_predictions = calc_predictions(train_data, test_data)\n",
    "\n",
    "# Additionally, let's calculate the percentage of session time spent by every site in session\n",
    "site_times = calc_site_times_portions(train_data, test_data)\n",
    "\n",
    "# Convert site times to sparse format\n",
    "site_times_sparse = site_times_to_sparse(site_times)\n",
    "train_site_times_sparse = site_times_sparse[:len(train_data)]\n",
    "test_site_times_sparse = site_times_sparse[len(train_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 256 ms, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_dic, site_dic = create_user_site_dic(train_data, \"site_freq.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_predictions, test_predictions = calc_predictions(train_data, test_data, \\\n",
    "                                                       site_dic, user_dic, 1, 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 4 ms, total: 17.5 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_preds = {}\n",
    "for k, v in train_predictions.items():\n",
    "    train_preds[k] = {}\n",
    "    for user, count in v.items():\n",
    "        if count not in train_preds[k]:\n",
    "            train_preds[k][count] = [user]\n",
    "        else:\n",
    "            train_preds[k][count].append(user)\n",
    "    train_preds[k] = train_preds[k][np.max(train_preds[k].keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.54 s, sys: 4 ms, total: 6.54 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_preds = {}\n",
    "for k, v in test_predictions.items():\n",
    "    test_preds[k] = {}\n",
    "    for user, count in v.items():\n",
    "        if count not in test_preds[k]:\n",
    "            test_preds[k][count] = [user]\n",
    "        else:\n",
    "            test_preds[k][count].append(user)\n",
    "    test_preds[k] = test_preds[k][np.max(test_preds[k].keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 132 ms, total: 1min 17s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_test_df = pd.concat([train_data, test_data])\n",
    "train_index_full = list(train_data.index)\n",
    "session_length = 10\n",
    "train_index_dup = list(train_data[train_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                       [['site' + str(c) for c in range(1,10+1)]+[\"target\"]].index)\n",
    "test_index_full = list(test_data.index)\n",
    "test_index_dup = list(test_data[test_data.duplicated(subset=['site' + str(c) for c in range(1,session_length+1)], keep=False)]\\\n",
    "                       [['site' + str(c) for c in range(1,10+1)]].index)\n",
    "train_duplicates_mask = np.transpose([np.in1d(train_index_full, train_index_dup).astype(int)])\n",
    "test_duplicates_mask = np.transpose([np.in1d(test_index_full, test_index_dup).astype(int)])\n",
    "\n",
    "y = train_data[\"target\"]\n",
    "\n",
    "train_test_df_sites = train_test_df[['site' + str(c) for c in range(1,10+1)]].fillna(0).astype('int')\n",
    "train_test_df_sites_array = [\" \".join([\"s_\"+str(s) for s in train_test_df_sites.as_matrix()[i] if int(s) != 0]) \\\n",
    "                                                              for i in range(train_test_df_sites.shape[0])]\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer=str.split, max_df=0.95, ngram_range=(1,3)).fit(train_test_df_sites_array) #TfidfVectorizer()\n",
    "X_train_test_sparse = tfidf.transform(train_test_df_sites_array)\n",
    "#X_train_test_sparse = TruncatedSVD(n_components=10000).fit_transform(X_train_test_sparse)\n",
    "\n",
    "X_train_sparse = X_train_test_sparse[:len(train_data)]\n",
    "X_test_sparse = X_train_test_sparse[len(train_data):]\n",
    "\n",
    "class_encoder = LabelEncoder().fit(y.astype('str'))\n",
    "y_for_vw = class_encoder.transform(y.astype('str')) + 1\n",
    "\n",
    "sites_columns_num = X_train_test_sparse.shape[1]\n",
    "inv_vocabulary = {v: int(re.search(\"s_(\\d+)$\", k).group(1)) for k, v in tfidf.vocabulary_.iteritems()}\n",
    "\n",
    "y_weights = [(np.sum(Counter(y_for_vw).values()) - v + min((Counter(y_for_vw).values())))/ \\\n",
    "            float(np.sum(Counter(y_for_vw).values())) for k, v in sorted(Counter(y_for_vw).items())]\n",
    "\n",
    "#y_weights = [round(np.max(Counter(y_for_vw).values())/float(v), 3) for k, v in sorted(Counter(y_for_vw).items())]\n",
    "#y_weights = [1]*550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "CPU times: user 53min 36s, sys: 580 ms, total: 53min 37s\n",
      "Wall time: 53min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "for r, p in train_preds.items():\n",
    "    if len(p) == 1:\n",
    "        row.append(r)\n",
    "        col.append(np.array(class_encoder.transform([str(p[0])])+1)[0])\n",
    "        data.append(100)\n",
    "    else:\n",
    "        for us in p:\n",
    "            row.append(r)\n",
    "            col.append((np.array(class_encoder.transform([str(us)])+1)[0]))\n",
    "            data.append(round(100./len(p), 0))\n",
    "print max(col)\n",
    "train_preds_sparse = csr_matrix((data, (row, col)), shape=(train_data.shape[0], 551), dtype=float)[:,1:]\n",
    "\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "for r, p in test_preds.items():\n",
    "    if len(p) == 1:\n",
    "        row.append(r)\n",
    "        col.append(np.array(class_encoder.transform([str(p[0])])+1)[0])\n",
    "        data.append(100)\n",
    "    else:\n",
    "        for us in p:\n",
    "            row.append(r)\n",
    "            col.append((np.array(class_encoder.transform([str(us)])+1)[0]))\n",
    "            data.append(round(100./len(p), 0))\n",
    "test_preds_sparse = csr_matrix((data, (row, col)), shape=(test_data.shape[0], 551), dtype=float)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.11 s, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X_train_sparse, X_test_sparse, y, y_for_vw, sites_columns_num, class_encoder, tfidf, train_duplicates_mask, test_duplicates_mask = \\\n",
    "    #sites_to_sparse_tfidf(train_data, test_data, \"target\", 10, label_encoder=LabelEncoder())\n",
    "\n",
    "mycolumns = [label for label in test_data[range(20, test_data.shape[1])]]\n",
    "\n",
    "train_features, test_features = features_to_sparse(train_data, test_data, mycolumns)\n",
    "\n",
    "X_train_sparse, X_test_sparse = combine_sites_features_sparse(X_train_sparse, train_features, train_preds_sparse, \\\n",
    "                                                             X_test_sparse, test_features, test_preds_sparse, \\\n",
    "                                                              train_duplicates_mask, test_duplicates_mask,\n",
    "                                                              train_site_times_sparse, test_site_times_sparse, \\\n",
    "                                                             train_site_sequence, test_site_sequence)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_sparse, y_for_vw, test_size=0.3, stratify=y_for_vw)\n",
    "\n",
    "y_train_weights = [(np.sum(Counter(y_train).values()) - v + min((Counter(y_train).values()))) / \\\n",
    "                   float(np.sum(Counter(y_train).values())) for k, v in sorted(Counter(y_train).items())]\n",
    "\n",
    "#y_train_weights = [round(np.max(Counter(y_train).values())/float(v), 3) for k, v in sorted(Counter(y_train).items())]\n",
    "#y_train_weights = [1] * 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 23s, sys: 4.36 s, total: 17min 28s\n",
      "Wall time: 17min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_part_vw = sparse_matrix_to_vw(X_train, sites_columns_num, inv_vocabulary, y_train, weights=y_train_weights)\n",
    "valid_vw = sparse_matrix_to_vw(X_valid, sites_columns_num, inv_vocabulary, y_valid)\n",
    "train_vw = sparse_matrix_to_vw(X_train_sparse, sites_columns_num, inv_vocabulary, y_for_vw, weights=y_weights)\n",
    "test_vw = sparse_matrix_to_vw(X_test_sparse, sites_columns_num, inv_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0.997895837417',\n",
       " 1: '0.979468078155',\n",
       " 2: '0.998536234725',\n",
       " 3: '0.996039992158',\n",
       " 4: '0.983415016663',\n",
       " 5: '0.99567405084',\n",
       " 6: '0.99907207737',\n",
       " 7: '0.988681957786',\n",
       " 8: '0.999045938705',\n",
       " 9: '0.996915637457',\n",
       " 10: '0.994811474874',\n",
       " 11: '0.999241978697',\n",
       " 12: '0.965026465399',\n",
       " 13: '0.983415016663',\n",
       " 14: '0.965026465399',\n",
       " 15: '0.998065738744',\n",
       " 16: '0.998405541397',\n",
       " 17: '0.997621381428',\n",
       " 18: '0.994811474874',\n",
       " 19: '0.997595242763',\n",
       " 20: '0.987884728485',\n",
       " 21: '0.997621381428',\n",
       " 22: '0.999307325361',\n",
       " 23: '0.997046330785',\n",
       " 24: '0.999085146703',\n",
       " 25: '0.997686728093',\n",
       " 26: '0.992040776318',\n",
       " 27: '0.987884728485',\n",
       " 28: '0.997503757433',\n",
       " 29: '0.99967326668',\n",
       " 30: '0.997007122786',\n",
       " 31: '0.998183362739',\n",
       " 32: '0.994105730902',\n",
       " 33: '0.986277200549',\n",
       " 34: '0.99725544011',\n",
       " 35: '0.983990067307',\n",
       " 36: '0.99474612821',\n",
       " 37: '0.997177024113',\n",
       " 38: '0.983415016663',\n",
       " 39: '0.99949029602',\n",
       " 40: '0.99925504803',\n",
       " 41: '0.99883682938',\n",
       " 42: '0.999150493367',\n",
       " 43: '0.993596026923',\n",
       " 44: '0.997686728093',\n",
       " 45: '0.995896229497',\n",
       " 46: '0.987858589819',\n",
       " 47: '0.990720773705',\n",
       " 48: '0.994641573548',\n",
       " 49: '0.995033653532',\n",
       " 50: '0.997974253414',\n",
       " 51: '0.998013461413',\n",
       " 52: '0.998157224074',\n",
       " 53: '0.999817029341',\n",
       " 54: '0.995242762857',\n",
       " 55: '0.999803960008',\n",
       " 56: '0.999725544011',\n",
       " 57: '0.999516434686',\n",
       " 58: '0.998719205385',\n",
       " 59: '0.983362739332',\n",
       " 60: '0.999568712017',\n",
       " 61: '0.998261778736',\n",
       " 62: '0.998693066719',\n",
       " 63: '0.99851009606',\n",
       " 64: '0.999189701366',\n",
       " 65: '0.991518003006',\n",
       " 66: '0.99567405084',\n",
       " 67: '0.987793243155',\n",
       " 68: '0.983990067307',\n",
       " 69: '0.996915637457',\n",
       " 70: '0.994785336209',\n",
       " 71: '0.997503757433',\n",
       " 72: '0.988681957786',\n",
       " 73: '0.995608704176',\n",
       " 74: '0.986277200549',\n",
       " 75: '0.983362739332',\n",
       " 76: '0.99883682938',\n",
       " 77: '0.999111285369',\n",
       " 78: '0.989779781742',\n",
       " 79: '0.99841861073',\n",
       " 80: '0.991282755015',\n",
       " 81: '0.998810690714',\n",
       " 82: '0.999150493367',\n",
       " 83: '0.998104946742',\n",
       " 84: '0.995268901523',\n",
       " 85: '0.998261778736',\n",
       " 86: '0.998431680063',\n",
       " 87: '0.996641181468',\n",
       " 88: '0.999268117363',\n",
       " 89: '0.983990067307',\n",
       " 90: '0.999817029341',\n",
       " 91: '0.99474612821',\n",
       " 92: '0.998967522708',\n",
       " 93: '0.999268117363',\n",
       " 94: '0.99892831471',\n",
       " 95: '0.994105730902',\n",
       " 96: '0.991282755015',\n",
       " 97: '0.996628112135',\n",
       " 98: '0.994641573548',\n",
       " 99: '0.996771874796',\n",
       " 100: '0.999686336013',\n",
       " 101: '0.999294256028',\n",
       " 102: '0.999320394694',\n",
       " 103: '0.983362739332',\n",
       " 104: '0.998640789388',\n",
       " 105: '0.983415016663',\n",
       " 106: '0.999634058681',\n",
       " 107: '0.994811474874',\n",
       " 108: '0.996771874796',\n",
       " 109: '0.999542573352',\n",
       " 110: '0.999725544011',\n",
       " 111: '0.983415016663',\n",
       " 112: '0.979468078155',\n",
       " 113: '0.996771874796',\n",
       " 114: '0.999856237339',\n",
       " 115: '0.997464549435',\n",
       " 116: '0.996445141476',\n",
       " 117: '0.999359602692',\n",
       " 118: '0.99800039208',\n",
       " 119: '0.983362739332',\n",
       " 120: '0.996680389466',\n",
       " 121: '0.99716395478',\n",
       " 122: '0.997307717441',\n",
       " 123: '0.999045938705',\n",
       " 124: '0.994863752205',\n",
       " 125: '0.998157224074',\n",
       " 126: '0.994602365549',\n",
       " 127: '0.996131477488',\n",
       " 128: '0.990720773705',\n",
       " 129: '0.995608704176',\n",
       " 130: '0.994354048226',\n",
       " 131: '0.999228909364',\n",
       " 132: '0.991518003006',\n",
       " 133: '0.983990067307',\n",
       " 134: '0.996157616154',\n",
       " 135: '0.998915245377',\n",
       " 136: '0.983990067307',\n",
       " 137: '0.995765536169',\n",
       " 138: '0.995608704176',\n",
       " 139: '0.994968306868',\n",
       " 140: '0.996484349474',\n",
       " 141: '0.998693066719',\n",
       " 142: '0.983415016663',\n",
       " 143: '0.997595242763',\n",
       " 144: '0.998287917402',\n",
       " 145: '0.998261778736',\n",
       " 146: '0.995791674835',\n",
       " 147: '0.986277200549',\n",
       " 148: '0.995608704176',\n",
       " 149: '0.991282755015',\n",
       " 150: '0.990720773705',\n",
       " 151: '0.998235640071',\n",
       " 152: '0.965026465399',\n",
       " 153: '0.996053061491',\n",
       " 154: '0.999111285369',\n",
       " 155: '0.997778213422',\n",
       " 156: '0.998196432072',\n",
       " 157: '0.998575442724',\n",
       " 158: '0.999751682677',\n",
       " 159: '0.999568712017',\n",
       " 160: '0.999006730706',\n",
       " 161: '0.998144154741',\n",
       " 162: '0.987884728485',\n",
       " 163: '0.998653858721',\n",
       " 164: '0.998693066719',\n",
       " 165: '0.999359602692',\n",
       " 166: '0.998104946742',\n",
       " 167: '0.99925504803',\n",
       " 168: '0.996405933477',\n",
       " 169: '0.999856237339',\n",
       " 170: '0.99841861073',\n",
       " 171: '0.994184146899',\n",
       " 172: '0.997033261452',\n",
       " 173: '0.999477226688',\n",
       " 174: '0.965026465399',\n",
       " 175: '0.979468078155',\n",
       " 176: '0.992040776318',\n",
       " 177: '0.987793243155',\n",
       " 178: '0.99725544011',\n",
       " 179: '0.997869698752',\n",
       " 180: '0.993596026923',\n",
       " 181: '0.987858589819',\n",
       " 182: '0.998222570738',\n",
       " 183: '0.998353264066',\n",
       " 184: '0.995765536169',\n",
       " 185: '0.999817029341',\n",
       " 186: '0.997046330785',\n",
       " 187: '0.983362739332',\n",
       " 188: '0.983362739332',\n",
       " 189: '0.999594850683',\n",
       " 190: '0.987858589819',\n",
       " 191: '0.996118408155',\n",
       " 192: '0.99874534405',\n",
       " 193: '0.999228909364',\n",
       " 194: '0.999137424035',\n",
       " 195: '0.994105730902',\n",
       " 196: '0.998274848069',\n",
       " 197: '0.995268901523',\n",
       " 198: '0.997503757433',\n",
       " 199: '0.998693066719',\n",
       " 200: '0.996732666797',\n",
       " 201: '0.996405933477',\n",
       " 202: '0.996523557472',\n",
       " 203: '0.998222570738',\n",
       " 204: '0.997137816114',\n",
       " 205: '0.996941776122',\n",
       " 206: '0.998758413383',\n",
       " 207: '0.998849898713',\n",
       " 208: '0.995765536169',\n",
       " 209: '0.999764752009',\n",
       " 210: '0.998627720055',\n",
       " 211: '0.99567405084',\n",
       " 212: '0.997621381428',\n",
       " 213: '0.996732666797',\n",
       " 214: '0.993635234921',\n",
       " 215: '0.99841861073',\n",
       " 216: '0.991282755015',\n",
       " 217: '0.995987714827',\n",
       " 218: '0.965026465399',\n",
       " 219: '0.999320394694',\n",
       " 220: '0.998235640071',\n",
       " 221: '0.996771874796',\n",
       " 222: '0.998902176044',\n",
       " 223: '0.965026465399',\n",
       " 224: '0.994445533556',\n",
       " 225: '0.995791674835',\n",
       " 226: '0.996157616154',\n",
       " 227: '0.991518003006',\n",
       " 228: '0.999542573352',\n",
       " 229: '0.993635234921',\n",
       " 230: '0.99558256551',\n",
       " 231: '0.998627720055',\n",
       " 232: '0.991518003006',\n",
       " 233: '0.999817029341',\n",
       " 234: '0.996249101483',\n",
       " 235: '0.99692870679',\n",
       " 236: '0.999660197347',\n",
       " 237: '0.998065738744',\n",
       " 238: '0.999150493367',\n",
       " 239: '0.999150493367',\n",
       " 240: '0.996249101483',\n",
       " 241: '0.987884728485',\n",
       " 242: '0.994563157551',\n",
       " 243: '0.998261778736',\n",
       " 244: '0.998183362739',\n",
       " 245: '0.994445533556',\n",
       " 246: '0.998693066719',\n",
       " 247: '0.994968306868',\n",
       " 248: '0.998967522708',\n",
       " 249: '0.999085146703',\n",
       " 250: '0.999634058681',\n",
       " 251: '0.999333464027',\n",
       " 252: '0.99725544011',\n",
       " 253: '0.999751682677',\n",
       " 254: '0.99641900281',\n",
       " 255: '0.99567405084',\n",
       " 256: '0.999333464027',\n",
       " 257: '0.999647128014',\n",
       " 258: '0.989779781742',\n",
       " 259: '0.997595242763',\n",
       " 260: '0.983415016663',\n",
       " 261: '0.997778213422',\n",
       " 262: '0.994184146899',\n",
       " 263: '0.990720773705',\n",
       " 264: '0.998078808077',\n",
       " 265: '0.997333856107',\n",
       " 266: '0.998679997386',\n",
       " 267: '0.996732666797',\n",
       " 268: '0.979468078155',\n",
       " 269: '0.999294256028',\n",
       " 270: '0.989779781742',\n",
       " 271: '0.993635234921',\n",
       " 272: '0.996053061491',\n",
       " 273: '0.983415016663',\n",
       " 274: '0.995896229497',\n",
       " 275: '0.998431680063',\n",
       " 276: '0.998679997386',\n",
       " 277: '0.997843560086',\n",
       " 278: '0.999307325361',\n",
       " 279: '0.983990067307',\n",
       " 280: '0.987858589819',\n",
       " 281: '0.999686336013',\n",
       " 282: '0.998287917402',\n",
       " 283: '0.999385741358',\n",
       " 284: '0.965026465399',\n",
       " 285: '0.998065738744',\n",
       " 286: '0.983415016663',\n",
       " 287: '0.987793243155',\n",
       " 288: '0.995033653532',\n",
       " 289: '0.999438018689',\n",
       " 290: '0.979468078155',\n",
       " 291: '0.986277200549',\n",
       " 292: '0.983362739332',\n",
       " 293: '0.998104946742',\n",
       " 294: '0.996249101483',\n",
       " 295: '0.996706528132',\n",
       " 296: '0.997137816114',\n",
       " 297: '0.998614650722',\n",
       " 298: '0.998536234725',\n",
       " 299: '0.983990067307',\n",
       " 300: '0.994863752205',\n",
       " 301: '0.995765536169',\n",
       " 302: '0.979468078155',\n",
       " 303: '0.996771874796',\n",
       " 304: '0.998666928053',\n",
       " 305: '0.986277200549',\n",
       " 306: '0.994994445534',\n",
       " 307: '0.99641900281',\n",
       " 308: '0.997686728093',\n",
       " 309: '0.995765536169',\n",
       " 310: '0.998679997386',\n",
       " 311: '0.994602365549',\n",
       " 312: '0.998640789388',\n",
       " 313: '0.996053061491',\n",
       " 314: '0.990720773705',\n",
       " 315: '0.986277200549',\n",
       " 316: '0.996954845455',\n",
       " 317: '0.999150493367',\n",
       " 318: '0.994354048226',\n",
       " 319: '0.987858589819',\n",
       " 320: '0.994811474874',\n",
       " 321: '0.996249101483',\n",
       " 322: '0.994184146899',\n",
       " 323: '0.991518003006',\n",
       " 324: '0.998353264066',\n",
       " 325: '0.997177024113',\n",
       " 326: '0.998287917402',\n",
       " 327: '0.999098216036',\n",
       " 328: '0.995242762857',\n",
       " 329: '0.99716395478',\n",
       " 330: '0.998562373391',\n",
       " 331: '0.995138208194',\n",
       " 332: '0.994994445534',\n",
       " 333: '0.992040776318',\n",
       " 334: '0.997712866758',\n",
       " 335: '0.99641900281',\n",
       " 336: '0.998104946742',\n",
       " 337: '0.997686728093',\n",
       " 338: '0.994445533556',\n",
       " 339: '0.983415016663',\n",
       " 340: '0.996628112135',\n",
       " 341: '0.999843168006',\n",
       " 342: '0.99567405084',\n",
       " 343: '0.994811474874',\n",
       " 344: '0.983415016663',\n",
       " 345: '0.99883682938',\n",
       " 346: '0.99558256551',\n",
       " 347: '0.996484349474',\n",
       " 348: '0.991282755015',\n",
       " 349: '0.965026465399',\n",
       " 350: '0.994968306868',\n",
       " 351: '0.99841861073',\n",
       " 352: '0.999019800039',\n",
       " 353: '0.995896229497',\n",
       " 354: '0.998902176044',\n",
       " 355: '0.995242762857',\n",
       " 356: '0.998666928053',\n",
       " 357: '0.999790890675',\n",
       " 358: '0.983362739332',\n",
       " 359: '0.996066130824',\n",
       " 360: '0.99851009606',\n",
       " 361: '0.999424949356',\n",
       " 362: '0.997686728093',\n",
       " 363: '0.997046330785',\n",
       " 364: '0.987793243155',\n",
       " 365: '0.999451088022',\n",
       " 366: '0.999385741358',\n",
       " 367: '0.99874534405',\n",
       " 368: '0.987884728485',\n",
       " 369: '0.999594850683',\n",
       " 370: '0.999777821342',\n",
       " 371: '0.996405933477',\n",
       " 372: '0.997464549435',\n",
       " 373: '0.998810690714',\n",
       " 374: '0.997595242763',\n",
       " 375: '0.998640789388',\n",
       " 376: '0.994994445534',\n",
       " 377: '0.994785336209',\n",
       " 378: '0.998431680063',\n",
       " 379: '0.997856629419',\n",
       " 380: '0.997974253414',\n",
       " 381: '0.99474612821',\n",
       " 382: '0.997503757433',\n",
       " 383: '0.999307325361',\n",
       " 384: '0.999973861334',\n",
       " 385: '0.99641900281',\n",
       " 386: '0.983415016663',\n",
       " 387: '0.996771874796',\n",
       " 388: '0.999803960008',\n",
       " 389: '0.998314056067',\n",
       " 390: '0.998431680063',\n",
       " 391: '0.999503365353',\n",
       " 392: '0.999111285369',\n",
       " 393: '0.994445533556',\n",
       " 394: '0.993635234921',\n",
       " 395: '0.997869698752',\n",
       " 396: '0.983415016663',\n",
       " 397: '0.99949029602',\n",
       " 398: '0.994445533556',\n",
       " 399: '0.994602365549',\n",
       " 400: '0.983415016663',\n",
       " 401: '0.997242370777',\n",
       " 402: '0.997621381428',\n",
       " 403: '0.999294256028',\n",
       " 404: '0.997856629419',\n",
       " 405: '0.996405933477',\n",
       " 406: '0.996771874796',\n",
       " 407: '0.983990067307',\n",
       " 408: '0.996053061491',\n",
       " 409: '0.999111285369',\n",
       " 410: '0.998287917402',\n",
       " 411: '0.997869698752',\n",
       " 412: '0.997595242763',\n",
       " 413: '0.998679997386',\n",
       " 414: '0.99892831471',\n",
       " 415: '0.998261778736',\n",
       " 416: '0.999712474678',\n",
       " 417: '0.99851009606',\n",
       " 418: '0.998287917402',\n",
       " 419: '0.965026465399',\n",
       " 420: '0.995268901523',\n",
       " 421: '0.998287917402',\n",
       " 422: '0.965026465399',\n",
       " 423: '0.983362739332',\n",
       " 424: '0.994785336209',\n",
       " 425: '0.999150493367',\n",
       " 426: '0.997621381428',\n",
       " 427: '0.997137816114',\n",
       " 428: '0.998640789388',\n",
       " 429: '0.992040776318',\n",
       " 430: '0.979468078155',\n",
       " 431: '0.995242762857',\n",
       " 432: '0.999607920016',\n",
       " 433: '0.999111285369',\n",
       " 434: '0.995791674835',\n",
       " 435: '0.995268901523',\n",
       " 436: '0.996066130824',\n",
       " 437: '0.993596026923',\n",
       " 438: '0.997739005424',\n",
       " 439: '0.99567405084',\n",
       " 440: '0.987793243155',\n",
       " 441: '0.999921584003',\n",
       " 442: '0.998405541397',\n",
       " 443: '0.997046330785',\n",
       " 444: '0.995242762857',\n",
       " 445: '0.998640789388',\n",
       " 446: '0.996680389466',\n",
       " 447: '0.99892831471',\n",
       " 448: '0.995765536169',\n",
       " 449: '0.997752074757',\n",
       " 450: '0.999764752009',\n",
       " 451: '0.996118408155',\n",
       " 452: '0.983415016663',\n",
       " 453: '0.999647128014',\n",
       " 454: '0.998902176044',\n",
       " 455: '0.99558256551',\n",
       " 456: '0.998196432072',\n",
       " 457: '0.998287917402',\n",
       " 458: '0.998235640071',\n",
       " 459: '0.998104946742',\n",
       " 460: '0.998314056067',\n",
       " 461: '0.996039992158',\n",
       " 462: '0.998497026727',\n",
       " 463: '0.996628112135',\n",
       " 464: '0.99967326668',\n",
       " 465: '0.991518003006',\n",
       " 466: '0.99716395478',\n",
       " 467: '0.996445141476',\n",
       " 468: '0.989779781742',\n",
       " 469: '0.999294256028',\n",
       " 470: '0.991518003006',\n",
       " 471: '0.965026465399',\n",
       " 472: '0.998405541397',\n",
       " 473: '0.999098216036',\n",
       " 474: '0.99725544011',\n",
       " 475: '0.965026465399',\n",
       " 476: '0.994641573548',\n",
       " 477: '0.999385741358',\n",
       " 478: '0.997765144089',\n",
       " 479: '0.994105730902',\n",
       " 480: '0.9983271254',\n",
       " 481: '0.983362739332',\n",
       " 482: '0.998575442724',\n",
       " 483: '0.990720773705',\n",
       " 484: '0.999660197347',\n",
       " 485: '0.999647128014',\n",
       " 486: '0.999320394694',\n",
       " 487: '0.994785336209',\n",
       " 488: '0.996013853493',\n",
       " 489: '0.999320394694',\n",
       " 490: '0.997948114749',\n",
       " 491: '0.998562373391',\n",
       " 492: '0.997869698752',\n",
       " 493: '0.999686336013',\n",
       " 494: '0.99716395478',\n",
       " 495: '0.997686728093',\n",
       " 496: '0.996039992158',\n",
       " 497: '0.987858589819',\n",
       " 498: '0.983415016663',\n",
       " 499: '0.986277200549',\n",
       " 500: '0.997438410769',\n",
       " 501: '0.997739005424',\n",
       " 502: '0.998666928053',\n",
       " 503: '0.995268901523',\n",
       " 504: '0.992040776318',\n",
       " 505: '0.965026465399',\n",
       " 506: '0.998876037378',\n",
       " 507: '0.996706528132',\n",
       " 508: '0.965026465399',\n",
       " 509: '0.997765144089',\n",
       " 510: '0.99949029602',\n",
       " 511: '0.998078808077',\n",
       " 512: '0.965026465399',\n",
       " 513: '0.998849898713',\n",
       " 514: '0.995896229497',\n",
       " 515: '0.994602365549',\n",
       " 516: '0.999411880024',\n",
       " 517: '0.997974253414',\n",
       " 518: '0.999843168006',\n",
       " 519: '0.997124746782',\n",
       " 520: '0.994354048226',\n",
       " 521: '0.996157616154',\n",
       " 522: '0.997124746782',\n",
       " 523: '0.994863752205',\n",
       " 524: '0.997046330785',\n",
       " 525: '0.996641181468',\n",
       " 526: '0.965026465399',\n",
       " 527: '0.994184146899',\n",
       " 528: '0.995765536169',\n",
       " 529: '0.998104946742',\n",
       " 530: '0.994785336209',\n",
       " 531: '0.999869306672',\n",
       " 532: '0.997438410769',\n",
       " 533: '0.993635234921',\n",
       " 534: '0.997242370777',\n",
       " 535: '0.987793243155',\n",
       " 536: '0.994563157551',\n",
       " 537: '0.997464549435',\n",
       " 538: '0.983990067307',\n",
       " 539: '0.965026465399',\n",
       " 540: '0.994563157551',\n",
       " 541: '0.994785336209',\n",
       " 542: '0.987793243155',\n",
       " 543: '0.996706528132',\n",
       " 544: '0.997595242763',\n",
       " 545: '0.997712866758',\n",
       " 546: '0.998287917402',\n",
       " 547: '0.994563157551',\n",
       " 548: '0.998287917402',\n",
       " 549: '0.99883682938',\n",
       " 550: '0.99800039208',\n",
       " 551: '0.999268117363',\n",
       " 552: '0.99567405084',\n",
       " 553: '0.987858589819',\n",
       " 554: '0.999202770699',\n",
       " 555: '0.99549108018',\n",
       " 556: '0.999346533359',\n",
       " 557: '0.997242370777',\n",
       " 558: '0.987884728485',\n",
       " 559: '0.999686336013',\n",
       " 560: '0.986277200549',\n",
       " 561: '0.99558256551',\n",
       " 562: '0.999359602692',\n",
       " 563: '0.994105730902',\n",
       " 564: '0.998941384042',\n",
       " 565: '0.998078808077',\n",
       " 566: '0.998287917402',\n",
       " 567: '0.997843560086',\n",
       " 568: '0.999830098673',\n",
       " 569: '0.988681957786',\n",
       " 570: '0.99549108018',\n",
       " 571: '0.996628112135',\n",
       " 572: '0.994563157551',\n",
       " 573: '0.994354048226',\n",
       " 574: '0.987884728485',\n",
       " 575: '0.996980984121',\n",
       " 576: '0.995608704176',\n",
       " 577: '0.999385741358',\n",
       " 578: '0.996954845455',\n",
       " 579: '0.994863752205',\n",
       " 580: '0.998640789388',\n",
       " 581: '0.997686728093',\n",
       " 582: '0.999830098673',\n",
       " 583: '0.999137424035',\n",
       " 584: '0.999411880024',\n",
       " 585: '0.996039992158',\n",
       " 586: '0.987858589819',\n",
       " 587: '0.994785336209',\n",
       " 588: '0.979468078155',\n",
       " 589: '0.997686728093',\n",
       " 590: '0.993635234921',\n",
       " 591: '0.996066130824',\n",
       " 592: '0.994994445534',\n",
       " 593: '0.998797621381',\n",
       " 594: '0.995242762857',\n",
       " 595: '0.983990067307',\n",
       " 596: '0.998078808077',\n",
       " 597: '0.99925504803',\n",
       " 598: '0.993635234921',\n",
       " 599: '0.995242762857',\n",
       " 600: '0.983415016663',\n",
       " 601: '0.998353264066',\n",
       " 602: '0.999294256028',\n",
       " 603: '0.998287917402',\n",
       " 604: '0.997739005424',\n",
       " 605: '0.99809187741',\n",
       " 606: '0.987884728485',\n",
       " 607: '0.994811474874',\n",
       " 608: '0.999411880024',\n",
       " 609: '0.998431680063',\n",
       " 610: '0.995033653532',\n",
       " 611: '0.995896229497',\n",
       " 612: '0.999529504019',\n",
       " 613: '0.997137816114',\n",
       " 614: '0.997333856107',\n",
       " 615: '0.998353264066',\n",
       " 616: '0.986277200549',\n",
       " 617: '0.997895837417',\n",
       " 618: '0.996118408155',\n",
       " 619: '0.998144154741',\n",
       " 620: '0.997817421421',\n",
       " 621: '0.983990067307',\n",
       " 622: '0.994811474874',\n",
       " 623: '0.999516434686',\n",
       " 624: '0.999777821342',\n",
       " 625: '0.996771874796',\n",
       " 626: '0.999111285369',\n",
       " 627: '0.996131477488',\n",
       " 628: '0.999751682677',\n",
       " 629: '0.998104946742',\n",
       " 630: '0.999764752009',\n",
       " 631: '0.99474612821',\n",
       " 632: '0.965026465399',\n",
       " 633: '0.994105730902',\n",
       " 634: '0.983362739332',\n",
       " 635: '0.988681957786',\n",
       " 636: '0.99725544011',\n",
       " 637: '0.998235640071',\n",
       " 638: '0.998405541397',\n",
       " 639: '0.996053061491',\n",
       " 640: '0.996249101483',\n",
       " 641: '0.989779781742',\n",
       " 642: '0.998666928053',\n",
       " 643: '0.998915245377',\n",
       " 644: '0.997464549435',\n",
       " 645: '0.998758413383',\n",
       " 646: '0.997869698752',\n",
       " 647: '0.999451088022',\n",
       " 648: '0.998261778736',\n",
       " 649: '0.988681957786',\n",
       " 650: '0.996053061491',\n",
       " 651: '0.997098608116',\n",
       " 652: '0.99692870679',\n",
       " 653: '0.983415016663',\n",
       " 654: '0.999019800039',\n",
       " 655: '0.965026465399',\n",
       " 656: '0.994811474874',\n",
       " 657: '0.979468078155',\n",
       " 658: '0.995242762857',\n",
       " 659: '0.998693066719',\n",
       " 660: '0.989779781742',\n",
       " 661: '0.998235640071',\n",
       " 662: '0.997503757433',\n",
       " 663: '0.994994445534',\n",
       " 664: '0.998758413383',\n",
       " 665: '0.997752074757',\n",
       " 666: '0.987793243155',\n",
       " 667: '0.999751682677',\n",
       " 668: '0.988681957786',\n",
       " 669: '0.999856237339',\n",
       " 670: '0.999006730706',\n",
       " 671: '0.965026465399',\n",
       " 672: '0.998849898713',\n",
       " 673: '0.996771874796',\n",
       " 674: '0.999503365353',\n",
       " 675: '0.999660197347',\n",
       " 676: '0.983990067307',\n",
       " 677: '0.998405541397',\n",
       " 678: '0.998797621381',\n",
       " 679: '0.986277200549',\n",
       " 680: '0.999307325361',\n",
       " 681: '0.998693066719',\n",
       " 682: '0.999006730706',\n",
       " 683: '0.996039992158',\n",
       " 684: '0.996732666797',\n",
       " 685: '0.965026465399',\n",
       " 686: '0.999268117363',\n",
       " 687: '0.998640789388',\n",
       " 688: '0.979468078155',\n",
       " 689: '0.996249101483',\n",
       " 690: '0.998523165392',\n",
       " 691: '0.997046330785',\n",
       " 692: '0.998353264066',\n",
       " 693: '0.997752074757',\n",
       " 694: '0.997503757433',\n",
       " 695: '0.999411880024',\n",
       " 696: '0.999424949356',\n",
       " 697: '0.996523557472',\n",
       " 698: '0.999385741358',\n",
       " 699: '0.997895837417',\n",
       " 700: '0.994445533556',\n",
       " 701: '0.994641573548',\n",
       " 702: '0.998457818728',\n",
       " 703: '0.99990851467',\n",
       " 704: '0.991282755015',\n",
       " 705: '0.998261778736',\n",
       " 706: '0.965026465399',\n",
       " 707: '0.998693066719',\n",
       " 708: '0.991282755015',\n",
       " 709: '0.99558256551',\n",
       " 710: '0.99841861073',\n",
       " 711: '0.999516434686',\n",
       " 712: '0.965026465399',\n",
       " 713: '0.987884728485',\n",
       " 714: '0.997686728093',\n",
       " 715: '0.983362739332',\n",
       " 716: '0.965026465399',\n",
       " 717: '0.999686336013',\n",
       " 718: '0.994105730902',\n",
       " 719: '0.997595242763',\n",
       " 720: '0.996405933477',\n",
       " 721: '0.995033653532',\n",
       " 722: '0.99474612821',\n",
       " 723: '0.999725544011',\n",
       " 724: '0.998353264066',\n",
       " 725: '0.996680389466',\n",
       " 726: '0.99692870679',\n",
       " 727: '0.996066130824',\n",
       " 728: '0.987884728485',\n",
       " 729: '0.997046330785',\n",
       " 730: '0.997712866758',\n",
       " 731: '0.999059008038',\n",
       " 732: '0.994994445534',\n",
       " 733: '0.994785336209',\n",
       " 734: '0.991518003006',\n",
       " 735: '0.998536234725',\n",
       " 736: '0.991282755015',\n",
       " 737: '0.998170293407',\n",
       " 738: '0.998144154741',\n",
       " 739: '0.998287917402',\n",
       " 740: '0.999803960008',\n",
       " 741: '0.965026465399',\n",
       " 742: '0.999725544011',\n",
       " 743: '0.999634058681',\n",
       " 744: '0.996680389466',\n",
       " 745: '0.998797621381',\n",
       " 746: '0.997621381428',\n",
       " 747: '0.996628112135',\n",
       " 748: '0.998405541397',\n",
       " 749: '0.996980984121',\n",
       " 750: '0.965026465399',\n",
       " 751: '0.99716395478',\n",
       " 752: '0.987793243155',\n",
       " 753: '0.995242762857',\n",
       " 754: '0.993596026923',\n",
       " 755: '0.999228909364',\n",
       " 756: '0.999503365353',\n",
       " 757: '0.998523165392',\n",
       " 758: '0.999411880024',\n",
       " 759: '0.979468078155',\n",
       " 760: '0.994105730902',\n",
       " 761: '0.997137816114',\n",
       " 762: '0.996405933477',\n",
       " 763: '0.999555642684',\n",
       " 764: '0.995987714827',\n",
       " 765: '0.997046330785',\n",
       " 766: '0.997438410769',\n",
       " 767: '0.99558256551',\n",
       " 768: '0.99474612821',\n",
       " 769: '0.99841861073',\n",
       " 770: '0.993596026923',\n",
       " 771: '0.998640789388',\n",
       " 772: '0.997333856107',\n",
       " 773: '0.997177024113',\n",
       " 774: '0.995896229497',\n",
       " 775: '0.994445533556',\n",
       " 776: '0.989779781742',\n",
       " 777: '0.994994445534',\n",
       " 778: '0.994184146899',\n",
       " 779: '0.987793243155',\n",
       " 780: '0.996053061491',\n",
       " 781: '0.983415016663',\n",
       " 782: '0.99567405084',\n",
       " 783: '0.999503365353',\n",
       " 784: '0.997974253414',\n",
       " 785: '0.999594850683',\n",
       " 786: '0.987884728485',\n",
       " 787: '0.987858589819',\n",
       " 788: '0.999817029341',\n",
       " 789: '0.994641573548',\n",
       " 790: '0.999607920016',\n",
       " 791: '0.983990067307',\n",
       " 792: '0.965026465399',\n",
       " 793: '0.995242762857',\n",
       " 794: '0.999320394694',\n",
       " 795: '0.987793243155',\n",
       " 796: '0.998353264066',\n",
       " 797: '0.998562373391',\n",
       " 798: '0.999607920016',\n",
       " 799: '0.997046330785',\n",
       " 800: '0.987858589819',\n",
       " 801: '0.987858589819',\n",
       " 802: '0.996013853493',\n",
       " 803: '0.99949029602',\n",
       " 804: '0.999516434686',\n",
       " 805: '0.99841861073',\n",
       " 806: '0.998693066719',\n",
       " 807: '0.998693066719',\n",
       " 808: '0.995138208194',\n",
       " 809: '0.994641573548',\n",
       " 810: '0.998170293407',\n",
       " 811: '0.997843560086',\n",
       " 812: '0.99851009606',\n",
       " 813: '0.996628112135',\n",
       " 814: '0.993635234921',\n",
       " 815: '0.997007122786',\n",
       " 816: '0.999803960008',\n",
       " 817: '0.998640789388',\n",
       " 818: '0.986277200549',\n",
       " 819: '0.99558256551',\n",
       " 820: '0.998640789388',\n",
       " 821: '0.99567405084',\n",
       " 822: '0.99841861073',\n",
       " 823: '0.99692870679',\n",
       " 824: '0.999111285369',\n",
       " 825: '0.999686336013',\n",
       " 826: '0.999712474678',\n",
       " 827: '0.993635234921',\n",
       " 828: '0.99800039208',\n",
       " 829: '0.999856237339',\n",
       " 830: '0.99874534405',\n",
       " 831: '0.99925504803',\n",
       " 832: '0.999320394694',\n",
       " 833: '0.998902176044',\n",
       " 834: '0.996039992158',\n",
       " 835: '0.991282755015',\n",
       " 836: '0.998287917402',\n",
       " 837: '0.999647128014',\n",
       " 838: '0.994105730902',\n",
       " 839: '0.992040776318',\n",
       " 840: '0.998693066719',\n",
       " 841: '0.999359602692',\n",
       " 842: '0.998536234725',\n",
       " 843: '0.994602365549',\n",
       " 844: '0.998679997386',\n",
       " 845: '0.998536234725',\n",
       " 846: '0.983990067307',\n",
       " 847: '0.965026465399',\n",
       " 848: '0.996013853493',\n",
       " 849: '0.989779781742',\n",
       " 850: '0.998405541397',\n",
       " 851: '0.986277200549',\n",
       " 852: '0.979468078155',\n",
       " 853: '0.983362739332',\n",
       " 854: '0.991518003006',\n",
       " 855: '0.99925504803',\n",
       " 856: '0.99641900281',\n",
       " 857: '0.994445533556',\n",
       " 858: '0.993596026923',\n",
       " 859: '0.996523557472',\n",
       " 860: '0.998823760047',\n",
       " 861: '0.999059008038',\n",
       " 862: '0.997137816114',\n",
       " 863: '0.986277200549',\n",
       " 864: '0.99892831471',\n",
       " 865: '0.987793243155',\n",
       " 866: '0.999817029341',\n",
       " 867: '0.988681957786',\n",
       " 868: '0.997974253414',\n",
       " 869: '0.995791674835',\n",
       " 870: '0.99851009606',\n",
       " 871: '0.994863752205',\n",
       " 872: '0.965026465399',\n",
       " 873: '0.983415016663',\n",
       " 874: '0.993635234921',\n",
       " 875: '0.994968306868',\n",
       " 876: '0.99692870679',\n",
       " 877: '0.996405933477',\n",
       " 878: '0.994785336209',\n",
       " 879: '0.998719205385',\n",
       " 880: '0.999503365353',\n",
       " 881: '0.987858589819',\n",
       " 882: '0.983990067307',\n",
       " 883: '0.994354048226',\n",
       " 884: '0.997765144089',\n",
       " 885: '0.999385741358',\n",
       " 886: '0.996771874796',\n",
       " 887: '0.99558256551',\n",
       " 888: '0.997817421421',\n",
       " 889: '0.999085146703',\n",
       " 890: '0.996131477488',\n",
       " 891: '0.998758413383',\n",
       " 892: '0.996706528132',\n",
       " 893: '0.999085146703',\n",
       " 894: '0.998758413383',\n",
       " 895: '0.997974253414',\n",
       " 896: '0.994354048226',\n",
       " 897: '0.965026465399',\n",
       " 898: '0.996980984121',\n",
       " 899: '0.999294256028',\n",
       " 900: '0.986277200549',\n",
       " 901: '0.999176632033',\n",
       " 902: '0.997739005424',\n",
       " 903: '0.998523165392',\n",
       " 904: '0.983990067307',\n",
       " 905: '0.999424949356',\n",
       " 906: '0.999059008038',\n",
       " 907: '0.992040776318',\n",
       " 908: '0.994863752205',\n",
       " 909: '0.999307325361',\n",
       " 910: '0.99567405084',\n",
       " 911: '0.99892831471',\n",
       " 912: '0.998915245377',\n",
       " 913: '0.996628112135',\n",
       " 914: '0.996066130824',\n",
       " 915: '0.997268509443',\n",
       " 916: '0.998065738744',\n",
       " 917: '0.996680389466',\n",
       " 918: '0.993596026923',\n",
       " 919: '0.997765144089',\n",
       " 920: '0.998536234725',\n",
       " 921: '0.999320394694',\n",
       " 922: '0.983990067307',\n",
       " 923: '0.999503365353',\n",
       " 924: '0.995987714827',\n",
       " 925: '0.994354048226',\n",
       " 926: '0.998693066719',\n",
       " 927: '0.998784552049',\n",
       " 928: '0.996980984121',\n",
       " 929: '0.990720773705',\n",
       " 930: '0.999124354702',\n",
       " 931: '0.999424949356',\n",
       " 932: '0.996628112135',\n",
       " 933: '0.997765144089',\n",
       " 934: '0.997007122786',\n",
       " 935: '0.989779781742',\n",
       " 936: '0.983362739332',\n",
       " 937: '0.999098216036',\n",
       " 938: '0.999895445338',\n",
       " 939: '0.996484349474',\n",
       " 940: '0.987858589819',\n",
       " 941: '0.991282755015',\n",
       " 942: '0.987793243155',\n",
       " 943: '0.999411880024',\n",
       " 944: '0.983362739332',\n",
       " 945: '0.997137816114',\n",
       " 946: '0.983990067307',\n",
       " 947: '0.999843168006',\n",
       " 948: '0.998183362739',\n",
       " 949: '0.999150493367',\n",
       " 950: '0.997974253414',\n",
       " 951: '0.998666928053',\n",
       " 952: '0.994994445534',\n",
       " 953: '0.999098216036',\n",
       " 954: '0.997503757433',\n",
       " 955: '0.998457818728',\n",
       " 956: '0.997503757433',\n",
       " 957: '0.983415016663',\n",
       " 958: '0.999647128014',\n",
       " 959: '0.994445533556',\n",
       " 960: '0.998104946742',\n",
       " 961: '0.998287917402',\n",
       " 962: '0.997974253414',\n",
       " 963: '0.997752074757',\n",
       " 964: '0.998797621381',\n",
       " 965: '0.996523557472',\n",
       " 966: '0.994785336209',\n",
       " 967: '0.999686336013',\n",
       " 968: '0.994354048226',\n",
       " 969: '0.994602365549',\n",
       " 970: '0.999019800039',\n",
       " 971: '0.993635234921',\n",
       " 972: '0.994105730902',\n",
       " 973: '0.992040776318',\n",
       " 974: '0.99925504803',\n",
       " 975: '0.987858589819',\n",
       " 976: '0.979468078155',\n",
       " 977: '0.997046330785',\n",
       " 978: '0.995242762857',\n",
       " 979: '0.996053061491',\n",
       " 980: '0.995896229497',\n",
       " 981: '0.998405541397',\n",
       " 982: '0.999124354702',\n",
       " 983: '0.998183362739',\n",
       " 984: '0.997438410769',\n",
       " 985: '0.996157616154',\n",
       " 986: '0.965026465399',\n",
       " 987: '0.998013461413',\n",
       " 988: '0.99692870679',\n",
       " 989: '0.99883682938',\n",
       " 990: '0.998693066719',\n",
       " 991: '0.998353264066',\n",
       " 992: '0.998719205385',\n",
       " 993: '0.998614650722',\n",
       " 994: '0.987793243155',\n",
       " 995: '0.99883682938',\n",
       " 996: '0.995138208194',\n",
       " 997: '0.988681957786',\n",
       " 998: '0.989779781742',\n",
       " 999: '0.999921584003',\n",
       " ...}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part_vw[\"lable_weights\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler and Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a: prediction\n",
    "- b: day_of_week \n",
    "- c: hour_start\n",
    "- d: time_of_day\n",
    "- e:\n",
    "- f: features\n",
    "- g: \n",
    "- h: site_longest_time\n",
    "- i: sitetimes\n",
    "- j: session_timespan\n",
    "- k: sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 188 ms, total: 2.28 s\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "folder = 'vw/'\n",
    "handler = '_idf_w8_pred'\n",
    "\n",
    "keys = ['day_of_week', 'daytime', 'prediction', 'start_hour', 'youtube_portion', 'fb_portion', 'sitetimes', 'sequence']\n",
    "\n",
    "vw_to_file(train_part_vw[\"sites\"], folder+'train_part'+handler+'.vw', \\\n",
    "           features={x:train_part_vw[x] for x in keys}, \\\n",
    "           lables=train_part_vw[\"lables\"], lable_weights=train_part_vw[\"lable_weights\"], quiet=True)\n",
    "vw_to_file(valid_vw[\"sites\"], folder+'valid'+handler+'.vw', features={x:valid_vw[x] for x in keys}, \\\n",
    "           lables=valid_vw[\"lables\"], quiet=True)\n",
    "vw_to_file(train_vw[\"sites\"], folder+'train'+handler+'.vw', features={x:train_vw[x] for x in keys}, \\\n",
    "           lables=train_vw[\"lables\"], lable_weights=train_vw[\"lable_weights\"], quiet=True)\n",
    "vw_to_file(test_vw[\"sites\"], folder+'test'+handler+'.vw', features={x:test_vw[x] for x in keys}, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(folder+'train_part'+handler+'.vw')\n",
    "train_part_file = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(folder+'train'+handler+'.vw')\n",
    "train_file = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(folder+'valid'+handler+'.vw')\n",
    "valid_file = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(folder+'test'+handler+'.vw')\n",
    "test_file = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: sd sb \n",
      "creating cubic features for triples: sbc \n",
      "using namespaces beginning with: s b c d a \n",
      "using l1 regularization = 1e-11\n",
      "using l2 regularization = 1e-11\n",
      "final_regressor = vw/initial_model_idf_w8_pred.model\n",
      "Num weight bits = 29\n",
      "learning rate = 0.541695\n",
      "initial_t = 0.00233705\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 0.9\n",
      "creating cache_file = vw/train_part_idf_w8_pred.vw.cache\n",
      "Reading datafile = vw/train_part_idf_w8_pred.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            2            2.0      469      162       36\n",
      "1.000000 1.000000            4            4.0      171      162       36\n",
      "1.000000 1.000000            9            8.9      544      473       41\n",
      "0.947147 0.899354           19           18.8      318      364      110\n",
      "0.973627 1.000000           38           37.7      311      145       37\n",
      "0.973624 0.973621           76           75.5      500       38       43\n",
      "0.947795 0.922000          152          151.2       47      318       29\n",
      "0.925188 0.902723          305          303.3       38      500       43\n",
      "0.891090 0.857000          610          606.7      150      386        8\n",
      "0.844013 0.797001         1221         1214.3      416      416       21\n",
      "0.797679 0.751372         2443         2429.2      227      318      116\n",
      "0.754933 0.712197         4887         4859.0      249      171       38\n",
      "0.711527 0.668130         9774         9718.9      177      192       39\n",
      "0.644165 0.576803        19548        19437.8      224      469       22\n",
      "0.573255 0.502346        39095        38875.7      369      369       26\n",
      "0.510943 0.510943        78187        77751.9      242      242       25 h\n",
      "0.462513 0.414091       156375       155504.7      150      150       30 h\n",
      "0.427267 0.392022       312749       311009.8      446      376      176 h\n",
      "0.407352 0.387437       625495       622020.2      130      130       42 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 68864\n",
      "passes used = 14\n",
      "weighted example sum = 958741.572369\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.386768 h\n",
      "total feature number = 48961542\n",
      "CPU times: user 3min 52s, sys: 36.8 s, total: 4min 29s\n",
      "Wall time: 2h 6min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa=550 -d {folder}train_part{handler}.vw \\\n",
    "-f {folder}initial_model{handler}.model -b 29 -c -k \\\n",
    "--passes=30 --decay_learning_rate 0.9 --initial_t 0.002337045080352835 \\\n",
    "-l 0.5416950450219994 \\\n",
    "--power_t 0.5 --loss_function='logistic' --l1 1e-11 --l2 1e-11 \\\n",
    "-q \"sd\" -q \"sb\" --cubic=\"sbc\"  \\\n",
    "--keep \"s\" --keep \"b\" --keep \"c\" --keep \"d\" --keep \"a\" \\\n",
    "--stage_poly --batch_sz {len(train_part_file)/6} --batch_sz_no_doubling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average loss = 0.406958 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.91 s, sys: 984 ms, total: 4.89 s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i {folder}initial_model{handler}.model  -t -d {folder}valid{handler}.vw \\\n",
    "-p {folder}vw_valid_pred{handler}.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53810264385692064"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_valid_pred = pd.read_csv(folder+'vw_valid_pred'+handler+'.csv', header=None)\n",
    "accuracy_score(y_valid, vw_valid_pred.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weiths1: 0.58872320312261761\n",
    "\n",
    "valid: 0.56661482633488858 -q \"sd\" -q \"sb\" --cubic=\"sbc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainvw = open(folder+'train'+handler+'.vw').readlines()\n",
    "np.random.shuffle(trainvw)\n",
    "with open(folder+'train'+handler+'.vw', \"wb\") as f:\n",
    "    for item in trainvw:\n",
    "        f.write(\"%s\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: sd sb \n",
      "creating cubic features for triples: sbc \n",
      "using namespaces beginning with: s b c d a \n",
      "using l1 regularization = 1e-11\n",
      "using l2 regularization = 1e-11\n",
      "final_regressor = vw/initial_model_idf_w8_pred.model\n",
      "Num weight bits = 29\n",
      "learning rate = 0.541695\n",
      "initial_t = 0.00233705\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 0.9\n",
      "creating cache_file = vw/train_idf_w8_pred.vw.cache\n",
      "Reading datafile = vw/train_idf_w8_pred.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.500000 0.500000            2            1.9      386      386       29\n",
      "0.503782 0.507507            4            3.9      386      386       21\n",
      "0.755045 1.000000            8            7.9      399      386       29\n",
      "0.877873 1.000000           16           15.8      422      386       37\n",
      "0.939199 1.000000           32           31.7      185      289       38\n",
      "0.954121 0.968991           64           63.6      217      180       25\n",
      "0.969323 0.984496          128          127.3       26      149       21\n",
      "0.930609 0.891918          256          254.7      402      271        8\n",
      "0.913443 0.896340          513          510.4      138      416       42\n",
      "0.862102 0.810857         1027         1021.7      168      386       45\n",
      "0.823890 0.785706         2055         2044.1      112      386       25\n",
      "0.781416 0.738956         4111         4088.9       67      349       39\n",
      "0.726250 0.671093         8223         8178.4      317      271       44\n",
      "0.664866 0.603482        16447        16357.0      138      138       38\n",
      "0.592000 0.519135        32895        32714.4      113       88      140\n",
      "0.523888 0.455777        65792        65429.3      154      154       32\n",
      "0.475689 0.475689       131587       130859.4      334      150      128 h\n",
      "0.437753 0.399821       263176       261719.3      162      162       33 h\n",
      "0.412181 0.386609       526355       523439.1      328      251       16 h\n",
      "0.397686 0.383191      1052712      1046879.0       48       48       41 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 98378\n",
      "passes used = 11\n",
      "weighted example sum = 1076159.377646\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.381399 h\n",
      "total feature number = 54843228\n",
      "CPU times: user 4min 28s, sys: 42.9 s, total: 5min 10s\n",
      "Wall time: 2h 24min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa=550 -d {folder}train{handler}.vw \\\n",
    "-f {folder}initial_model{handler}.model -b 29 -c -k \\\n",
    "--passes=30 --decay_learning_rate 0.9 --initial_t 0.002337045080352835 \\\n",
    "-l 0.5416950450219994 \\\n",
    "--power_t 0.5 --loss_function='logistic' --l1 1e-11 --l2 1e-11 \\\n",
    "-q \"sd\" -q \"sb\" --cubic=\"sbc\"  \\\n",
    "--keep \"s\" --keep \"b\" --keep \"c\" --keep \"d\" --keep \"a\" \\\n",
    "--stage_poly --batch_sz {len(train_part_file)/6} --batch_sz_no_doubling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average loss = 0.394867 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 s, sys: 876 ms, total: 4.23 s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Prediction on VALID\n",
    "!vw -i {folder}initial_model{handler}.model  -t -d {folder}valid{handler}.vw \\\n",
    "-p {folder}vw_valid_pred{handler}.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68712835056262012"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_valid_pred = pd.read_csv(folder+'vw_valid_pred'+handler+'.csv', header=None)\n",
    "accuracy_score(y_valid, vw_valid_pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: sd sb \n",
      "creating cubic features for triples: sbc \n",
      "only testing\n",
      "predictions = vw/vw_test_pred_idf_w8_pred.csv\n",
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = vw/test_idf_w8_pred.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0  unknown      333      168\n",
      "1.000000 1.000000            2            2.0  unknown       63       44\n",
      "1.000000 1.000000            4            4.0  unknown      168       16\n",
      "1.000000 1.000000            8            8.0  unknown      161       80\n",
      "1.000000 1.000000           16           16.0  unknown      328       33\n",
      "1.000000 1.000000           32           32.0  unknown      460       48\n",
      "1.000000 1.000000           64           64.0  unknown      514       55\n",
      "1.000000 1.000000          128          128.0  unknown      426       59\n",
      "1.000000 1.000000          256          256.0  unknown       97      170\n",
      "1.000000 1.000000          512          512.0  unknown       97       66\n",
      "1.000000 1.000000         1024         1024.0  unknown      115       45\n",
      "1.000000 1.000000         2048         2048.0  unknown      328       50\n",
      "1.000000 1.000000         4096         4096.0  unknown      530       60\n",
      "1.000000 1.000000         8192         8192.0  unknown      161       52\n",
      "1.000000 1.000000        16384        16384.0  unknown      344      111\n",
      "1.000000 1.000000        32768        32768.0  unknown      313       56\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 41177\n",
      "passes used = 1\n",
      "weighted example sum = 41177.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 1.000000\n",
      "total feature number = 2590807\n",
      "CPU times: user 4.46 s, sys: 1.04 s, total: 5.5 s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prediction on TEST!\n",
    "!vw -i {folder}initial_model{handler}.model -t -d {folder}test{handler}.vw \\\n",
    "-p {folder}vw_test_pred{handler}.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw_pred = pd.read_csv(folder+'vw_test_pred'+handler+'.csv', header=None)\n",
    "vw_subm = class_encoder.inverse_transform(vw_pred-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(vw_subm,\n",
    "                         folder+'42vw_submission'+handler+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://vw/42vw_submission_idf_w8_pred.csv [Content-Type=text/csv]...\n",
      "/ [1 files][419.7 KiB/419.7 KiB]                                                \n",
      "Operation completed over 1 objects/419.7 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {folder}42vw_submission{handler}.csv gs://smartandnimble/identifyme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score: 0.57276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.867574166625138, 'initial_t': 0.2776239270739265, 'l': 0.0434341264970275, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 5.248698547405331e-09, 'loss_function': 'squared', 'l1': 1.541908660931064e-08, 'type': 'ect'}\n",
      "Accuracy: 0.412161131949 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.4380919176573933, 'initial_t': 0.08681977356754463, 'l': 0.2790283913381128, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 1.4656938601889154e-08, 'loss_function': 'hinge', 'l1': 2.5435275529929987e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.528496935322 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.10244638809961329, 'initial_t': 1.0419999810170089, 'l': 0.07462834369874273, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 1.1388346589835574e-06, 'loss_function': 'squared', 'l1': 5.803833976036988e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.289513005824 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.16808058541633378, 'initial_t': 0.005555321314757138, 'l': 0.04444752645218835, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 1.1965405145568205e-05, 'loss_function': 'squared', 'l1': 1.4518447803551378e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.495807031989 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.4709268106303166, 'initial_t': 0.00018232830908504607, 'l': 1.7237113551377938, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 1.1179779226251723e-07, 'loss_function': 'logistic', 'l1': 9.004914465343011e-09, 'type': 'ect'}\n",
      "Accuracy: 0.447930960876 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.667221282158522, 'initial_t': 0.0006975129144123112, 'l': 0.32060741849890867, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 2.5570817227072065e-08, 'loss_function': 'hinge', 'l1': 2.1057562361303843e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.513646204983 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.7858665585312469, 'initial_t': 0.00042344201060401116, 'l': 1.4730057038030036, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 5.836736355475676e-05, 'loss_function': 'logistic', 'l1': 2.1203383742965224e-05, 'type': 'ect'}\n",
      "Accuracy: 0.168481078279 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.028318987790783814, 'initial_t': 0.030032169493808977, 'l': 0.5339022525190165, 'q': 'sb', 'power_t': 0.5, 'noconstant': True, 'l2': 1.2323338977249126e-08, 'loss_function': 'logistic', 'l1': 1.3026316879961454e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.476626109231 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.803828413283501, 'initial_t': 7.251986425318597e-05, 'l': 0.010738114909829934, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 8.293060327461105e-05, 'loss_function': 'hinge', 'l1': 1.017453078652902e-05, 'type': 'ect'}\n",
      "Accuracy: 0.136340072576 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8350969530752927, 'initial_t': 6.148033377066741e-05, 'l': 0.28727062121464286, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.6196189470466576e-07, 'loss_function': 'squared', 'l1': 1.076166841799221e-05, 'type': 'ect'}\n",
      "Accuracy: 0.410057024365 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.38071123698050885, 'initial_t': 1.029655337972089, 'l': 0.238946431436958, 'q': 'sb', 'power_t': 1, 'noconstant': False, 'l2': 3.4810379092435342e-06, 'loss_function': 'logistic', 'l1': 2.9740305019497227e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.347665660354 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.3569775300809522, 'initial_t': 0.03620474030483321, 'l': 0.006914254438518453, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 8.17563084648187e-05, 'loss_function': 'squared', 'l1': 1.0152289980224266e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.176988991553 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9425358835992573, 'initial_t': 0.00010266179700461874, 'l': 0.9040110078154401, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 2.2022658199277962e-07, 'loss_function': 'hinge', 'l1': 1.012003849706742e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.542981733907 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.963750119439077, 'initial_t': 0.00021341866476415038, 'l': 0.4057361275172061, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 7.871280140366821e-07, 'loss_function': 'logistic', 'l1': 2.9095665502016997e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.345653035709 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.9950491847551776, 'initial_t': 0.0016859038817446455, 'l': 0.8611465899365406, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 5.660212285444413e-08, 'loss_function': 'logistic', 'l1': 1.31935022648046e-08, 'type': 'ect'}\n",
      "Accuracy: 0.301985179764 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.8244305209892622, 'initial_t': 0.6044731177268563, 'l': 0.05898405895120441, 'q': 'sc', 'power_t': 0.5, 'noconstant': False, 'l2': 2.230259958554409e-07, 'loss_function': 'logistic', 'l1': 8.465536600126847e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.201902845119 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.9836243046489217, 'initial_t': 0.49960742438834327, 'l': 13.947026272264141, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 3.329590227960979e-07, 'loss_function': 'squared', 'l1': 1.383889873145811e-07, 'type': 'ect'}\n",
      "Accuracy: 0.410422956119 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.2069750855559933, 'initial_t': 2.044801037183741, 'l': 0.1486979684439112, 'q': 'sc', 'power_t': 1, 'noconstant': False, 'l2': 6.737026930977787e-09, 'loss_function': 'squared', 'l1': 7.852046429182051e-08, 'type': 'ect'}\n",
      "Accuracy: 0.46458085567 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9647307710877955, 'initial_t': 0.013825871179414648, 'l': 6.214989541783011, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 4.5987144503865284e-08, 'loss_function': 'hinge', 'l1': 5.0681556248419835e-08, 'type': 'ect'}\n",
      "Accuracy: 0.362333424816 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.7596547947685287, 'initial_t': 0.00010624603226661501, 'l': 2.228098807107105, 'q': 'sb', 'power_t': 1, 'noconstant': False, 'l2': 3.829575753815416e-06, 'loss_function': 'logistic', 'l1': 9.562560941127986e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.347818131918 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6114642593697446, 'initial_t': 0.17494198716491285, 'l': 4.087508444334099, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 2.891510296207632e-09, 'loss_function': 'hinge', 'l1': 3.3717311644920374e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.518616777971 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5608206423819566, 'initial_t': 0.09582253572080197, 'l': 0.01625028536502988, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 2.1009703268757885e-09, 'loss_function': 'hinge', 'l1': 1.2331193199982042e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.528283475132 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.32583392552738244, 'initial_t': 0.0037633987719442523, 'l': 0.1253821724283344, 'q': 'sc', 'power_t': 0.5, 'noconstant': True, 'l2': 1.8624144463140984e-08, 'loss_function': 'hinge', 'l1': 4.3209428693750286e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.527978532004 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.4725251087411133, 'initial_t': 0.07118893566426134, 'l': 0.7609741146179296, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 1.833406701345565e-06, 'loss_function': 'hinge', 'l1': 2.429787231673145e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.519104686976 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6903038146057064, 'initial_t': 0.012978095051215995, 'l': 3.3719472932911034, 'q': 'sd', 'power_t': 0.5, 'noconstant': True, 'l2': 4.789461559086119e-08, 'loss_function': 'hinge', 'l1': 1.0734782836610043e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.519684078919 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.31260845757366884, 'initial_t': 0.0019265616640974361, 'l': 13.289300736478957, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 4.694875570658157e-07, 'loss_function': 'hinge', 'l1': 2.8657950844506984e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.528100509255 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5504255982235231, 'initial_t': 0.026177117831937383, 'l': 0.9644049119424981, 'q': 'si', 'power_t': 0.5, 'noconstant': True, 'l2': 9.958615331544467e-08, 'loss_function': 'hinge', 'l1': 6.730661620715218e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.519196169914 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.42463535883088643, 'initial_t': 0.11831785697971116, 'l': 0.16884333680606062, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 9.010238562889848e-06, 'loss_function': 'hinge', 'l1': 3.889856481623916e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.518616777971 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.2511874906956846, 'initial_t': 0.28037167624937537, 'l': 0.0193456758102741, 'q': 'sc', 'power_t': 1, 'noconstant': True, 'l2': 4.256803659543965e-09, 'loss_function': 'hinge', 'l1': 2.966577697601274e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.528161497881 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8966456642972636, 'initial_t': 2.591190562005083, 'l': 0.030355876387419708, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 9.432291954140874e-09, 'loss_function': 'hinge', 'l1': 3.022708505737078e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.544597932486 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9038745943123347, 'initial_t': 0.0006506852216306373, 'l': 0.025297537178081007, 'q': 'si', 'power_t': 1, 'noconstant': False, 'l2': 5.691905490085639e-09, 'loss_function': 'hinge', 'l1': 3.613280742959939e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.54377458604 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8924143429991436, 'initial_t': 0.0009176749968896749, 'l': 0.02719148259572378, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 8.611626562241357e-09, 'loss_function': 'hinge', 'l1': 2.2923878354039406e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.54475040405 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.7411724684515997, 'initial_t': 0.0032760466146900644, 'l': 0.007682965176907049, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0187459370369072e-08, 'loss_function': 'hinge', 'l1': 2.41554814655738e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.509559967066 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6806678479212226, 'initial_t': 0.0008895493280219338, 'l': 0.02966976825054761, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 3.3315429739876752e-09, 'loss_function': 'hinge', 'l1': 2.3548352859844302e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.544414966609 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.8606191701687609, 'initial_t': 0.007479088544991431, 'l': 0.08523867443268686, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.9452785137192623e-08, 'loss_function': 'hinge', 'l1': 7.0536033141966626e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.509834415881 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9016364068908295, 'initial_t': 2.656762843770968, 'l': 0.03819034685580118, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0330447278285289e-08, 'loss_function': 'squared', 'l1': 2.2033581258741658e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.530844997408 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.6297951276295942, 'initial_t': 0.00029110952581480517, 'l': 0.012175374196556475, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.0921511462750696e-09, 'loss_function': 'hinge', 'l1': 2.2081921620480158e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.509163541 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.7360955082403693, 'initial_t': 0.0011360578115734766, 'l': 0.08174689700362535, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 2.56009126176999e-08, 'loss_function': 'hinge', 'l1': 7.104847515271128e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.541975421584 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.02414675781724518, 'initial_t': 0.00039770713562303333, 'l': 0.05631507266574943, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.9261369235907193e-05, 'loss_function': 'squared', 'l1': 4.780803019180059e-09, 'type': 'ect'}\n",
      "Accuracy: 0.18845485317 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9043901943230026, 'initial_t': 0.0030179846419993994, 'l': 0.010014644666380024, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 6.101052355586952e-08, 'loss_function': 'hinge', 'l1': 1.647028902873203e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.543713597414 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.7782475448882687, 'initial_t': 0.007480946302319199, 'l': 0.03891371083842383, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0291450756094518e-07, 'loss_function': 'hinge', 'l1': 1.277504362794637e-07, 'type': 'ect'}\n",
      "Accuracy: 0.372488030982 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5404385074112038, 'initial_t': 0.041030236990719504, 'l': 0.016980053014815123, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 1.0138500988137962e-06, 'loss_function': 'squared', 'l1': 8.121596545017285e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.543073216845 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.09102838187044016, 'initial_t': 1.3781158778266847, 'l': 0.11216051684063558, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.6542756526855426e-08, 'loss_function': 'logistic', 'l1': 4.52668948600449e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.323697130485 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.6339908970006558, 'initial_t': 0.00015269816906855234, 'l': 0.24081193168742832, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 6.2860519956614055e-09, 'loss_function': 'hinge', 'l1': 5.886873861693009e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.463544049035 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.8498198522212665, 'initial_t': 0.017724570965637624, 'l': 0.47891316300051534, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 9.802344452997663e-09, 'loss_function': 'hinge', 'l1': 1.089918421658346e-08, 'type': 'ect'}\n",
      "Accuracy: 0.353032659409 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.9985245270661639, 'initial_t': 5.6376305095619074e-05, 'l': 0.0265659462238616, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 2.141392626992311e-09, 'loss_function': 'logistic', 'l1': 4.9851144080070744e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.000304943128107 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.7141337060555072, 'initial_t': 0.0014012333606823588, 'l': 0.007234363561354108, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 1.891377083199654e-07, 'loss_function': 'squared', 'l1': 1.6351475567091892e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.53075351447 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9216755533035966, 'initial_t': 0.0004678639323557776, 'l': 0.19920698610238285, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 2.0658897519635912e-06, 'loss_function': 'hinge', 'l1': 3.2941696238959135e-09, 'type': 'ect'}\n",
      "Accuracy: 0.336809684994 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.8003661292648909, 'initial_t': 0.061366782666453935, 'l': 0.04706359934348978, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 5.229073935104497e-07, 'loss_function': 'logistic', 'l1': 9.185081042507018e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.118378922331 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.511829427912783, 'initial_t': 0.002180606672363022, 'l': 0.012771199211871103, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 3.923826960065199e-08, 'loss_function': 'hinge', 'l1': 4.138316786854354e-08, 'type': 'ect'}\n",
      "Accuracy: 0.338120940445 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.4139319015786712, 'initial_t': 0.4703685746945758, 'l': 0.061115965647616954, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 3.1810949490067295e-05, 'loss_function': 'squared', 'l1': 2.3733807062425772e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.530844997408 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.5989129637151813, 'initial_t': 0.00596811114052136, 'l': 0.33771828284683847, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 7.715387602266084e-08, 'loss_function': 'hinge', 'l1': 1.523643081868199e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.511999512091 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.868742381038061, 'initial_t': 0.00022524088644335286, 'l': 0.10130010225767733, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 2.0065362204351222e-08, 'loss_function': 'logistic', 'l1': 5.925442072941253e-09, 'type': 'ect'}\n",
      "Accuracy: 0.374012746623 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.9431747752219428, 'initial_t': 4.703256587334727e-05, 'l': 0.6169710590248493, 'q': 'si', 'power_t': 0.5, 'noconstant': False, 'l2': 6.93947925168237e-06, 'loss_function': 'hinge', 'l1': 1.9338132560453233e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.54356112585 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': True, 'decay_learning_rate': 0.8210881657187984, 'initial_t': 0.00012135491850180972, 'l': 1.4055895316204468, 'q': 'sd', 'power_t': 0.5, 'noconstant': False, 'l2': 3.436166850552988e-09, 'loss_function': 'hinge', 'l1': 4.55084179024482e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.513676699296 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': False, 'decay_learning_rate': 0.994301899421435, 'initial_t': 0.8733990383178091, 'l': 0.008974327412449122, 'q': 'sc', 'power_t': 0.5, 'noconstant': False, 'l2': 1.4340308395150135e-07, 'loss_function': 'squared', 'l1': 1.1046261054580319e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.0835544171012 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.147515241193658, 'initial_t': 0.3070425282762998, 'l': 9.219277866573012, 'q': 'si', 'power_t': 1, 'noconstant': True, 'l2': 4.07834749978152e-07, 'loss_function': 'logistic', 'l1': 1.9318631557197636e-08, 'type': 'ect'}\n",
      "Accuracy: 0.361632055622 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5886509467982302, 'initial_t': 0.14249250639344718, 'l': 0.021072771541441267, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 3.47093028545959e-08, 'loss_function': 'hinge', 'l1': 3.122930522066985e-08, 'type': 'oaa'}\n",
      "Accuracy: 0.545360290306 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.2803270699530178, 'initial_t': 0.13165421842819006, 'l': 0.021450353546160983, 'q': 'sb', 'power_t': 0.5, 'noconstant': True, 'l2': 8.372662927056156e-08, 'loss_function': 'hinge', 'l1': 1.6865581063499615e-05, 'type': 'oaa'}\n",
      "Accuracy: 0.525020583661 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'ibc', 'ftrl': False, 'decay_learning_rate': 0.4557892299481036, 'initial_t': 0.2024706762556334, 'l': 0.015548992248513544, 'q': 'sb', 'power_t': 1, 'noconstant': False, 'l2': 2.4873846210259985e-07, 'loss_function': 'hinge', 'l1': 7.028324607359167e-07, 'type': 'oaa'}\n",
      "Accuracy: 0.000304943128107 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.35824236145095445, 'initial_t': 0.01885870669637885, 'l': 0.07005245622187406, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 3.842472246496982e-08, 'loss_function': 'logistic', 'l1': 5.958407209441769e-06, 'type': 'oaa'}\n",
      "Accuracy: 0.347787637606 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.6528557133125664, 'initial_t': 0.040628719432438135, 'l': 0.1510350985381956, 'q': 'sb', 'power_t': 1, 'noconstant': True, 'l2': 1.3036145202013727e-07, 'loss_function': 'squared', 'l1': 3.222755093814935e-09, 'type': 'ect'}\n",
      "Accuracy: 0.438508218217 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5054904256118788, 'initial_t': 8.474172793882138e-05, 'l': 0.04910364485272336, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 4.829478246653022e-09, 'loss_function': 'hinge', 'l1': 9.646286240319292e-09, 'type': 'oaa'}\n",
      "Accuracy: 0.546305614003 \n",
      "\n",
      "Testing with params:\n",
      "{'cubic': 'sbc', 'ftrl': True, 'decay_learning_rate': 0.5779945710270283, 'initial_t': 0.055681674604569326, 'l': 0.04766346626707306, 'q': 'sb', 'power_t': 0.5, 'noconstant': False, 'l2': 1.4421125487342108e-08, 'loss_function': 'hinge', 'l1': 1.1133601373615166e-08, 'type': 'oaa'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-1de8059121aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'def hyperopt_train_test(params):\\n    with open(folder+\\'train_part\\'+handler+\\'.vw\\') as f:\\n        train_part_file = f.readlines()\\n    \\n    with open(folder+\\'valid\\'+handler+\\'.vw\\') as f:\\n        valid_file = f.readlines()\\n    \\n    clas_type = params[\"type\"]\\n    del params[\"type\"]\\n    \\n    if clas_type == \"ect\":\\n        model = VW(ect=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\\n    else:\\n        model = VW(oaa=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\\n    \\n    #skf = StratifiedKFold(n_splits=3, shuffle=True)\\n    model.fit(train_part_file)\\n    accuracy = accuracy_score(y_valid, model.predict(valid_file))\\n    return accuracy\\n    #return cross_val_score(model, X=train_part_file, y=y_train, cv=skf, scoring=make_scorer(accuracy_score), n_jobs=3).mean()\\n\\nspace4knn = {\\n    \\'type\\': hp.choice(\\'type\\', [\\'oaa\\', \\'ect\\']),\\n    \\'l\\': hp.loguniform(\\'l\\', -5, 3),\\n    \\'initial_t\\': hp.loguniform(\\'initial_t\\', -10, 1),\\n    \\'power_t\\': hp.choice(\\'power_t\\', [0.5, 1]),\\n    \\'decay_learning_rate\\': hp.uniform(\\'decay_learning_rate\\', 0.001, 1),\\n    \\'l2\\': hp.loguniform(\\'l2\\', -20, -9),\\n    \\'l1\\': hp.loguniform(\\'l1\\', -20, -9),\\n    \\'loss_function\\': hp.choice(\\'loss_function\\', [\"logistic\", \"hinge\", \"squared\"]),\\n    \\'ftrl\\': hp.choice(\\'ftrl\\', [True, False]),\\n    \\'noconstant\\': hp.choice(\\'noconstant\\', [True, False]),\\n    \\'cubic\\': hp.choice(\\'cubic\\', [\\'sbc\\', \\'ibc\\']),\\n    \\'q\\': hp.choice(\\'q\\', [\"sb\", \"sc\", \"sd\", \"si\"])\\n}\\n\\ndef f(params):\\n    print \"Testing with params:\"\\n    print params\\n    acc = hyperopt_train_test(params)\\n    print \"Accuracy:\", acc, \"\\\\n\"\\n    return {\\'loss\\': -acc, \\'status\\': STATUS_OK}\\n\\ntrials_wide_range = Trials()\\n#trials_wide_range = MongoTrials(\\'mongo://localhost:1234/mydb/jobs\\', exp_key=\\'exp1\\')\\nbest = fmin(f, space4knn, algo=tpe.suggest, max_evals=100, trials=trials_wide_range)\\nprint \\'best:\\'\\nprint best'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mf\u001b[1;34m(params)\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mhyperopt_train_test\u001b[1;34m(params)\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/vowpalwabbit/sklearn_vw.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dlihhats/anaconda2/lib/python2.7/site-packages/vowpalwabbit/pyvw.pyc\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, ec)\u001b[0m\n\u001b[0;32m     82\u001b[0m         learned on).\"\"\"\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'setup_done'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def hyperopt_train_test(params):\n",
    "    with open(folder+'train_part'+handler+'.vw') as f:\n",
    "        train_part_file = f.readlines()\n",
    "    \n",
    "    with open(folder+'valid'+handler+'.vw') as f:\n",
    "        valid_file = f.readlines()\n",
    "    \n",
    "    clas_type = params[\"type\"]\n",
    "    del params[\"type\"]\n",
    "    \n",
    "    if clas_type == \"ect\":\n",
    "        model = VW(ect=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\n",
    "    else:\n",
    "        model = VW(oaa=550, passes=30, b=26, convert_to_vw=False, sort_features=True, **params)\n",
    "    \n",
    "    #skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    model.fit(train_part_file)\n",
    "    accuracy = accuracy_score(y_valid, model.predict(valid_file))\n",
    "    return accuracy\n",
    "    #return cross_val_score(model, X=train_part_file, y=y_train, cv=skf, scoring=make_scorer(accuracy_score), n_jobs=3).mean()\n",
    "\n",
    "space4knn = {\n",
    "    'type': hp.choice('type', ['oaa', 'ect']),\n",
    "    'l': hp.loguniform('l', -5, 3),\n",
    "    'initial_t': hp.loguniform('initial_t', -10, 1),\n",
    "    'power_t': hp.choice('power_t', [0.5, 1]),\n",
    "    'decay_learning_rate': hp.uniform('decay_learning_rate', 0.001, 1),\n",
    "    'l2': hp.loguniform('l2', -20, -9),\n",
    "    'l1': hp.loguniform('l1', -20, -9),\n",
    "    'loss_function': hp.choice('loss_function', [\"logistic\", \"hinge\", \"squared\"]),\n",
    "    'ftrl': hp.choice('ftrl', [True, False]),\n",
    "    'noconstant': hp.choice('noconstant', [True, False]),\n",
    "    'cubic': hp.choice('cubic', ['sbc', 'ibc']),\n",
    "    'q': hp.choice('q', [\"sb\", \"sc\", \"sd\", \"si\"])\n",
    "}\n",
    "\n",
    "def f(params):\n",
    "    print \"Testing with params:\"\n",
    "    print params\n",
    "    acc = hyperopt_train_test(params)\n",
    "    print \"Accuracy:\", acc, \"\\n\"\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials_wide_range = Trials()\n",
    "#trials_wide_range = MongoTrials('mongo://localhost:1234/mydb/jobs', exp_key='exp1')\n",
    "best = fmin(f, space4knn, algo=tpe.suggest, max_evals=100, trials=trials_wide_range)\n",
    "print 'best:'\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
