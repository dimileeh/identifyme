{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"new_kaggle_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Progress tracker from https://github.com/alexanderkuk/log-progress\n",
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_site_index(csv_file):\n",
    "    site_index = pd.read_csv(csv_file, header=None, names=['siteid', 'site'], index_col=1)\n",
    "    site_dic = site_index.to_dict()\n",
    "    return site_dic[\"siteid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(folder+'test_sessions.csv', \\\n",
    "                      parse_dates=range(10,20), \\\n",
    "                      infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57654\n"
     ]
    }
   ],
   "source": [
    "site_index = get_site_index(folder+\"site_indexes.txt\")\n",
    "print len(site_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_site_dic = {}\n",
    "for k, v in site_index.items():\n",
    "    id_site_dic[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for session in test_df.values:\n",
    "    for i in range (0, 10):\n",
    "        if int(session[i]) != 0:\n",
    "            row = [session[10 + i], id_site_dic[int(session[i])]]\n",
    "            data.append(row)\n",
    "data = pd.DataFrame(data, columns=[\"timestamp\", \"site\"])\n",
    "\n",
    "data.to_csv(folder+\"full_test_temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sitefreq(sites, site_freq={}, site_index={}):\n",
    "    if not len(site_index):\n",
    "        if len(site_freq):\n",
    "            site_id = max(site_freq.items(), key=lambda t: t[1][0])[1][0] + 1\n",
    "        else:\n",
    "            site_id = 1\n",
    "    for site in sites:\n",
    "        if len(site_index):\n",
    "            site_id = site_index[site]\n",
    "                \n",
    "        if site not in site_freq:\n",
    "            site_freq[site] = [site_id, 1]\n",
    "            site_id += 1\n",
    "        else:\n",
    "            site_freq[site][1] += 1\n",
    "            \n",
    "    return site_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_set_with_fe(csv_files_mask, feature_names, site_index={}, site_freq_path=\"\", dataframe_csv=\"\",\n",
    "                                    session_length=10, window_size=10, session_time = 30,\\\n",
    "                                sort_in_session=False,\n",
    "                             freq_only=False, prediction=False):\n",
    "    \n",
    "    global_window_size = window_size\n",
    "    train_data = np.array([np.zeros(len(feature_names))])\n",
    "    site_freq = {}\n",
    "    session_num = 0\n",
    "    temp_session_length = session_length\n",
    "    user_count = 1\n",
    "    \n",
    "    if site_freq_path != \"\":\n",
    "        pkl_file = open(site_freq_path, 'rb')\n",
    "        site_freq = pickle.load(pkl_file)\n",
    "    \n",
    "    if len(site_freq):\n",
    "        regex=re.compile(\".*(facebook).*\")\n",
    "        facebook_ix = [site_freq[i][0] for i in [m.group(0) for l in site_freq.keys() for m in [regex.search(l)] if m]]\n",
    "        regex=re.compile(\".*(youtube).*\")\n",
    "        youtube_ix = [site_freq[i][0] for i in [m.group(0) for l in site_freq.keys() for m in [regex.search(l)] if m]]\n",
    "\n",
    "        num_more_100 = len([[k, v] for k, v in sorted(site_freq.items(), key=lambda t: t[1][1], reverse=False) if v[1] > 1000])\n",
    "        top30_ix = [v[0] for k, v in sorted(site_freq.items(), key=lambda t: t[1][1], reverse=True)[:num_more_100]]\n",
    "        num_less_100 = len([[k, v] for k, v in sorted(site_freq.items(), key=lambda t: t[1][1], reverse=False) if v[1] < 50])\n",
    "        bot30_ix = [v[0] for k, v in sorted(site_freq.items(), key=lambda t: t[1][1], reverse=False)[:num_less_100]]\n",
    "    else:\n",
    "        freq_only = True\n",
    "        print \"Building site freq.\"\n",
    "    \n",
    "    data = None\n",
    "    if dataframe_csv != \"\":\n",
    "        data = pd.read_csv(dataframe_csv, parse_dates=[0], infer_datetime_format=True)\n",
    "        files = [0]\n",
    "    else:\n",
    "        files = glob(csv_files_mask)\n",
    "        \n",
    "    for userfile in log_progress(files, every=1):\n",
    "        if dataframe_csv == \"\":\n",
    "            window_size = global_window_size\n",
    "            user_id = int(re.search('user(\\d+)\\.csv', userfile).group(1))\n",
    "            data = pd.read_csv(userfile, \\\n",
    "                               parse_dates=[0], infer_datetime_format=True)\n",
    "\n",
    "            if not len(data):\n",
    "                continue\n",
    "            data.sort_values(\"timestamp\", inplace=True)\n",
    "            data.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            user_count += 1\n",
    "        session_hash = {}    \n",
    "        \n",
    "        if freq_only: site_freq = sitefreq(data.site, site_freq, site_index)\n",
    "            \n",
    "        if not freq_only:\n",
    "        \n",
    "            session = []\n",
    "            timestamps = []\n",
    "            next_session = []\n",
    "            next_t_session = []\n",
    "            next_s_session = []\n",
    "            next_timestamps = []\n",
    "\n",
    "            for i in range (0, len(data), window_size):  \n",
    "                session += list(data[i:i+session_length].site.apply(lambda x: site_index[x]))\n",
    "                timestamps += list(data[i:i+session_length].timestamp)\n",
    "\n",
    "                if window_size < session_length and sort_in_session:\n",
    "                    ses_ts_zip = sorted(set(zip(session, timestamps)), key = lambda t: t[1])\n",
    "                    session, timestamps = zip(*ses_ts_zip)\n",
    "                    session = list(session)\n",
    "                    timestamps = list(timestamps)\n",
    "\n",
    "                while ((len(session) >= session_length) or (not len(data[i+window_size:]) and len(session))):\n",
    "                    time_diff = [(timestamps[n+1] - timestamps[n]).total_seconds() for n in range(0, len(session)-1)]\n",
    "                    session_timespan = (max(timestamps) - min(timestamps)).total_seconds()\n",
    "                    next_session = []\n",
    "                    next_timestamps = []\n",
    "                    \n",
    "                    while session_timespan > session_time*60 or len(session) > session_length:\n",
    "                        next_session.insert(0, session.pop())\n",
    "                        next_timestamps.insert(0, timestamps.pop())\n",
    "                        time_diff = [(timestamps[n+1] - timestamps[n]).total_seconds() for n in range(0, len(session)-1)]\n",
    "                        session_timespan = (max(timestamps) - min(timestamps)).total_seconds()\n",
    "\n",
    "                    session = tuple(session)\n",
    "\n",
    "                    if session not in session_hash or dataframe_csv != \"\":                      \n",
    "                        session_hash[session] = 1\n",
    "                        session = list(session)                       \n",
    "                                                \n",
    "                        if dataframe_csv != \"\" and sort_in_session: #need to sort sites in sessions by timestamp in test data\n",
    "                            ses_ts_zip = sorted(set(zip(session, timestamps)), key = lambda t: t[1])\n",
    "                            session, timestamps = zip(*ses_ts_zip)\n",
    "                            session = list(session)\n",
    "                            timestamps = list(timestamps)\n",
    "                            time_diff = [(timestamps[n+1] - timestamps[n]).total_seconds() for n in range(0, len(session)-1)]\n",
    "                            session_timespan = (max(timestamps) - min(timestamps)).total_seconds()\n",
    "                        \n",
    "                        num_unique_sites = len(set(session))\n",
    "                        start_hour = min(timestamps).hour\n",
    "                        day_of_week = min(timestamps).weekday()\n",
    "                        \n",
    "                        #сайт, на котором пользователь находился дольше всего в сессии\n",
    "                        if len(session) == 1:\n",
    "                            site_longest_time = session[0]\n",
    "                        else:\n",
    "                            site_longest_time = session[time_diff.index(max(time_diff))]\n",
    "                        \n",
    "                        #доля facebook в сессии по времени\n",
    "                        facebook_in_session = np.where(np.in1d(session, facebook_ix) == True)[0]\n",
    "                        facebook_times = [time_diff[t] for t in facebook_in_session if t < len(time_diff)]\n",
    "                        fb_portion = sum(facebook_times)/session_timespan if len(facebook_times) and session_timespan else 0\n",
    "                        #print(facebook_in_session)\n",
    "\n",
    "                        #доля youtube в сессии по времени\n",
    "                        youtube_in_session = np.where(np.in1d(session, youtube_ix) == True)[0]\n",
    "                        youtube_times = [time_diff[t] for t in youtube_in_session if t < len(time_diff)]\n",
    "                        youtube_portion = sum(youtube_times)/session_timespan if len(youtube_times) and session_timespan else 0\n",
    "\n",
    "                        #доля топ30 сайтов в сессии по времени\n",
    "                        top30_in_session = np.where(np.in1d(session, top30_ix) == True)[0]\n",
    "                        top30_times = [time_diff[t] for t in top30_in_session if t < len(time_diff)]\n",
    "                        top30_portion = sum(top30_times)/session_timespan if len(top30_times) and session_timespan else 0\n",
    "                        \n",
    "                        #доля бот30 сайтов в сессии по времени\n",
    "                        bot30_in_session = np.where(np.in1d(session, bot30_ix) == True)[0]\n",
    "                        bot30_times = [time_diff[t] for t in bot30_in_session if t < len(time_diff)]\n",
    "                        bot30_portion = sum(bot30_times)/session_timespan if len(bot30_times) and session_timespan else 0\n",
    "\n",
    "                        #время суток начала сессии: 5-12 утро, 12-17 - день, 18-23 вечер, 0-5 ночь\n",
    "                        if start_hour in range(5,12):\n",
    "                            daytime = 0\n",
    "                        elif start_hour in range(12, 18):\n",
    "                            daytime = 1\n",
    "                        elif start_hour > 18:\n",
    "                            daytime = 2\n",
    "                        elif start_hour < 5:\n",
    "                            daytime = 3\n",
    "                            \n",
    "                        if dataframe_csv != \"\":\n",
    "                            session_length = temp_session_length\n",
    "                            \n",
    "\n",
    "                        session_prediction = 0\n",
    "                        if prediction:\n",
    "                            for site in session:\n",
    "                                if site in site_user_dic and len(site_user_dic[site]) == 1:\n",
    "                                    session_prediction = list(site_user_dic[site])[0]\n",
    "                                    break   \n",
    "\n",
    "                        session.extend([0] * (session_length - len(session)) + \\\n",
    "                                       timestamps + [0] * (session_length - len(timestamps)) + \\\n",
    "                                       time_diff + \\\n",
    "                                       [0]*(session_length - len(time_diff) - 1) + \\\n",
    "                                       [session_timespan, num_unique_sites, site_longest_time, start_hour, day_of_week, daytime, fb_portion,\\\n",
    "                                youtube_portion, top30_portion, bot30_portion, session_prediction])\n",
    "                        if dataframe_csv == \"\":\n",
    "                            session.extend([user_id])\n",
    "                        \n",
    "\n",
    "                        train_data = np.concatenate((train_data, np.array([session])))\n",
    "                        session_num += 1\n",
    "\n",
    "                    session = next_session\n",
    "                    timestamps = next_timestamps\n",
    "            \n",
    "            if len(next_session):\n",
    "                print(\"ERROR! next_session left!\")\n",
    "                print(session)\n",
    "                return None\n",
    "\n",
    "    if freq_only:\n",
    "        with open(folder+'site_freq.pkl', 'wb') as site_freq_pkl:\n",
    "            pickle.dump(site_freq, site_freq_pkl)\n",
    "        return site_freq\n",
    "    \n",
    "    train_data = np.delete(train_data, 0, 0)\n",
    "    train_data = pd.DataFrame(train_data, columns=feature_names)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['site' + str(i) for i in range(1,11)] + ['time' + str(i) for i in range(1,11)] + \\\n",
    "                ['time_diff' + str(j) for j in range(1,10)] + \\\n",
    "                ['session_timespan', '#unique_sites', 'site_longest_time', 'start_hour', 'day_of_week', 'daytime', 'fb_portion',\\\n",
    "                 'youtube_portion', 'top30_portion', 'bot30_portion', 'prediction', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building site freq.\n",
      "CPU times: user 19.9 s, sys: 1.75 s, total: 21.6 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "site_freq  = prepare_train_set_with_fe(folder+'train/*',\n",
    "                                   feature_names=feature_names, \n",
    "                                            freq_only=True, site_index = site_index, session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 133905 58.2483637928 2.0 44157\n"
     ]
    }
   ],
   "source": [
    "freqs = [v[1] for v in site_freq.values()]\n",
    "print min(freqs), max(freqs), np.mean(freqs), np.median(freqs), len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_initial = pd.read_csv(folder+\"train_sessions.csv\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 257014\n",
      "CPU times: user 50.2 s, sys: 324 ms, total: 50.5 s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_site_dic = {}\n",
    "site_user_dic = {}\n",
    "\n",
    "pkl_file = open(folder+\"site_freq.pkl\", 'rb')\n",
    "site_freq = pickle.load(pkl_file)\n",
    "print \"Rows:\", len(train_data_initial)\n",
    "for i, v in train_data_initial.iterrows():\n",
    "    userid = int(v.user_id)\n",
    "    if userid not in user_site_dic:\n",
    "        user_site_dic[userid] = {}\n",
    "    for site in ['site' + str(i) for i in range(1,11)]:\n",
    "        ssite = int(v[site])\n",
    "        if ssite != 0:\n",
    "            if ssite in user_site_dic[userid]:\n",
    "                user_site_dic[userid][ssite] +=1\n",
    "            else:\n",
    "                user_site_dic[userid][ssite] = 1\n",
    "        \n",
    "        if ssite in site_user_dic:\n",
    "            site_user_dic[ssite].add(userid)\n",
    "        else:\n",
    "            site_user_dic[ssite] = set([userid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 9s, sys: 18min 22s, total: 4h 18min 31s\n",
      "Wall time: 4h 18min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data  = prepare_train_set_with_fe(folder+'train/*',\n",
    "                                feature_names=feature_names, \n",
    "                                site_freq_path=folder+\"site_freq.pkl\", \\\n",
    "                                session_length=10, prediction=True, site_index = site_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 13min 25s, sys: 1min 17s, total: 1h 14min 42s\n",
      "Wall time: 1h 14min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_feature_names = feature_names[:-1]\n",
    "test_data  = prepare_train_set_with_fe(folder+'train/*', dataframe_csv=folder+\"full_test_temp.csv\",\n",
    "                                feature_names=test_feature_names, site_index = site_index, \\\n",
    "                                site_freq_path=folder+\"site_freq.pkl\", session_length=10, \\\n",
    "                                prediction=True, sort_in_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_csv(folder+\"full_test.csv\", index=False)\n",
    "train_data.to_csv(folder+\"full_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
