{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlihhats/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, make_scorer\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(pkl_path=\"\", csv_path=\"\"):\n",
    "    if pkl_path != \"\":\n",
    "        pkl_file = open(pkl_path, 'rb')\n",
    "        data = pickle.load(pkl_file)\n",
    "    elif csv_path != \"\":\n",
    "        data = pd.read_csv(csv_path)\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_site_times_portions(train_data, test_data):\n",
    "    site_times = [{},{}]\n",
    "    count = 0\n",
    "    for data in [train_data, test_data]:\n",
    "        for r, row in data[:][range(0, 10)+range(20,30)].iterrows():\n",
    "            rowdic = {}\n",
    "            for c, s in [[c, 'site' + str(c)] for c in range(1,10)]:\n",
    "                if row[s] == 0:\n",
    "                    continue\n",
    "                if row[s] in rowdic:\n",
    "                    rowdic[int(row[s])] += row[\"time_diff\"+str(c)]\n",
    "                else:\n",
    "                    rowdic[int(row[s])] = row[\"time_diff\"+str(c)]\n",
    "            site_times[count][r] = {}\n",
    "            for site, time in rowdic.items():\n",
    "                if len(rowdic) == 1:\n",
    "                    site_times[count][r][int(site)] = 1.0\n",
    "                    continue\n",
    "                if time > 0:\n",
    "                    site_times[count][r][int(site)] = round(float(time)/row[\"session_timespan\"],3)\n",
    "        count+=1\n",
    "    return site_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def site_times_to_sparse(sitetimes):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    rowcount = 0\n",
    "    for sitetime in sitetimes:\n",
    "        for r, sites in sitetime.items():\n",
    "            for site, p in sites.items():\n",
    "                col.append(site)\n",
    "                row.append(rowcount)\n",
    "                data.append(p)\n",
    "            rowcount+=1\n",
    "    site_times_sparse = csr_matrix((data, (row, col)), shape=(len(sitetimes[0])+len(sitetimes[1]), max(col)+1), \\\n",
    "                                                                                              dtype=float)[:,1:]\n",
    "    return site_times_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparsematrix1(X):\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    vocabulary = {}\n",
    "    for d in X:\n",
    "        for term in d:\n",
    "            if term != 0:\n",
    "                index = vocabulary.setdefault(term, len(vocabulary))\n",
    "                indices.append(index)\n",
    "                data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    return csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparsematrix(X):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for r in range(X.shape[0]):\n",
    "        row_counter = Counter(X[r])\n",
    "        for site, num in row_counter.items():\n",
    "            row.append(r)\n",
    "            col.append(site)\n",
    "            data.append(num)\n",
    "    print \"Sparse Matrix - rows:\", X.shape[0], \"columns:\", len(set(col))\n",
    "    return csr_matrix((data, (row, col)), shape=(X.shape[0], len(set(col))))[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sites_to_sparse(train_data, test_data, target_col, session_length, label_encoder=False):\n",
    "    train_test_df = pd.concat([train_data, test_data])\n",
    "\n",
    "    train_test_df_sites = train_test_df[['site' + str(c) for c in range(1,session_length+1)]].fillna(0).astype('int')\n",
    "    X_train_test_sparse = sparsematrix1(train_test_df_sites.as_matrix())\n",
    "    X_train_sparse = X_train_test_sparse[:len(train_data)]\n",
    "    X_test_sparse = X_train_test_sparse[len(train_data):]\n",
    "    y = train_data[target_col]\n",
    "    \n",
    "    sites_columns_num = X_train_test_sparse.shape[1]\n",
    "    \n",
    "    y_for_vw = None\n",
    "    class_encoder = None\n",
    "    if label_encoder:\n",
    "        class_encoder = LabelEncoder().fit(y.astype('str'))\n",
    "        y_for_vw = class_encoder.transform(y.astype('str'))\n",
    "    \n",
    "    return [X_train_sparse, X_test_sparse, y, y_for_vw, sites_columns_num, class_encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_to_sparse(train_data, test_data, feature_cols):\n",
    "    features_matrix = []\n",
    "    for df in [train_data, test_data]:\n",
    "        num_cols = 0\n",
    "        data = []\n",
    "        rows = []\n",
    "        cols = []\n",
    "        for label in feature_cols:\n",
    "            if label in [\"day_of_week\", \"daytime\"]:\n",
    "                coldata = list(df[[label]].values.T[0].astype('float') + 1)\n",
    "            else:\n",
    "                coldata = list(df[[label]].values.T[0].astype('float'))\n",
    "            if len(data):\n",
    "                data += coldata\n",
    "            else:\n",
    "                data = list(coldata)\n",
    "            if len(cols):\n",
    "                cols += [num_cols] * len(coldata)\n",
    "            else:\n",
    "                cols = [num_cols] * len(coldata)\n",
    "            num_cols += 1\n",
    "        rows = [r for r in range(df.shape[0])] * num_cols\n",
    "        features = csr_matrix((data, (rows, cols)), shape=(df.shape[0], num_cols), dtype=float)\n",
    "        features_matrix.append(features)\n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_sites_features_sparse(sites_train_sparse, features_train_sparse, \\\n",
    "                                  sites_test_sparse, features_test_sparse):\n",
    "    X_train_sparse = hstack([sites_train_sparse, features_train_sparse], dtype=float).tocsr()\n",
    "    X_test_sparse = hstack([sites_test_sparse, features_test_sparse], dtype=float).tocsr()\n",
    "    return [X_train_sparse, X_test_sparse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading processed train and test files\n",
    "train_data = load_data(csv_path='kaggle_data/toy_train_w5_old.csv')\n",
    "test_data = load_data(csv_path='kaggle_data/full_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.05 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Additionally, let's calculate the percentage of session time spent by every site in session\n",
    "#site_times = calc_site_times_portions(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert site times to sparse format\n",
    "#site_times_sparse = site_times_to_sparse(site_times)\n",
    "#train_site_times_sparse = site_times_sparse[:len(train_data)]\n",
    "#test_site_times_sparse = site_times_sparse[len(train_data):]\n",
    "#site_times_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_diff1',\n",
       " 'time_diff2',\n",
       " 'time_diff3',\n",
       " 'time_diff4',\n",
       " 'time_diff5',\n",
       " 'time_diff6',\n",
       " 'time_diff7',\n",
       " 'time_diff8',\n",
       " 'time_diff9',\n",
       " 'session_timespan',\n",
       " '#unique_sites',\n",
       " 'site_longest_time',\n",
       " 'start_hour',\n",
       " 'day_of_week',\n",
       " 'daytime',\n",
       " 'fb_portion',\n",
       " 'youtube_portion',\n",
       " 'top30_portion',\n",
       " 'bot30_portion',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[label for label in test_data[range(20, test_data.shape[1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 144 ms, total: 1.52 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_sparse, X_test_sparse, y, y_for_vw, sites_columns_num, class_encoder = \\\n",
    "    sites_to_sparse(train_data, test_data, \"target\", 10, label_encoder=LabelEncoder())\n",
    "    \n",
    "mycolumns = ['day_of_week', 'daytime', 'prediction', 'start_hour', 'youtube_portion', \\\n",
    "             'fb_portion', 'bot30_portion']\n",
    "#[label for label in test_data[range(20, test_data.shape[1])]]\n",
    "\n",
    "train_features, test_features = features_to_sparse(train_data, test_data, mycolumns)\n",
    "\n",
    "\n",
    "\n",
    "X_train_sparse, X_test_sparse = combine_sites_features_sparse(X_train_sparse, train_features, \\\n",
    "                                                             X_test_sparse, \\\n",
    "                                                              test_features)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_sparse, y_for_vw, test_size=0.3, stratify=y_for_vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "dtrainfull = xgb.DMatrix(X_train_sparse, y_for_vw)\n",
    "dtest = xgb.DMatrix(X_test_sparse)\n",
    "\n",
    "pd.DataFrame(y_valid).to_csv(\"kaggle_data/xgb/toy/y_valid_w5_old.csv\", index=False, header=False)\n",
    "\n",
    "dtrain.save_binary(\"kaggle_data/xgb/toy/train.buffer\")\n",
    "dvalid.save_binary(\"kaggle_data/xgb/toy/valid.buffer\")\n",
    "dtrainfull.save_binary(\"kaggle_data/xgb/toy/trainfull.buffer\")\n",
    "dtest.save_binary(\"kaggle_data/xgb/toy/test.buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid=pd.read_csv(\"kaggle_data/y_valid_w5.csv\", header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.640883159221\n",
      "CPU times: user 2min 7s, sys: 248 ms, total: 2min 7s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# specify parameters via map\n",
    "param = {'silent':0, 'objective':'multi:softmax', 'num_class':150, 'max_depth':5, 'max_delta_step': 3}\n",
    "param['eval_metric'] = ['merror']#, 'mlogloss']\n",
    "param['nthread'] = 2\n",
    "num_round = 30\n",
    "evallist  = [(dvalid,'eval'), (dtrain,'train')]\n",
    "bst = xgb.train(param, dtrain, num_round)#, evallist, verbose_eval=True, early_stopping_rounds=10)\n",
    "# make prediction\n",
    "preds = bst.predict(dvalid)\n",
    "print \"Accuracy:\", accuracy_score(preds, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
